\relax 
\providecommand\hyper@newdestlabel[2]{}
\catcode `"\active 
\AC@reset@newl@bel
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\babel@aux{english}{}
\@writefile{@@@}{\chapterbegin }
\@writefile{@@@}{\chapterbegin }
\citation{reviewASRchildren}
\citation{Acoustic_change_children}
\citation{klatt1977review}
\citation{kiktova2013comparison}
\citation{weide1998carnegie}
\citation{TFchildren}
\citation{vaswani2017attention}
\@writefile{@@@}{\chapterbegin }
\@writefile{@@@}{\chapterbegin }
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {xchapter}{Introduction}{1}{chapter.1}}
\@writefile{lot}{\contentsline {xchapter}{Introduction}{1}{chapter.1}}
\citation{levelt1993speaking}
\citation{black2015communication}
\citation{langbecker2020long}
\newlabel{chapter:1}{{1}{3}{Introduction}{chapter.1}{}}
\newlabel{chapter:1@cref}{{[chapter][1][]1}{[1][3][]3}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Context}{3}{section.1.1}}
\citation{hilty2015new,barnett2011utilizing}
\citation{hughes2019increasing}
\citation{mendoza2022added}
\citation{brewer2013using}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Illustrated herein are some examples of children's Speech and Language Technology applications that were developed during the course of this thesis. On the left is a running platformer game, where the user's voice controls the character. Pitch dictates running and jumping actions, while energy modulates the velocity of these actions. On the right, a reading task game is depicted, wherein a robot instructs the user to read designated words.\relax }}{5}{figure.caption.5}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:exSLT}{{1.1}{5}{Illustrated herein are some examples of children's Speech and Language Technology applications that were developed during the course of this thesis. On the left is a running platformer game, where the user's voice controls the character. Pitch dictates running and jumping actions, while energy modulates the velocity of these actions. On the right, a reading task game is depicted, wherein a robot instructs the user to read designated words.\relax }{figure.caption.5}{}}
\newlabel{fig:exSLT@cref}{{[figure][1][1]1.1}{[1][4][]5}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Problem statement}{5}{section.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Contributions}{6}{section.1.3}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Structure for the thesis}{8}{section.1.4}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background - Children automatic speech recognition}{9}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {xchapter}{Background - Children automatic speech recognition}{9}{chapter.2}}
\@writefile{lot}{\contentsline {xchapter}{Background - Children automatic speech recognition}{9}{chapter.2}}
\newlabel{chap:Chapter2}{{2}{10}{Background - Children automatic speech recognition}{chapter.2}{}}
\newlabel{chap:Chapter2@cref}{{[chapter][2][]2}{[1][10][]10}}
\citation{childrenSpeechWorse}
\citation{li2023asr}
\citation{li2014overview,king2017robust}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Children speech recognition challenges}{12}{section.2.1}}
\newlabel{section:Children_seepch_challenges}{{2.1}{12}{Children speech recognition challenges}{section.2.1}{}}
\newlabel{section:Children_seepch_challenges@cref}{{[section][1][2]2.1}{[1][12][]12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Speech variability}{12}{subsection.2.1.1}}
\citation{Acoustic_change_children}
\citation{first_vowel_study}
\citation{reviewASRchildren,Acoustic_change_children,why_children_speech_no_working}
\citation{reviewASRchildren}
\citation{reviewASRchildren}
\citation{reviewASRchildren}
\citation{Acoustic_change_children}
\citation{Acoustic_change_children}
\citation{Acoustic_change_children}
\citation{segment_definition}
\citation{Acoustic_change_children}
\newlabel{fig:f1f2_children}{{2.1(a)}{14}{Subfigure 2 2.1(a)}{subfigure.2.1.1}{}}
\newlabel{fig:f1f2_children@cref}{{[subfigure][1][2,1]2.1(a)}{[1][14][]14}}
\newlabel{sub@fig:f1f2_children}{{(a)}{14}{Subfigure 2 2.1(a)\relax }{subfigure.2.1.1}{}}
\newlabel{fig:intra_children}{{2.1(b)}{14}{Subfigure 2 2.1(b)}{subfigure.2.1.2}{}}
\newlabel{fig:intra_children@cref}{{[subfigure][2][2,1]2.1(b)}{[1][14][]14}}
\newlabel{sub@fig:intra_children}{{(b)}{14}{Subfigure 2 2.1(b)\relax }{subfigure.2.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Formant and cepstral variability. Figures taken from \cite  {reviewASRchildren}\relax }}{14}{figure.caption.6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Changes in F1-F2 vowel space as a function of age}}}{14}{figure.caption.6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Mean cepstral distance between the two repetitions of the same vowels}}}{14}{figure.caption.6}}
\citation{moats2000speech}
\citation{Acoustic_change_children}
\newlabel{fig:duration_vowel_children}{{2.2(a)}{15}{Subfigure 2 2.2(a)}{subfigure.2.2.1}{}}
\newlabel{fig:duration_vowel_children@cref}{{[subfigure][1][2,2]2.2(a)}{[1][14][]15}}
\newlabel{sub@fig:duration_vowel_children}{{(a)}{15}{Subfigure 2 2.2(a)\relax }{subfigure.2.2.1}{}}
\newlabel{fig:intra_duration_children}{{2.2(b)}{15}{Subfigure 2 2.2(b)}{subfigure.2.2.2}{}}
\newlabel{fig:intra_duration_children@cref}{{[subfigure][2][2,2]2.2(b)}{[1][14][]15}}
\newlabel{sub@fig:intra_duration_children}{{(b)}{15}{Subfigure 2 2.2(b)\relax }{subfigure.2.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Segmental duration variability. Figures taken from \cite  {Acoustic_change_children}\relax }}{15}{figure.caption.7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Averaged-vowel duration across all vowels and subjects in each age group}}}{15}{figure.caption.7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Within- and between-subject variations. The between-subject variation is reduced by a factor of 2.0}}}{15}{figure.caption.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Language and phonetic knowledge}{15}{subsection.2.1.2}}
\newlabel{subsection:mispron}{{2.1.2}{15}{Language and phonetic knowledge}{subsection.2.1.2}{}}
\newlabel{subsection:mispron@cref}{{[subsection][2][2,1]2.1.2}{[1][15][]15}}
\citation{language_children}
\citation{clark1977psychology}
\citation{language_children2}
\citation{Children_language_model,children_language_model2}
\citation{radford2023robust}
\citation{librispeech}
\citation{chen2021gigaspeech}
\citation{MyST,singakids,ahmed2021auskidtalk}
\citation{MyST,cmu,cslu,pf-star-british,ahmed2021auskidtalk}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Data scarcity}{17}{subsection.2.1.3}}
\newlabel{section:data_scarcity}{{2.1.3}{17}{Data scarcity}{subsection.2.1.3}{}}
\newlabel{section:data_scarcity@cref}{{[subsection][3][2,1]2.1.3}{[1][17][]17}}
\citation{asr-google}
\citation{benzeghiba2007automatic,karpagavalli2016review,arora2012automatic}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Introduction to automatic speech recognition}{19}{section.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}A brief history of Automatic Speech Recognition}{19}{subsection.2.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1.A}Early Days}{19}{subsubsection.2.2.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Example of a standard digit pattern from Davis et al. 1952\relax }}{20}{figure.caption.8}}
\newlabel{Bell}{{2.3}{20}{Example of a standard digit pattern from Davis et al. 1952\relax }{figure.caption.8}{}}
\newlabel{Bell@cref}{{[figure][3][2]2.3}{[1][19][]20}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1.B}The Speech Understanding Research program}{20}{subsubsection.2.2.1.2}}
\citation{klatt1977review}
\citation{klatt1977review}
\citation{klatt1977review}
\citation{first_asr}
\citation{htk_book}
\citation{darpa1992}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Example of a decoding graph from the Harpy system for the sentence "GIVE ME" from \cite  {klatt1977review}\relax }}{22}{figure.caption.9}}
\newlabel{harpy}{{2.4}{22}{Example of a decoding graph from the Harpy system for the sentence "GIVE ME" from \cite {klatt1977review}\relax }{figure.caption.9}{}}
\newlabel{harpy@cref}{{[figure][4][2]2.4}{[1][21][]22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Traditional automatic speech recognition systems}{22}{subsection.2.2.2}}
\citation{hmm-dnn}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Architecture of a HMM-based speech recognition system\relax }}{23}{figure.caption.10}}
\newlabel{HMM-GMM-model}{{2.5}{23}{Architecture of a HMM-based speech recognition system\relax }{figure.caption.10}{}}
\newlabel{HMM-GMM-model@cref}{{[figure][5][2]2.5}{[1][21][]23}}
\citation{kiktova2013comparison}
\citation{kiktova2013comparison}
\citation{mfcc}
\newlabel{equation:asr_0}{{2.1}{24}{Traditional automatic speech recognition systems}{equation.2.2.1}{}}
\newlabel{equation:asr_0@cref}{{[equation][1][2]2.1}{[1][23][]24}}
\newlabel{equation:asr}{{2.2}{24}{Traditional automatic speech recognition systems}{equation.2.2.2}{}}
\newlabel{equation:asr@cref}{{[equation][2][2]2.2}{[1][24][]24}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2.A}Feature extraction}{24}{subsubsection.2.2.2.1}}
\newlabel{subsection:features}{{2.2.2.A}{24}{Feature extraction}{subsubsection.2.2.2.1}{}}
\newlabel{subsection:features@cref}{{[subsubsection][1][2,2,2]2.2.2.A}{[1][24][]24}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Principal block scheme of main speech features for ASR: Melspec, fbanks and MFCC coefficients from \cite  {kiktova2013comparison}\relax }}{25}{figure.caption.11}}
\newlabel{feature_block}{{2.6}{25}{Principal block scheme of main speech features for ASR: Melspec, fbanks and MFCC coefficients from \cite {kiktova2013comparison}\relax }{figure.caption.11}{}}
\newlabel{feature_block@cref}{{[figure][6][2]2.6}{[1][24][]25}}
\newlabel{equation:delta}{{2.3}{25}{Feature extraction}{equation.2.2.3}{}}
\newlabel{equation:delta@cref}{{[equation][3][2]2.3}{[1][25][]25}}
\citation{Dragon_system}
\citation{bizzocchi2017many}
\citation{schwartz1985context}
\citation{bahl1991context}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Three-state Hidden Markov Model for modelling phones\relax }}{26}{figure.caption.12}}
\newlabel{HMM_monophone}{{2.7}{26}{Three-state Hidden Markov Model for modelling phones\relax }{figure.caption.12}{}}
\newlabel{HMM_monophone@cref}{{[figure][7][2]2.7}{[1][26][]26}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2.B}Acoustic model}{26}{subsubsection.2.2.2.2}}
\citation{bourlard2012connectionist,meinedo2003audimus}
\citation{hmm-dnn}
\citation{lang1990time}
\citation{sak2014long}
\citation{waibel2013phoneme}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2.C}Pronunciation model}{27}{subsubsection.2.2.2.3}}
\citation{g2p}
\citation{weide1998carnegie}
\citation{weide1998carnegie}
\citation{n-grams-NLP}
\citation{n-grams-computational_biology}
\citation{n-gram-compression}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Phoneme set and examples of CMU dictionary using 39 phonemes from \cite  {weide1998carnegie}\relax }}{28}{figure.caption.13}}
\newlabel{CMU_DICT}{{2.8}{28}{Phoneme set and examples of CMU dictionary using 39 phonemes from \cite {weide1998carnegie}\relax }{figure.caption.13}{}}
\newlabel{CMU_DICT@cref}{{[figure][8][2]2.8}{[1][28][]28}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2.D}Language model}{28}{subsubsection.2.2.2.4}}
\citation{n-grams-smoothing}
\citation{Bert}
\citation{brown2020language}
\citation{viterbi_decoder}
\citation{valtchev1994novel}
\citation{aubert1995large}
\citation{mohri1997finite,caseiro2002using}
\citation{kaldi}
\citation{richardson1995lattice}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2.E}Decoder}{30}{subsubsection.2.2.2.5}}
\citation{hannun2014deep,hmmvse2e}
\citation{hmm-end2end}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Architecture of an end-to-end speech recognition system\relax }}{31}{figure.caption.14}}
\newlabel{fig:e2e_archi}{{2.9}{31}{Architecture of an end-to-end speech recognition system\relax }{figure.caption.14}{}}
\newlabel{fig:e2e_archi@cref}{{[figure][9][2]2.9}{[1][31][]31}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}End-to-end automatic speech recognition}{31}{subsection.2.2.3}}
\newlabel{section:SOTAE2E}{{2.2.3}{31}{End-to-end automatic speech recognition}{subsection.2.2.3}{}}
\newlabel{section:SOTAE2E@cref}{{[subsection][3][2,2]2.2.3}{[1][31][]31}}
\citation{First_End2End}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3.A}Connectionist Temporal Classification}{32}{subsubsection.2.2.3.1}}
\citation{sutskever2014sequence}
\citation{bahdanau2014neural}
\citation{seq2seq_imagecaption}
\citation{vinyals2015neural}
\citation{nallapati2016abstractive}
\citation{dong2018speech}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3.B}Sequence to sequence}{33}{subsubsection.2.2.3.2}}
\citation{tuske2021limit}
\citation{bermuth2021scribosermo}
\citation{chan2021speechstew}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Automatic Speech Recognition metrics}{34}{subsection.2.2.4}}
\citation{ghai2009exploring,ghai2011addressing}
\citation{Hermansky1990PerceptualLP}
\citation{ghai2009exploring}
\citation{shahnawazuddin2023gammatone}
\citation{feat_ext_from_raw}
\citation{feat_ext_from_raw}
\citation{sincnet_adapt}
\citation{Sincnet}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Children automatic speech recognition}{35}{section.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Feature extraction stage}{35}{subsection.2.3.1}}
\citation{VTLN,VTLN2}
\citation{claus2013survey,potamianos1997automatic}
\citation{potamianos1997combining}
\citation{f0norm,pitchnorm,pitch_adapt_norm,shahnawazuddin2023gammatone}
\citation{formant_norm,kumar2023effect}
\citation{speaking_rate}
\citation{adversarial-adapt1,adversarial-adapt2}
\citation{ivector}
\citation{shivakumar2020transfer}
\citation{prosody_feat,kadyan2023prosody}
\citation{linguistic-children,gale2019improving}
\citation{subwords}
\citation{pronunciation,pronunciation2}
\citation{children_language_model2,Children_language_model}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Pronunciation and language model}{37}{subsection.2.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Design of acoustic models}{37}{subsection.2.3.3}}
\citation{potamianos1997automatic,language_children2}
\citation{bhardwaj2022automatic}
\citation{bhardwaj2022automatic}
\citation{TFchildren}
\citation{tdnn}
\citation{kumar2020leveraging}
\citation{TDNN-F}
\citation{tdnnf-children}
\citation{gelin2021endtoend}
\citation{gelin2021endtoend,sri_end2end,chen2020data,ng2020cuhk}
\citation{chan2015listen}
\citation{targ2016resnet}
\citation{Transformer}
\citation{gelin2021endtoend}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}End-to-end models}{38}{subsection.2.3.4}}
\citation{adultAUGMENT1,adultAUGMENT2}
\citation{nonnative}
\citation{nagano2019data}
\citation{yeung2021fundamental}
\citation{dua2022spectral}
\citation{shuyangdata}
\citation{GANS}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.5}Data augmentation}{39}{subsection.2.3.5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.5.A}Using external data}{39}{subsubsection.2.3.5.1}}
\citation{shen2018natural}
\citation{kim2021conditional}
\citation{laptev2020you}
\citation{wang2021towards}
\citation{liu2003noise,whitenoise,gelin2020babble,couvreur2000use,malek2017robust}
\citation{lo2020ntnu}
\citation{singh2022spectral}
\citation{VTLP}
\citation{specaugment}
\citation{gelin2021simulating}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.5.B}Using available data}{40}{subsubsection.2.3.5.2}}
\citation{pronunciation,asr-improved2,children_language_model2,reviewASRchildren}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.6}Training procedure for children speech recognition}{41}{subsection.2.3.6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.6.A}Transfer learning}{41}{subsubsection.2.3.6.1}}
\newlabel{section:TL}{{2.3.6.A}{41}{Transfer learning}{subsubsection.2.3.6.1}{}}
\newlabel{section:TL@cref}{{[subsubsection][1][2,3,6]2.3.6.A}{[1][41][]41}}
\citation{tfbased,yosinski2014transferable}
\citation{TFchildren}
\citation{TFchildren}
\citation{Bert}
\citation{tfcharacter}
\citation{tfpathology}
\citation{TFchildren}
\newlabel{fig:acoustics_adapt}{{2.10(a)}{42}{Subfigure 2 2.10(a)}{subfigure.2.10.1}{}}
\newlabel{fig:acoustics_adapt@cref}{{[subfigure][1][2,10]2.10(a)}{[1][42][]42}}
\newlabel{sub@fig:acoustics_adapt}{{(a)}{42}{Subfigure 2 2.10(a)\relax }{subfigure.2.10.1}{}}
\newlabel{fig:pronunciation_adapt}{{2.10(b)}{42}{Subfigure 2 2.10(b)}{subfigure.2.10.2}{}}
\newlabel{fig:pronunciation_adapt@cref}{{[subfigure][2][2,10]2.10(b)}{[1][42][]42}}
\newlabel{sub@fig:pronunciation_adapt}{{(b)}{42}{Subfigure 2 2.10(b)\relax }{subfigure.2.10.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Transfer learning approaches. Figures from \cite  {TFchildren}\relax }}{42}{figure.caption.15}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Acoustic adaptation}}}{42}{figure.caption.15}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Pronunciation adaptation}}}{42}{figure.caption.15}}
\citation{TFchildren}
\citation{TransferLF}
\citation{TFchildren}
\citation{Bert}
\citation{tfcharacter}
\citation{tfpathology}
\citation{TFchildren}
\citation{TFchildren}
\citation{TransferLF}
\citation{TFchildren}
\citation{sri_end2end,gelin2021endtoend}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Multilingual approach using each language as a task in a multi-task learning context.\relax }}{44}{figure.caption.16}}
\newlabel{fig:MTL}{{2.11}{44}{Multilingual approach using each language as a task in a multi-task learning context.\relax }{figure.caption.16}{}}
\newlabel{fig:MTL@cref}{{[figure][11][2]2.11}{[1][44][]44}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.6.B}Multi-task learning}{44}{subsubsection.2.3.6.2}}
\newlabel{section:MTL}{{2.3.6.B}{44}{Multi-task learning}{subsubsection.2.3.6.2}{}}
\newlabel{section:MTL@cref}{{[subsubsection][2][2,3,6]2.3.6.B}{[1][44][]44}}
\newlabel{equation:MT}{{2.12}{44}{Multi-task learning}{equation.2.3.12}{}}
\newlabel{equation:MT@cref}{{[equation][12][2]2.12}{[1][44][]44}}
\citation{zhang2018overview}
\citation{multi-nlp}
\citation{mtl_computervision}
\citation{bioinfo}
\citation{MTL-LFMMI}
\citation{abad2020}
\citation{TransferLF}
\citation{2019multi}
\citation{zavaliagkos1998utilizing,ma2006unsupervised}
\citation{radford2023robust}
\citation{sarzynska2021detecting}
\citation{henaff2020data}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.6.C}Self-supervised Learning}{45}{subsubsection.2.3.6.3}}
\citation{baevski2020wav2vec}
\citation{hsu2021hubert}
\citation{riviere2020unsupervised}
\citation{wang2022wav2vec}
\citation{li2021accent}
\citation{xu2021tal}
\citation{jain2023wav2vec2,jain2023adaptation,fan2022draft}
\citation{providence}
\citation{LyonSC}
\citation{cass_child}
\citation{demuth1992acquisition}
\citation{nitk}
\citation{chiede}
\citation{cuchild}
\citation{emochildru}
\citation{hamalainen2013cng}
\citation{ahmed2021auskidtalk}
\citation{yeung2019robotic}
\citation{pfstar}
\citation{yu2021slt}
\citation{pfstar,russell2006pf,pf-star-british}
\citation{ad-child_ru}
\citation{tball}
\citation{speco}
\citation{eshky2019ultrasuite}
\citation{lee1999acoustics}
\citation{khanzadi2022persian}
\citation{letsread}
\citation{cmu}
\citation{CFSC}
\citation{PEREZESPINOSA202055}
\citation{hagen2003children}
\citation{chorec}
\citation{childit2}
\citation{leonard1993tidigits}
\citation{cslu}
\citation{singakids}
\citation{gerosa2006acoustic}
\citation{burkhardt2010database}
\citation{burkhardt2010database}
\citation{JASMIN}
\citation{gerosa2006acoustic}
\citation{gerosa2006acoustic}
\citation{bell2005swedish}
\citation{language_children2}
\citation{SPEECONS}
\citation{linguistic-children}
\citation{MyST}
\citation{hagen2003children}
\citation{etlt}
\citation{grissemann2000zurcher}
\citation{steidl2009automatic}
\citation{bell2003child}
\citation{takemaru}
\citation{callslt}
\citation{letsread}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Children Corpora}{46}{section.2.4}}
\newlabel{section:children_corpora}{{2.4}{46}{Children Corpora}{section.2.4}{}}
\newlabel{section:children_corpora@cref}{{[section][4][2]2.4}{[1][46][]46}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Non-exhaustive comparison of children's speech corpora. This table has been sorted by age range. Blanks indicate unavailable information. Entries highlighted in bold correspond to the corpora used in the experiments presented in this thesis. K: Kindergarden. G: Grade\relax }}{47}{table.caption.17}}
\newlabel{table:children_corpora}{{2.1}{47}{Non-exhaustive comparison of children's speech corpora. This table has been sorted by age range. Blanks indicate unavailable information. Entries highlighted in bold correspond to the corpora used in the experiments presented in this thesis. K: Kindergarden. G: Grade\relax }{table.caption.17}{}}
\newlabel{table:children_corpora@cref}{{[table][1][2]2.1}{[1][46][]47}}
\citation{pfstar}
\citation{etlt}
\citation{cmu}
\citation{sphinx2}
\citation{chorec}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}LETSREAD}{48}{subsection.2.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}PFSTAR\_SWEDISH}{48}{subsection.2.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}ETLTDE}{48}{subsection.2.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.4}CMU\_KIDS}{48}{subsection.2.4.4}}
\citation{MyST}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.5}CHOREC}{49}{subsection.2.4.5}}
\newlabel{subsection:chorec}{{2.4.5}{49}{CHOREC}{subsection.2.4.5}{}}
\newlabel{subsection:chorec@cref}{{[subsection][5][2,4]2.4.5}{[1][48][]49}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.6}MyST}{49}{subsection.2.4.6}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Summary}{49}{section.2.5}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Hybrid models for children automatic speech recognition}{51}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {xchapter}{Hybrid models for children automatic speech recognition}{51}{chapter.3}}
\@writefile{lot}{\contentsline {xchapter}{Hybrid models for children automatic speech recognition}{51}{chapter.3}}
\newlabel{chap:Chapter3}{{3}{52}{Hybrid models for children automatic speech recognition}{chapter.3}{}}
\newlabel{chap:Chapter3@cref}{{[chapter][3][]3}{[1][52][]52}}
\citation{TransferLF}
\citation{big_review_childASR}
\citation{TFchildren,TransferLF,2019multi}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Introduction}{53}{section.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Multi-task and Transfer learning using adult and children data}{53}{section.3.2}}
\newlabel{section:HMMDNNADULT2CHILD}{{3.2}{53}{Multi-task and Transfer learning using adult and children data}{section.3.2}{}}
\newlabel{section:HMMDNNADULT2CHILD@cref}{{[section][2][3]3.2}{[1][53][]53}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Methodology}{53}{subsection.3.2.1}}
\citation{tribus}
\citation{bdpublico}
\citation{kaldi}
\citation{ssc}
\citation{ivector}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Corpus}{54}{subsection.3.2.2}}
\newlabel{sec:corpus}{{3.2.2}{54}{Corpus}{subsection.3.2.2}{}}
\newlabel{sec:corpus@cref}{{[subsection][2][3,2]3.2.2}{[1][54][]54}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Number of utterances and duration of the different corpora for multi-task and transfer learning experiments using adult and children data\relax }}{54}{table.caption.18}}
\newlabel{tab:statistics_exp1}{{3.1}{54}{Number of utterances and duration of the different corpora for multi-task and transfer learning experiments using adult and children data\relax }{table.caption.18}{}}
\newlabel{tab:statistics_exp1@cref}{{[table][1][3]3.1}{[1][54][]54}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Experimental setup}{54}{subsection.3.2.3}}
\newlabel{section:exp_setup}{{3.2.3}{54}{Experimental setup}{subsection.3.2.3}{}}
\newlabel{section:exp_setup@cref}{{[subsection][3][3,2]3.2.3}{[1][54][]54}}
\citation{specaugment}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Results}{55}{subsection.3.2.4}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces WER results using adult data for knowledge transfer methods\relax }}{55}{table.caption.20}}
\newlabel{tab:res_exp1}{{3.2}{55}{WER results using adult data for knowledge transfer methods\relax }{table.caption.20}{}}
\newlabel{tab:res_exp1@cref}{{[table][2][3]3.2}{[1][55][]55}}
\citation{TransferLF,TFchildren}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.5}Summary and discussion}{56}{subsection.3.2.5}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Multi-task and transfer learning using multilingual children data}{57}{section.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Motivation}{57}{subsection.3.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Proposed approach}{57}{subsection.3.3.2}}
\newlabel{section:method}{{3.3.2}{57}{Proposed approach}{subsection.3.3.2}{}}
\newlabel{section:method@cref}{{[subsection][2][3,3]3.3.2}{[1][57][]57}}
\citation{TransferLF}
\citation{2019multi}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Multilingual transfer learning approach. Language-specific layers can be randomly initialized for a language not present during the MTL phase or use the corresponding pre-trained layers in case the target language was present during the MTL phase. Grey blocks are pre-trained during MTL phase.\relax }}{58}{figure.caption.21}}
\newlabel{fig:MLTL1}{{3.1}{58}{Multilingual transfer learning approach. Language-specific layers can be randomly initialized for a language not present during the MTL phase or use the corresponding pre-trained layers in case the target language was present during the MTL phase. Grey blocks are pre-trained during MTL phase.\relax }{figure.caption.21}{}}
\newlabel{fig:MLTL1@cref}{{[figure][1][3]3.1}{[1][58][]58}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Setup}{58}{subsection.3.3.3}}
\newlabel{section:corpus}{{3.3.3}{58}{Setup}{subsection.3.3.3}{}}
\newlabel{section:corpus@cref}{{[subsection][3][3,3]3.3.3}{[1][58][]58}}
\citation{TFchildren}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces Statistics on the different corpora of children's speech.\relax }}{59}{table.caption.22}}
\newlabel{tab:statistics}{{3.3}{59}{Statistics on the different corpora of children's speech.\relax }{table.caption.22}{}}
\newlabel{tab:statistics@cref}{{[table][3][3]3.3}{[1][58][]59}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.4}Multilingual-transfer learning experiment}{59}{subsection.3.3.4}}
\@writefile{lot}{\contentsline {table}{\numberline {3.4}{\ignorespaces WER results of multilingual-transfer learning and cross-lingual experiments. MTL: Multi-Task Learning, TL: Transfer Learning, MLTL: Multilingual Transfer Learning, MLTL-olo: Multilingual Transfer Learning one-language-out\relax }}{59}{table.caption.23}}
\newlabel{tab:result-TL4epoch}{{3.4}{59}{WER results of multilingual-transfer learning and cross-lingual experiments. MTL: Multi-Task Learning, TL: Transfer Learning, MLTL: Multilingual Transfer Learning, MLTL-olo: Multilingual Transfer Learning one-language-out\relax }{table.caption.23}{}}
\newlabel{tab:result-TL4epoch@cref}{{[table][4][3]3.4}{[1][58][]59}}
\citation{TransferLF}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.5}Cross-lingual validation}{60}{subsection.3.3.5}}
\newlabel{section:olo}{{3.3.5}{60}{Cross-lingual validation}{subsection.3.3.5}{}}
\newlabel{section:olo@cref}{{[subsection][5][3,3]3.3.5}{[1][60][]60}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.6}Summary and discussion}{61}{subsection.3.3.6}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Conclusion}{61}{section.3.4}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}End-to-End children automatic speech recognition}{63}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {xchapter}{End-to-End children automatic speech recognition}{63}{chapter.4}}
\@writefile{lot}{\contentsline {xchapter}{End-to-End children automatic speech recognition}{63}{chapter.4}}
\newlabel{chap:4}{{4}{64}{End-to-End children automatic speech recognition}{chapter.4}{}}
\newlabel{chap:4@cref}{{[chapter][4][]4}{[1][64][]64}}
\citation{gelin2021endtoend,sri_end2end,chen2020data,ng2020cuhk}
\citation{luscher2019rwth}
\citation{soltau2016neural}
\citation{battenberg2017exploring}
\citation{vaswani2017attention}
\citation{gelin2021endtoend}
\citation{vaswani2017attention}
\citation{vaswani2017attention}
\citation{vaswani2017attention}
\citation{Bert,brown2020language}
\citation{dosovitskiy2020image}
\citation{dong2018speech}
\citation{bahrini2023chatgpt}
\citation{ramesh2021zero}
\citation{vaswani2017attention}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Introduction}{65}{section.4.1}}
\newlabel{chap:implement}{{4.1}{65}{Introduction}{section.4.1}{}}
\newlabel{chap:implement@cref}{{[section][1][4]4.1}{[1][65][]65}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Transformer model}{65}{section.4.2}}
\newlabel{sec:trans_archi}{{4.2}{65}{Transformer model}{section.4.2}{}}
\newlabel{sec:trans_archi@cref}{{[section][2][4]4.2}{[1][65][]65}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Architecture of the standard Transformer \cite  {vaswani2017attention}. a) scaled dot-product attention, b) multi-head self-attention, c) Transformer-encoder, d) Transformer-decoder.\relax }}{66}{figure.caption.24}}
\newlabel{fig:transformer_archi}{{4.1}{66}{Architecture of the standard Transformer \cite {vaswani2017attention}. a) scaled dot-product attention, b) multi-head self-attention, c) Transformer-encoder, d) Transformer-decoder.\relax }{figure.caption.24}{}}
\newlabel{fig:transformer_archi@cref}{{[figure][1][4]4.1}{[1][65][]66}}
\citation{vaswani2017attention}
\newlabel{equation:attention}{{4.3}{67}{Transformer model}{equation.4.2.3}{}}
\newlabel{equation:attention@cref}{{[equation][3][4]4.3}{[1][67][]67}}
\newlabel{equation:FFN}{{4.6}{68}{Transformer model}{equation.4.2.6}{}}
\newlabel{equation:FFN@cref}{{[equation][6][4]4.6}{[1][68][]68}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Conformer model}{68}{section.4.3}}
\newlabel{sec:conformer}{{4.3}{68}{Conformer model}{section.4.3}{}}
\newlabel{sec:conformer@cref}{{[section][3][4]4.3}{[1][68][]68}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Architecture of a Conformer layer\relax }}{68}{figure.caption.25}}
\newlabel{fig:conformer_archi}{{4.2}{68}{Architecture of a Conformer layer\relax }{figure.caption.25}{}}
\newlabel{fig:conformer_archi@cref}{{[figure][2][4]4.2}{[1][68][]68}}
\citation{bello2019attention,yang2019convolutional}
\citation{gulati2020conformer}
\citation{lu2019understanding}
\citation{wu2020lite}
\citation{dauphin2017language}
\citation{shivakumar2020transfer}
\citation{sri_end2end,gelin2021endtoend}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Convolution module in the context of a conformer layer\relax }}{69}{figure.caption.26}}
\newlabel{fig:convModule}{{4.3}{69}{Convolution module in the context of a conformer layer\relax }{figure.caption.26}{}}
\newlabel{fig:convModule@cref}{{[figure][3][4]4.3}{[1][68][]69}}
\citation{Bert}
\citation{kovaleva-etal-2019-revealing,michel2019sixteen}
\citation{kovaleva-etal-2019-revealing,michel2019sixteen,ye2023partial}
\citation{mccarley2019structured,sanh2019distilbert}
\citation{zheng22d_interspeech}
\citation{shen2021partial,wang2021fine}
\citation{ye2023partial}
\citation{frankle2018lottery}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Understand transfer learning efficacy for transformer based models}{70}{section.4.4}}
\citation{gandhi2023distilwhisper,chang2022distilhubert,peng23c_interspeech}
\citation{shivakumar2020transfer}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Partial Transfer learning}{71}{subsection.4.4.1}}
\citation{speechbrain}
\citation{librispeech}
\citation{gelin2021endtoend}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Experimental setup}{72}{subsection.4.4.2}}
\newlabel{section:methods_chapter4}{{4.4.2}{72}{Experimental setup}{subsection.4.4.2}{}}
\newlabel{section:methods_chapter4@cref}{{[subsection][2][4,4]4.4.2}{[1][71][]72}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}Corpus}{72}{subsection.4.4.3}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces My Science Tutor Children Speech Corpus statistics\relax }}{72}{table.caption.27}}
\newlabel{tab:statistics_myst}{{4.1}{72}{My Science Tutor Children Speech Corpus statistics\relax }{table.caption.27}{}}
\newlabel{tab:statistics_myst@cref}{{[table][1][4]4.1}{[1][71][]72}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.4}Implementation details}{72}{subsection.4.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.5}Encoder-Decoder Transfer learning}{72}{subsection.4.4.5}}
\citation{TFchildren}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Encoder-Decoder experiment\relax }}{73}{table.caption.28}}
\newlabel{tab:EncoderDecoder}{{4.2}{73}{Encoder-Decoder experiment\relax }{table.caption.28}{}}
\newlabel{tab:EncoderDecoder@cref}{{[table][2][4]4.2}{[1][72][]73}}
\newlabel{fig:transferTLTransformer}{{4.4(a)}{73}{Subfigure 4 4.4(a)}{subfigure.4.4.1}{}}
\newlabel{fig:transferTLTransformer@cref}{{[subfigure][1][4,4]4.4(a)}{[1][73][]73}}
\newlabel{sub@fig:transferTLTransformer}{{(a)}{73}{Subfigure 4 4.4(a)\relax }{subfigure.4.4.1}{}}
\newlabel{fig:transferTLConformer}{{4.4(b)}{73}{Subfigure 4 4.4(b)}{subfigure.4.4.2}{}}
\newlabel{fig:transferTLConformer@cref}{{[subfigure][2][4,4]4.4(b)}{[1][73][]73}}
\newlabel{sub@fig:transferTLConformer}{{(b)}{73}{Subfigure 4 4.4(b)\relax }{subfigure.4.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Layers-wise up-way and down-way transfer learning experiment for Transformer and Conformer architecture\relax }}{73}{figure.caption.29}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Results of the transfer learning layer wise for the Transformer model}}}{73}{figure.caption.29}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Results of the transfer learning layer wise for the Conformer model}}}{73}{figure.caption.29}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Modules fine-tuning experiment\relax }}{74}{table.caption.30}}
\newlabel{table:ModulesTL}{{4.3}{74}{Modules fine-tuning experiment\relax }{table.caption.30}{}}
\newlabel{table:ModulesTL@cref}{{[table][3][4]4.3}{[1][74][]74}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.6}Modules Transfer learning}{74}{subsection.4.4.6}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Summary}{76}{section.4.5}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Exploring parameters-efficient transfer learning for end-to-end children ASR}{77}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {xchapter}{Exploring parameters-efficient transfer learning for end-to-end children ASR}{77}{chapter.5}}
\@writefile{lot}{\contentsline {xchapter}{Exploring parameters-efficient transfer learning for end-to-end children ASR}{77}{chapter.5}}
\newlabel{chap:5}{{5}{78}{Exploring parameters-efficient transfer learning for end-to-end children ASR}{chapter.5}{}}
\newlabel{chap:5@cref}{{[chapter][5][]5}{[1][78][]78}}
\citation{brown2020language}
\citation{ramesh2021zero}
\citation{radford2023robust}
\citation{hsu2021hubert}
\citation{Kaplan2020ScalingLF}
\citation{zheng22d_interspeech}
\citation{sri_end2end,gelin2021endtoend}
\citation{houlsby,pfeiffer}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Introduction}{79}{section.5.1}}
\citation{houlsby}
\citation{pfeiffer}
\citation{fan2022draft}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Residual Adapter architecture\relax }}{80}{figure.caption.31}}
\newlabel{fig:Adapter_architecture}{{5.1}{80}{Residual Adapter architecture\relax }{figure.caption.31}{}}
\newlabel{fig:Adapter_architecture@cref}{{[figure][1][5]5.1}{[1][80][]80}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Adapters}{80}{section.5.2}}
\citation{ruckle2020adapterdrop}
\citation{cappellazzo2023parameter,chen2023efficient,10095837}
\citation{kannan2019large,hou2021exploiting,kulkarni2023adapting}
\citation{thomas2022efficient,fan2022draft}
\citation{tomanek2021residual}
\citation{tomanek2021residual}
\citation{fan2022draft}
\citation{he2021towards}
\citation{chen2023efficient}
\citation{10095837}
\citation{chen2023efficient}
\citation{chen2023efficient}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Transformer block with various residual adapter configurations. Normalisation layers are not display in this figure\relax }}{82}{figure.caption.32}}
\newlabel{fig:transformer_config}{{5.2}{82}{Transformer block with various residual adapter configurations. Normalisation layers are not display in this figure\relax }{figure.caption.32}{}}
\newlabel{fig:transformer_config@cref}{{[figure][2][5]5.2}{[1][82][]82}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Conformer block with various residual adapter configurations. Normalisation layers are not display in this figure\relax }}{82}{figure.caption.33}}
\newlabel{fig:conformer_config}{{5.3}{82}{Conformer block with various residual adapter configurations. Normalisation layers are not display in this figure\relax }{figure.caption.33}{}}
\newlabel{fig:conformer_config@cref}{{[figure][3][5]5.3}{[1][82][]82}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Investigating Adapters for children ASR}{82}{section.5.3}}
\citation{snyder2018x}
\citation{speechbrain}
\citation{librispeech}
\citation{glorot2010understanding}
\citation{chen2023efficient}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Implementation details}{84}{section.5.4}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Results of the different Adapters configurations in both Transformer and Conformer.\relax }}{85}{table.caption.34}}
\newlabel{tab:res}{{5.1}{85}{Results of the different Adapters configurations in both Transformer and Conformer.\relax }{table.caption.34}{}}
\newlabel{tab:res@cref}{{[table][1][5]5.1}{[1][84][]85}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Results}{85}{section.5.5}}
\newlabel{sec:results}{{5.5}{85}{Results}{section.5.5}{}}
\newlabel{sec:results@cref}{{[section][5][5]5.5}{[1][84][]85}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.1}Configurations}{85}{subsection.5.5.1}}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Results of the clustering approach.\relax }}{86}{table.caption.35}}
\newlabel{tab:res_clusters}{{5.2}{86}{Results of the clustering approach.\relax }{table.caption.35}{}}
\newlabel{tab:res_clusters@cref}{{[table][2][5]5.2}{[1][86][]86}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.2}Unsupervised Clustering of utterances}{87}{subsection.5.5.2}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Use of synthetic speech as data augmentation}{89}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {xchapter}{Use of synthetic speech as data augmentation}{89}{chapter.6}}
\@writefile{lot}{\contentsline {xchapter}{Use of synthetic speech as data augmentation}{89}{chapter.6}}
\newlabel{chap:6}{{6}{90}{Use of synthetic speech as data augmentation}{chapter.6}{}}
\newlabel{chap:6@cref}{{[chapter][6][]6}{[1][90][]90}}
\citation{asr-review}
\citation{Acoustic_change_children,language_children}
\citation{linguistic-children}
\citation{VTLN}
\citation{pitchnorm}
\citation{adversarial-adapt1}
\citation{liao2015large}
\citation{laptev2020you}
\citation{wang2021towards}
\citation{wang2021towards,hu2022synt++}
\citation{fan2022draft}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Introduction}{91}{section.6.1}}
\citation{laptev2020you}
\citation{casanova2022asr}
\citation{9688218}
\citation{wang2021towards}
\citation{wang2021towards}
\citation{hu2022synt++}
\citation{CTC}
\citation{houlsby}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Related work}{92}{section.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}TTS data augmentation}{92}{subsection.6.2.1}}
\citation{philip2020monolingual}
\citation{tomanek2021residual}
\citation{fan2022draft}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}Adapters}{93}{subsection.6.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Method}{93}{section.6.3}}
\citation{Transformer}
\citation{VIT}
\citation{Bert}
\citation{CTC}
\citation{sri_end2end}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Overview of a) double way fine-tuning and b) Adapter layer architecture\relax }}{94}{figure.caption.36}}
\newlabel{fig:overall}{{6.1}{94}{Overview of a) double way fine-tuning and b) Adapter layer architecture\relax }{figure.caption.36}{}}
\newlabel{fig:overall@cref}{{[figure][1][6]6.1}{[1][93][]94}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}System description}{94}{section.6.4}}
\newlabel{section:SOA}{{6.4}{94}{System description}{section.6.4}{}}
\newlabel{section:SOA@cref}{{[section][4][6]6.4}{[1][94][]94}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.1}Transformer architecture for ASR}{94}{subsection.6.4.1}}
\citation{speechbrain}
\citation{librispeech}
\citation{casanova2022yourtts}
\citation{kong2020hifi}
\citation{casanova2022yourtts}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.2}Multi-speaker text-to-speech: YourTTS}{95}{subsection.6.4.2}}
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Experimental setup}{95}{section.6.5}}
\newlabel{section:methods}{{6.5}{95}{Experimental setup}{section.6.5}{}}
\newlabel{section:methods@cref}{{[section][5][6]6.5}{[1][95][]95}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.1}Real speech corpus}{95}{subsection.6.5.1}}
\@writefile{lot}{\contentsline {table}{\numberline {6.1}{\ignorespaces My Science Tutor Children Speech Corpus statistics\relax }}{95}{table.caption.37}}
\newlabel{tab:statistics}{{6.1}{95}{My Science Tutor Children Speech Corpus statistics\relax }{table.caption.37}{}}
\newlabel{tab:statistics@cref}{{[table][1][6]6.1}{[1][95][]95}}
\citation{hu2022synt++}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.2}Synthetic data}{96}{subsection.6.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.3}Experiments}{96}{subsection.6.5.3}}
\citation{wang2021towards}
\@writefile{lot}{\contentsline {table}{\numberline {6.2}{\ignorespaces Results of the different approaches (in WER).\relax }}{97}{table.caption.38}}
\newlabel{tab:res}{{6.2}{97}{Results of the different approaches (in WER).\relax }{table.caption.38}{}}
\newlabel{tab:res@cref}{{[table][2][6]6.2}{[1][97][]97}}
\@writefile{toc}{\contentsline {section}{\numberline {6.6}Results and discussion}{97}{section.6.6}}
\newlabel{section:exp}{{6.6}{97}{Results and discussion}{section.6.6}{}}
\newlabel{section:exp@cref}{{[section][6][6]6.6}{[1][97][]97}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.1}Comparison with existing approaches}{97}{subsection.6.6.1}}
\@writefile{lot}{\contentsline {table}{\numberline {6.3}{\ignorespaces Results of the different number of hours in our Adapter double-way approach with \textit  {Synth$_2$} data\relax }}{98}{table.caption.39}}
\newlabel{tab:hours}{{6.3}{98}{Results of the different number of hours in our Adapter double-way approach with \textit {Synth$_2$} data\relax }{table.caption.39}{}}
\newlabel{tab:hours@cref}{{[table][3][6]6.3}{[1][97][]98}}
\@writefile{lot}{\contentsline {table}{\numberline {6.4}{\ignorespaces Results of the different configurations of Adapter double-way approach on 300h of \textit  {Synth$_2$}\relax }}{98}{table.caption.40}}
\newlabel{tab:config}{{6.4}{98}{Results of the different configurations of Adapter double-way approach on 300h of \textit {Synth$_2$}\relax }{table.caption.40}{}}
\newlabel{tab:config@cref}{{[table][4][6]6.4}{[1][98][]98}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.2}Effect of the number of hours}{98}{subsection.6.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.3}Effect of the Adapters hyper-parameters}{98}{subsection.6.6.3}}
\citation{pfeiffer2020adapterfusion}
\citation{gong2022layer}
\citation{van2017neural}
\citation{wang2021towards}
\citation{cooper2020zero,kim2021conditional}
\citation{wang2021towards}
\citation{hu2022synt++}
\citation{goodfellow2014generative}
\@writefile{toc}{\contentsline {section}{\numberline {6.7}Extension to Conformer architecture}{99}{section.6.7}}
\@writefile{toc}{\contentsline {section}{\numberline {6.8}Conclusions and future work}{99}{section.6.8}}
\newlabel{section:conclusions_tts}{{6.8}{99}{Conclusions and future work}{section.6.8}{}}
\newlabel{section:conclusions_tts@cref}{{[section][8][6]6.8}{[1][99][]99}}
\@writefile{toc}{\contentsline {section}{\numberline {6.9}Ongoing and future work}{99}{section.6.9}}
\newlabel{section:ongoing}{{6.9}{99}{Ongoing and future work}{section.6.9}{}}
\newlabel{section:ongoing@cref}{{[section][9][6]6.9}{[1][99][]99}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Parameters efficent transfer learning alternative approaches}{101}{chapter.7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {xchapter}{Parameters efficent transfer learning alternative approaches}{101}{chapter.7}}
\@writefile{lot}{\contentsline {xchapter}{Parameters efficent transfer learning alternative approaches}{101}{chapter.7}}
\newlabel{chap:7}{{7}{102}{Parameters efficent transfer learning alternative approaches}{chapter.7}{}}
\newlabel{chap:7@cref}{{[chapter][7][]7}{[1][102][]102}}
\citation{he2022towards}
\citation{mao-etal-2022-unipelt}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Introduction}{103}{section.7.1}}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Exploring literature alternatives}{103}{section.7.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.1}Scaled Adapters}{103}{subsection.7.2.1}}
\citation{gulati2020conformer}
\citation{yang23p_interspeech}
\citation{muthuchamyselvaraj23_interspeech}
\citation{jie2022convolutional}
\citation{jie2022convolutional}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.2}Convolution based Adapters}{104}{subsection.7.2.2}}
\citation{li2023evaluating}
\citation{hu2018squeeze}
\citation{ben-zaken-etal-2022-bitfit}
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces Th architecture of the ConvPass adapter. $k$ is the kernel size of the 1D convolution. All Convoluation are depth-wise convolution.\relax }}{105}{figure.caption.41}}
\newlabel{fig:convpass}{{7.1}{105}{Th architecture of the ConvPass adapter. $k$ is the kernel size of the 1D convolution. All Convoluation are depth-wise convolution.\relax }{figure.caption.41}{}}
\newlabel{fig:convpass@cref}{{[figure][1][7]7.1}{[1][104][]105}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.3}BitFit}{105}{subsection.7.2.3}}
\citation{lian2022scaling}
\citation{wu2018group,huang2017arbitrary}
\citation{sun2016return}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.4}Scale and Shift features}{106}{subsection.7.2.4}}
\citation{ben-zaken-etal-2022-bitfit}
\citation{fu-etal-2022-adapterbias}
\@writefile{lof}{\contentsline {figure}{\numberline {7.2}{\ignorespaces  AdapterBias, consisting of a linear layer $L_\alpha $ and a vector $\mathcal  {V}$, is added after the second feed-forward layer only in each FFN module.\relax }}{107}{figure.caption.42}}
\newlabel{fig:AdapterBias}{{7.2}{107}{AdapterBias, consisting of a linear layer $L_\alpha $ and a vector $\mathcal {V}$, is added after the second feed-forward layer only in each FFN module.\relax }{figure.caption.42}{}}
\newlabel{fig:AdapterBias@cref}{{[figure][2][7]7.2}{[1][107][]107}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.5}AdapterBias}{107}{subsection.7.2.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.3}{\ignorespaces Different paramter efficent procedure for children ASR in conformer model\relax }}{108}{figure.caption.43}}
\newlabel{fig:adapter_compared_withoutWide}{{7.3}{108}{Different paramter efficent procedure for children ASR in conformer model\relax }{figure.caption.43}{}}
\newlabel{fig:adapter_compared_withoutWide@cref}{{[figure][3][7]7.3}{[1][108][]108}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.6}Results of the different PETL methods}{108}{subsection.7.2.6}}
\citation{li2023evaluating}
\citation{cappellazzo2023parameter}
\@writefile{lot}{\contentsline {table}{\numberline {7.1}{\ignorespaces Model Performance and Parameters\relax }}{109}{table.caption.44}}
\newlabel{tab:PETL_alternatives}{{7.1}{109}{Model Performance and Parameters\relax }{table.caption.44}{}}
\newlabel{tab:PETL_alternatives@cref}{{[table][1][7]7.1}{[1][108][]109}}
\@writefile{toc}{\contentsline {section}{\numberline {7.3}New type of Adapter: The Shared Adapter}{109}{section.7.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.1}Motivation}{109}{subsection.7.3.1}}
\citation{pires2023one}
\citation{geva2020transformer}
\citation{pires2023one}
\@writefile{lof}{\contentsline {figure}{\numberline {7.4}{\ignorespaces Shared-Adapter setup in a Conformer model\relax }}{110}{figure.caption.45}}
\newlabel{fig:Shared_adapter}{{7.4}{110}{Shared-Adapter setup in a Conformer model\relax }{figure.caption.45}{}}
\newlabel{fig:Shared_adapter@cref}{{[figure][4][7]7.4}{[1][109][]110}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.2}Experimental setup}{111}{subsection.7.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.3}Results}{111}{subsection.7.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.5}{\ignorespaces Different paramter efficent procedure for children ASR in conformer model with shared-Adapters\relax }}{112}{figure.caption.46}}
\newlabel{fig:adapter_compared}{{7.5}{112}{Different paramter efficent procedure for children ASR in conformer model with shared-Adapters\relax }{figure.caption.46}{}}
\newlabel{fig:adapter_compared@cref}{{[figure][5][7]7.5}{[1][111][]112}}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Conclusions}{113}{chapter.8}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {xchapter}{Conclusions}{113}{chapter.8}}
\@writefile{lot}{\contentsline {xchapter}{Conclusions}{113}{chapter.8}}
\newlabel{chap:8}{{8}{114}{Conclusions}{chapter.8}{}}
\newlabel{chap:8@cref}{{[chapter][8][]8}{[1][114][]114}}
\bibstyle{IEEEtran}
\bibdata{./Thesis-MSc-Bibliography}
\bibcite{reviewASRchildren}{1}
\bibcite{Acoustic_change_children}{2}
\bibcite{klatt1977review}{3}
\bibcite{kiktova2013comparison}{4}
\bibcite{weide1998carnegie}{5}
\bibcite{TFchildren}{6}
\bibcite{vaswani2017attention}{7}
\bibcite{levelt1993speaking}{8}
\bibcite{black2015communication}{9}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{115}{chapter.8}}
\@writefile{@@@}{\chapterbegin }
\bibcite{langbecker2020long}{10}
\bibcite{hilty2015new}{11}
\bibcite{barnett2011utilizing}{12}
\bibcite{hughes2019increasing}{13}
\bibcite{mendoza2022added}{14}
\bibcite{brewer2013using}{15}
\bibcite{childrenSpeechWorse}{16}
\bibcite{li2023asr}{17}
\bibcite{li2014overview}{18}
\bibcite{king2017robust}{19}
\bibcite{first_vowel_study}{20}
\bibcite{why_children_speech_no_working}{21}
\bibcite{segment_definition}{22}
\bibcite{moats2000speech}{23}
\bibcite{language_children}{24}
\bibcite{clark1977psychology}{25}
\bibcite{language_children2}{26}
\bibcite{Children_language_model}{27}
\bibcite{children_language_model2}{28}
\bibcite{radford2023robust}{29}
\bibcite{librispeech}{30}
\bibcite{chen2021gigaspeech}{31}
\bibcite{MyST}{32}
\bibcite{singakids}{33}
\bibcite{ahmed2021auskidtalk}{34}
\bibcite{cmu}{35}
\bibcite{cslu}{36}
\bibcite{pf-star-british}{37}
\bibcite{asr-google}{38}
\bibcite{benzeghiba2007automatic}{39}
\bibcite{karpagavalli2016review}{40}
\bibcite{arora2012automatic}{41}
\bibcite{first_asr}{42}
\bibcite{htk_book}{43}
\bibcite{darpa1992}{44}
\bibcite{hmm-dnn}{45}
\bibcite{mfcc}{46}
\bibcite{Dragon_system}{47}
\bibcite{bizzocchi2017many}{48}
\bibcite{schwartz1985context}{49}
\bibcite{bahl1991context}{50}
\bibcite{bourlard2012connectionist}{51}
\bibcite{meinedo2003audimus}{52}
\bibcite{lang1990time}{53}
\bibcite{sak2014long}{54}
\bibcite{waibel2013phoneme}{55}
\bibcite{g2p}{56}
\bibcite{n-grams-NLP}{57}
\bibcite{n-grams-computational_biology}{58}
\bibcite{n-gram-compression}{59}
\bibcite{n-grams-smoothing}{60}
\bibcite{Bert}{61}
\bibcite{brown2020language}{62}
\bibcite{viterbi_decoder}{63}
\bibcite{valtchev1994novel}{64}
\bibcite{aubert1995large}{65}
\bibcite{mohri1997finite}{66}
\bibcite{caseiro2002using}{67}
\bibcite{kaldi}{68}
\bibcite{richardson1995lattice}{69}
\bibcite{hannun2014deep}{70}
\bibcite{hmmvse2e}{71}
\bibcite{hmm-end2end}{72}
\bibcite{First_End2End}{73}
\bibcite{sutskever2014sequence}{74}
\bibcite{bahdanau2014neural}{75}
\bibcite{seq2seq_imagecaption}{76}
\bibcite{vinyals2015neural}{77}
\bibcite{nallapati2016abstractive}{78}
\bibcite{dong2018speech}{79}
\bibcite{tuske2021limit}{80}
\bibcite{bermuth2021scribosermo}{81}
\bibcite{chan2021speechstew}{82}
\bibcite{ghai2009exploring}{83}
\bibcite{ghai2011addressing}{84}
\bibcite{Hermansky1990PerceptualLP}{85}
\bibcite{shahnawazuddin2023gammatone}{86}
\bibcite{feat_ext_from_raw}{87}
\bibcite{sincnet_adapt}{88}
\bibcite{Sincnet}{89}
\bibcite{VTLN}{90}
\bibcite{VTLN2}{91}
\bibcite{claus2013survey}{92}
\bibcite{potamianos1997automatic}{93}
\bibcite{potamianos1997combining}{94}
\bibcite{f0norm}{95}
\bibcite{pitchnorm}{96}
\bibcite{pitch_adapt_norm}{97}
\bibcite{formant_norm}{98}
\bibcite{kumar2023effect}{99}
\bibcite{speaking_rate}{100}
\bibcite{adversarial-adapt1}{101}
\bibcite{adversarial-adapt2}{102}
\bibcite{ivector}{103}
\bibcite{shivakumar2020transfer}{104}
\bibcite{prosody_feat}{105}
\bibcite{kadyan2023prosody}{106}
\bibcite{linguistic-children}{107}
\bibcite{gale2019improving}{108}
\bibcite{subwords}{109}
\bibcite{pronunciation}{110}
\bibcite{pronunciation2}{111}
\bibcite{bhardwaj2022automatic}{112}
\bibcite{tdnn}{113}
\bibcite{kumar2020leveraging}{114}
\bibcite{TDNN-F}{115}
\bibcite{tdnnf-children}{116}
\bibcite{gelin2021endtoend}{117}
\bibcite{sri_end2end}{118}
\bibcite{chen2020data}{119}
\bibcite{ng2020cuhk}{120}
\bibcite{chan2015listen}{121}
\bibcite{targ2016resnet}{122}
\bibcite{Transformer}{123}
\bibcite{adultAUGMENT1}{124}
\bibcite{adultAUGMENT2}{125}
\bibcite{nonnative}{126}
\bibcite{nagano2019data}{127}
\bibcite{yeung2021fundamental}{128}
\bibcite{dua2022spectral}{129}
\bibcite{shuyangdata}{130}
\bibcite{GANS}{131}
\bibcite{shen2018natural}{132}
\bibcite{kim2021conditional}{133}
\bibcite{laptev2020you}{134}
\bibcite{wang2021towards}{135}
\bibcite{liu2003noise}{136}
\bibcite{whitenoise}{137}
\bibcite{gelin2020babble}{138}
\bibcite{couvreur2000use}{139}
\bibcite{malek2017robust}{140}
\bibcite{lo2020ntnu}{141}
\bibcite{singh2022spectral}{142}
\bibcite{VTLP}{143}
\bibcite{specaugment}{144}
\bibcite{gelin2021simulating}{145}
\bibcite{asr-improved2}{146}
\bibcite{tfbased}{147}
\bibcite{yosinski2014transferable}{148}
\bibcite{tfcharacter}{149}
\bibcite{tfpathology}{150}
\bibcite{TransferLF}{151}
\bibcite{zhang2018overview}{152}
\bibcite{multi-nlp}{153}
\bibcite{mtl_computervision}{154}
\bibcite{bioinfo}{155}
\bibcite{MTL-LFMMI}{156}
\bibcite{abad2020}{157}
\bibcite{2019multi}{158}
\bibcite{zavaliagkos1998utilizing}{159}
\bibcite{ma2006unsupervised}{160}
\bibcite{sarzynska2021detecting}{161}
\bibcite{henaff2020data}{162}
\bibcite{baevski2020wav2vec}{163}
\bibcite{hsu2021hubert}{164}
\bibcite{riviere2020unsupervised}{165}
\bibcite{wang2022wav2vec}{166}
\bibcite{li2021accent}{167}
\bibcite{xu2021tal}{168}
\bibcite{jain2023wav2vec2}{169}
\bibcite{jain2023adaptation}{170}
\bibcite{fan2022draft}{171}
\bibcite{providence}{172}
\bibcite{LyonSC}{173}
\bibcite{cass_child}{174}
\bibcite{demuth1992acquisition}{175}
\bibcite{nitk}{176}
\bibcite{chiede}{177}
\bibcite{cuchild}{178}
\bibcite{emochildru}{179}
\bibcite{hamalainen2013cng}{180}
\bibcite{yeung2019robotic}{181}
\bibcite{pfstar}{182}
\bibcite{yu2021slt}{183}
\bibcite{russell2006pf}{184}
\bibcite{ad-child_ru}{185}
\bibcite{tball}{186}
\bibcite{speco}{187}
\bibcite{eshky2019ultrasuite}{188}
\bibcite{lee1999acoustics}{189}
\bibcite{khanzadi2022persian}{190}
\bibcite{letsread}{191}
\bibcite{CFSC}{192}
\bibcite{PEREZESPINOSA202055}{193}
\bibcite{hagen2003children}{194}
\bibcite{chorec}{195}
\bibcite{childit2}{196}
\bibcite{leonard1993tidigits}{197}
\bibcite{gerosa2006acoustic}{198}
\bibcite{burkhardt2010database}{199}
\bibcite{JASMIN}{200}
\bibcite{bell2005swedish}{201}
\bibcite{SPEECONS}{202}
\bibcite{etlt}{203}
\bibcite{grissemann2000zurcher}{204}
\bibcite{steidl2009automatic}{205}
\bibcite{bell2003child}{206}
\bibcite{takemaru}{207}
\bibcite{callslt}{208}
\bibcite{sphinx2}{209}
\bibcite{big_review_childASR}{210}
\bibcite{tribus}{211}
\bibcite{bdpublico}{212}
\bibcite{ssc}{213}
\bibcite{luscher2019rwth}{214}
\bibcite{soltau2016neural}{215}
\bibcite{battenberg2017exploring}{216}
\bibcite{dosovitskiy2020image}{217}
\bibcite{bahrini2023chatgpt}{218}
\bibcite{ramesh2021zero}{219}
\bibcite{bello2019attention}{220}
\bibcite{yang2019convolutional}{221}
\bibcite{gulati2020conformer}{222}
\bibcite{lu2019understanding}{223}
\bibcite{wu2020lite}{224}
\bibcite{dauphin2017language}{225}
\bibcite{kovaleva-etal-2019-revealing}{226}
\bibcite{michel2019sixteen}{227}
\bibcite{ye2023partial}{228}
\bibcite{mccarley2019structured}{229}
\bibcite{sanh2019distilbert}{230}
\bibcite{zheng22d_interspeech}{231}
\bibcite{shen2021partial}{232}
\bibcite{wang2021fine}{233}
\bibcite{frankle2018lottery}{234}
\bibcite{gandhi2023distilwhisper}{235}
\bibcite{chang2022distilhubert}{236}
\bibcite{peng23c_interspeech}{237}
\bibcite{speechbrain}{238}
\bibcite{Kaplan2020ScalingLF}{239}
\bibcite{houlsby}{240}
\bibcite{pfeiffer}{241}
\bibcite{ruckle2020adapterdrop}{242}
\bibcite{cappellazzo2023parameter}{243}
\bibcite{chen2023efficient}{244}
\bibcite{10095837}{245}
\bibcite{kannan2019large}{246}
\bibcite{hou2021exploiting}{247}
\bibcite{kulkarni2023adapting}{248}
\bibcite{thomas2022efficient}{249}
\bibcite{tomanek2021residual}{250}
\bibcite{he2021towards}{251}
\bibcite{snyder2018x}{252}
\bibcite{glorot2010understanding}{253}
\bibcite{hu2022synt++}{254}
\bibcite{philip2020monolingual}{255}
\bibcite{pfeiffer2020adapterfusion}{256}
\bibcite{gong2022layer}{257}
\bibcite{van2017neural}{258}
\bibcite{cooper2020zero}{259}
\bibcite{goodfellow2014generative}{260}
\bibcite{he2022towards}{261}
\bibcite{mao-etal-2022-unipelt}{262}
\bibcite{yang23p_interspeech}{263}
\bibcite{muthuchamyselvaraj23_interspeech}{264}
\bibcite{jie2022convolutional}{265}
\bibcite{li2023evaluating}{266}
\bibcite{hu2018squeeze}{267}
\bibcite{ben-zaken-etal-2022-bitfit}{268}
\bibcite{lian2022scaling}{269}
\bibcite{wu2018group}{270}
\bibcite{huang2017arbitrary}{271}
\bibcite{sun2016return}{272}
\bibcite{fu-etal-2022-adapterbias}{273}
\bibcite{pires2023one}{274}
\bibcite{geva2020transformer}{275}
\bibcite{hauptman2019identifying}{276}
\bibcite{botelho2019speech}{277}
\bibcite{laaridh17_interspeech}{278}
\bibcite{pappagari2020x}{279}
\bibcite{perero2019modeling}{280}
\bibcite{zargarbashi2019multi}{281}
\bibcite{botelho2020pathological}{282}
\bibcite{snyder2017deep}{283}
\bibcite{kenny2007joint}{284}
\bibcite{reynolds2000speaker}{285}
\bibcite{dehak2010front}{286}
\bibcite{hamalainen2014easr}{287}
\bibcite{pinto2016dysarthria}{288}
\bibcite{orozco2014new}{289}
\bibcite{pompili2017automatic}{290}
\bibcite{eyben2015geneva}{291}
\bibcite{eyben2013recent}{292}
\bibcite{pompili2020inesc}{293}
\bibcite{yang21c_interspeech}{294}
\bibcite{chang2021exploration}{295}
\bibcite{librilight}{296}
\bibcite{tera}{297}
\bibcite{chi2021audio}{298}
\bibcite{mcauliffe2017montreal}{299}
\bibcite{phdthesis}{300}
\bibcite{babu2021xlsr}{301}
\citation{hauptman2019identifying,botelho2019speech}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Pathological speech detection through pre-trained models}{143}{appendix.A}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {xchapter}{Pathological speech detection through pre-trained models}{143}{appendix.A}}
\@writefile{lot}{\contentsline {xchapter}{Pathological speech detection through pre-trained models}{143}{appendix.A}}
\newlabel{chapter:appendixA}{{A}{143}{Pathological speech detection through pre-trained models}{appendix.A}{}}
\newlabel{chapter:appendixA@cref}{{[appendix][1][2147483647]A}{[1][143][]143}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}Introduction}{143}{section.A.1}}
\citation{hauptman2019identifying}
\citation{laaridh17_interspeech}
\citation{hauptman2019identifying}
\citation{snyder2018x}
\citation{pappagari2020x}
\citation{perero2019modeling}
\citation{zargarbashi2019multi}
\citation{botelho2020pathological}
\citation{snyder2017deep}
\citation{kenny2007joint}
\citation{reynolds2000speaker}
\citation{dehak2010front}
\citation{hauptman2019identifying}
\@writefile{toc}{\contentsline {section}{\numberline {A.2}Pathological speech detection using x-vector embeddings}{144}{section.A.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.1}Introduction}{144}{subsection.A.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.2}Speaker embeddings: i-vector and x-vector}{144}{subsection.A.2.2}}
\citation{hamalainen2014easr}
\citation{pinto2016dysarthria}
\citation{orozco2014new}
\citation{botelho2019speech}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.3}Experimental setup}{145}{subsection.A.2.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.2.3.A}Corpora}{145}{subsubsection.A.2.3.1}}
\citation{pompili2017automatic}
\citation{eyben2015geneva}
\citation{botelho2019speech}
\citation{eyben2013recent}
\citation{kaldi}
\@writefile{lot}{\contentsline {table}{\numberline {A.1}{\ignorespaces Description of Speakers and Segments\relax }}{146}{table.caption.48}}
\newlabel{tab:xvect_data}{{A.1}{146}{Description of Speakers and Segments\relax }{table.caption.48}{}}
\newlabel{tab:xvect_data@cref}{{[table][1][2147483647,1]A.1}{[1][145][]146}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.2.3.B}Knowledge based features}{146}{subsubsection.A.2.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.2.3.C}Speaker embeddings}{146}{subsubsection.A.2.3.3}}
\@writefile{lot}{\contentsline {table}{\numberline {A.2}{\ignorespaces X-vector network Description\relax }}{146}{table.caption.49}}
\newlabel{tab:xvect_description}{{A.2}{146}{X-vector network Description\relax }{table.caption.49}{}}
\newlabel{tab:xvect_description@cref}{{[table][2][2147483647,1]A.2}{[1][146][]146}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.4}Results}{147}{subsection.A.2.4}}
\@writefile{lot}{\contentsline {table}{\numberline {A.3}{\ignorespaces Results of the different tasks\relax }}{147}{table.caption.50}}
\newlabel{tab:xvect_results}{{A.3}{147}{Results of the different tasks\relax }{table.caption.50}{}}
\newlabel{tab:xvect_results@cref}{{[table][3][2147483647,1]A.3}{[1][147][]147}}
\citation{pompili2020inesc}
\citation{Bert}
\@writefile{toc}{\contentsline {section}{\numberline {A.3}The INESC-ID Multi-Modal System for the ADReSS 2020 Challenge}{148}{section.A.3}}
\@writefile{toc}{\contentsline {section}{\numberline {A.4}Transfer Learning-Based Cough Representations for Automatic Detection of COVID-19}{148}{section.A.4}}
\citation{baevski2020wav2vec}
\citation{yang21c_interspeech,chang2021exploration}
\citation{fan2022draft,jain2023wav2vec2,wang2021fine,li2021accent}
\citation{fan2022draft}
\citation{yang21c_interspeech,chang2021exploration}
\@writefile{toc}{\contentsline {chapter}{\numberline {B}Sefl-supervised learning as feature extractor for children's ASR}{149}{appendix.B}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {xchapter}{Sefl-supervised learning as feature extractor for children's ASR}{149}{appendix.B}}
\@writefile{lot}{\contentsline {xchapter}{Sefl-supervised learning as feature extractor for children's ASR}{149}{appendix.B}}
\newlabel{chapter:appendixB}{{B}{149}{Sefl-supervised learning as feature extractor for children's ASR}{appendix.B}{}}
\newlabel{chapter:appendixB@cref}{{[appendix][2][2147483647]B}{[1][149][]149}}
\@writefile{toc}{\contentsline {section}{\numberline {B.1}Introduction}{149}{section.B.1}}
\@writefile{toc}{\contentsline {section}{\numberline {B.2}Self-supervised pre-trained models}{150}{section.B.2}}
\@writefile{lot}{\contentsline {table}{\numberline {B.1}{\ignorespaces Overview of different SSL architectures used in this chapter\relax }}{150}{table.caption.51}}
\newlabel{tab:SSL_models}{{B.1}{150}{Overview of different SSL architectures used in this chapter\relax }{table.caption.51}{}}
\newlabel{tab:SSL_models@cref}{{[table][1][2147483647,2]B.1}{[1][150][]150}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2.1}Generative modeling}{150}{subsection.B.2.1}}
\citation{baevski2020wav2vec}
\citation{baevski2020wav2vec}
\citation{hsu2021hubert}
\citation{hsu2021hubert}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2.2}Discriminative modeling}{151}{subsection.B.2.2}}
\newlabel{fig:wav2vec2}{{B.1(a)}{151}{Subfigure B B.1(a)}{subfigure.B.1.1}{}}
\newlabel{fig:wav2vec2@cref}{{[subfigure][1][2147483647,2,1]B.1(a)}{[1][151][]151}}
\newlabel{sub@fig:wav2vec2}{{(a)}{151}{Subfigure B B.1(a)\relax }{subfigure.B.1.1}{}}
\newlabel{fig:Hubert}{{B.1(b)}{151}{Subfigure B B.1(b)}{subfigure.B.1.2}{}}
\newlabel{fig:Hubert@cref}{{[subfigure][2][2147483647,2,1]B.1(b)}{[1][151][]151}}
\newlabel{sub@fig:Hubert}{{(b)}{151}{Subfigure B B.1(b)\relax }{subfigure.B.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.1}{\ignorespaces Overview of the discriminative SSL Wav2vec2 and HuBert models\relax }}{151}{figure.caption.52}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Illustration of the Wav2vec2 architecture taken from \cite {baevski2020wav2vec}}}}{151}{figure.caption.52}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Illustration of the HuBert architecture taken from \cite {hsu2021hubert}}}}{151}{figure.caption.52}}
\citation{librispeech}
\citation{librilight}
\citation{MyST}
\citation{tera}
\citation{chi2021audio}
\citation{chang2022distilhubert}
\citation{tera}
\citation{chi2021audio}
\citation{chang2022distilhubert}
\@writefile{toc}{\contentsline {section}{\numberline {B.3}Experimental setup}{152}{section.B.3}}
\@writefile{lot}{\contentsline {table}{\numberline {B.2}{\ignorespaces My Science Tutor Children Speech Subset Corpus statistics\relax }}{152}{table.caption.53}}
\newlabel{tab:ssl_myst}{{B.2}{152}{My Science Tutor Children Speech Subset Corpus statistics\relax }{table.caption.53}{}}
\newlabel{tab:ssl_myst@cref}{{[table][2][2147483647,2]B.2}{[1][152][]152}}
\citation{mcauliffe2017montreal}
\@writefile{lot}{\contentsline {table}{\numberline {B.3}{\ignorespaces Results without language model of different Self-supervised models as feature extractors\relax }}{153}{table.caption.54}}
\newlabel{tab:ssl}{{B.3}{153}{Results without language model of different Self-supervised models as feature extractors\relax }{table.caption.54}{}}
\newlabel{tab:ssl@cref}{{[table][3][2147483647,2]B.3}{[1][152][]153}}
\@writefile{toc}{\contentsline {section}{\numberline {B.4}Results}{153}{section.B.4}}
\@writefile{toc}{\contentsline {section}{\numberline {B.5}Analysis of the extracted features}{153}{section.B.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.2}{\ignorespaces (a) Fbanks (b) TERA (c) Wav2Vec 2.0 (d) HuBERT   T-SNE plot of the different extracted features using the same speech data using phoneme labels\relax }}{154}{figure.caption.55}}
\newlabel{fig:tsne_ssl}{{B.2}{154}{(a) Fbanks (b) TERA (c) Wav2Vec 2.0 (d) HuBERT \\ T-SNE plot of the different extracted features using the same speech data using phoneme labels\relax }{figure.caption.55}{}}
\newlabel{fig:tsne_ssl@cref}{{[figure][2][2147483647,2]B.2}{[1][153][]154}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{154}{figure.caption.55}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{154}{figure.caption.55}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{154}{figure.caption.55}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {}}}{154}{figure.caption.55}}
\citation{phdthesis}
\citation{babu2021xlsr}
\global\mtcsecondpartfalse
\@writefile{toc}{\contentsline {section}{\numberline {B.6}Conclusions and future work}{155}{section.B.6}}
