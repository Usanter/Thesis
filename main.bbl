% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{100}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{klatt1977review}
D.~H. Klatt, ``Review of the {ARPA} speech understanding project,'' \emph{The
  Journal of the Acoustical Society of America}, vol.~62, no.~6, pp.
  1345--1366, 1977.

\bibitem{kiktova2013comparison}
E.~Kiktova, M.~Lojka, M.~Pleva, J.~Juhar, and A.~Cizmar, ``Comparison of
  different feature types for acoustic event detection system,'' in
  \emph{Multimedia Communications, Services and Security: 6th International
  Conference, MCSS 2013, Krakow, Poland, June 6-7, 2013. Proceedings 6}.\hskip
  1em plus 0.5em minus 0.4em\relax Springer, 2013, pp. 288--297.

\bibitem{weide1998carnegie}
R.~Weide \emph{et~al.}, ``The carnegie mellon pronouncing dictionary,''
  \emph{release 0.6, www. cs. cmu. edu}, 1998.

\bibitem{reviewASRchildren}
\BIBentryALTinterwordspacing
M.~Gerosa, D.~Giuliani, S.~Narayanan, and A.~Potamianos, ``A review of {ASR}
  technologies for children's speech,'' in \emph{Proceedings of the 2nd
  Workshop on Child, Computer and Interaction}, ser. WOCCI '09.\hskip 1em plus
  0.5em minus 0.4em\relax New York, NY, USA: Association for Computing
  Machinery, 2009. [Online]. Available:
  \url{https://doi.org/10.1145/1640377.1640384}
\BIBentrySTDinterwordspacing

\bibitem{Acoustic_change_children}
\BIBentryALTinterwordspacing
S.~Lee, A.~Potamianos, and S.~Narayanan, ``Acoustics of children’s speech:
  Developmental changes of temporal and spectral parameters,'' \emph{The
  Journal of the Acoustical Society of America}, vol. 105, no.~3, pp.
  1455--1468, 1999. [Online]. Available: \url{https://doi.org/10.1121/1.426686}
\BIBentrySTDinterwordspacing

\bibitem{TFchildren}
\BIBentryALTinterwordspacing
P.~{Gurunath Shivakumar} and P.~Georgiou, ``Transfer learning from adult to
  children for speech recognition: Evaluation, analysis and recommendations,''
  \emph{Computer Speech \& Language}, vol.~63, p. 101077, 2020. [Online].
  Available:
  \url{https://www.sciencedirect.com/science/article/pii/S0885230820300103}
\BIBentrySTDinterwordspacing

\bibitem{tdnnf-children}
F.~Wu, L.~P. Garc{\'\i}a-Perera, D.~Povey, and S.~Khudanpur, ``Advances in
  automatic speech recognition for child speech using factored time delay
  neural network.'' in \emph{Interspeech}, 2019, pp. 1--5.

\bibitem{vaswani2017attention}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez,
  {\L}.~Kaiser, and I.~Polosukhin, ``Attention is all you need,''
  \emph{Advances in neural information processing systems}, vol.~30, 2017.

\bibitem{levelt1993speaking}
\BIBentryALTinterwordspacing
W.~J.~M. Levelt, \emph{{Speaking: From Intention to Articulation}}.\hskip 1em
  plus 0.5em minus 0.4em\relax The MIT Press, 08 1993. [Online]. Available:
  \url{https://doi.org/10.7551/mitpress/6393.001.0001}
\BIBentrySTDinterwordspacing

\bibitem{black2015communication}
L.~Black, A.~Vahratian, and H.~Hoffman, ``Communication disorders and use of
  intervention services among children aged 3--17 years: United states, 2012;
  us department of health and human services, centers for disease control and
  prevention,'' \emph{National Center for Health Statistics: Atlanta, GA, USA},
  2015.

\bibitem{langbecker2020long}
D.~Langbecker, C.~L. Snoswell, A.~C. Smith, J.~Verboom, and L.~J. Caffery,
  ``Long-term effects of childhood speech and language disorders: A scoping
  review,'' \emph{South African Journal of Childhood Education}, vol.~10,
  no.~1, pp. 1--13, 2020.

\bibitem{hilty2015new}
D.~Hilty, S.~Chan, J.~Torous, J.~Mahautmr, and D.~Mucic, ``New frontiers in
  healthcare and technology: Internet-and web-based mental options emerge to
  complement in-person and telepsychiatric care options,'' \emph{J Health Med
  Informatics}, vol.~6, no.~4, pp. 1--14, 2015.

\bibitem{barnett2011utilizing}
J.~E. Barnett, ``Utilizing technological innovations to enhance psychotherapy
  supervision, training, and outcomes.'' \emph{Psychotherapy}, vol.~48, no.~2,
  p. 103, 2011.

\bibitem{hughes2019increasing}
M.~C. Hughes, J.~M. Gorman, Y.~Ren, S.~Khalid, and C.~Clayton, ``Increasing
  access to rural mental health care using hybrid care that includes
  telepsychiatry.'' \emph{Journal of Rural Mental Health}, vol.~43, no.~1,
  p.~30, 2019.

\bibitem{mendoza2022added}
V.~Mendoza~Ramos, ``The added value of speech technology in clinical care of
  patients with dysarthria,'' Ph.D. dissertation, University of Antwerp, 2022.

\bibitem{SAZ2009948}
\BIBentryALTinterwordspacing
O.~Saz, S.-C. Yin, E.~Lleida, R.~Rose, C.~Vaquero, and W.~R. Rodríguez,
  ``Tools and technologies for computer-aided speech and language therapy,''
  \emph{Speech Communication}, vol.~51, no.~10, pp. 948--967, 2009, spoken
  Language Technology for Education. [Online]. Available:
  \url{https://www.sciencedirect.com/science/article/pii/S0167639309000661}
\BIBentrySTDinterwordspacing

\bibitem{brewer2013using}
R.~Brewer, L.~Anthony, Q.~Brown, G.~Irwin, J.~Nias, and B.~Tate, ``Using
  gamification to motivate children to complete empirical studies in lab
  environments,'' in \emph{Proceedings of the 12th international conference on
  interaction design and children}, 2013, pp. 388--391.

\bibitem{liu2015gamification}
Q.~Liu, F.~Cai, Y.~Yang, and T.~Han, ``Gamification design based research on
  speech training system for hearing-impaired children,'' in \emph{Engineering
  Psychology and Cognitive Ergonomics: 12th International Conference, EPCE
  2015, Held as Part of HCI International 2015, Los Angeles, CA, USA, August
  2-7, 2015, Proceedings 12}.\hskip 1em plus 0.5em minus 0.4em\relax Springer,
  2015, pp. 140--151.

\bibitem{lu1992mastering}
C.~Lu and D.~Frye, ``Mastering the machine: A comparison of the mouse and touch
  screen for children's use of computers,'' in \emph{International conference
  on computer assisted learning}.\hskip 1em plus 0.5em minus 0.4em\relax
  Springer, 1992, pp. 417--427.

\bibitem{wise2023learning}
B.~Wise, R.~Cole, S.~Van~Vuuren, S.~Schwartz, L.~Snyder, N.~Ngampatipatpong,
  J.~Tuantranont, and B.~Pellom, ``Learning to read with a virtual tutor:
  Foundations to literacy,'' in \emph{Interactive Literacy Education}.\hskip
  1em plus 0.5em minus 0.4em\relax Routledge, 2023, pp. 31--76.

\bibitem{pompili2020evaluation}
A.~Pompili, A.~Abad, I.~Trancoso, J.~Fonseca, and I.~P. Martins, ``Evaluation
  and extensions of an automatic speech therapy platform,'' in
  \emph{International Conference on Computational Processing of the Portuguese
  Language}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2020, pp. 43--52.

\bibitem{albudoor2022identifying}
N.~Albudoor and E.~D. Pe{\~n}a, ``Identifying language disorder in bilingual
  children using automatic speech recognition,'' \emph{Journal of Speech,
  Language, and Hearing Research}, vol.~65, no.~7, pp. 2648--2661, 2022.

\bibitem{sri_end2end}
P.~{Gurunath Shivakumar} and S.~Narayanan, ``End-to-end neural systems for
  automatic children speech recognition: An empirical study,'' \emph{Computer
  Speech \& Language}, vol.~72, p. 101289, 2022.

\bibitem{gelin2021endtoend}
L.~Gelin, M.~Daniel, J.~Pinquier, and T.~Pellegrini, ``End-to-end acoustic
  modelling for phone recognition of young readers,'' \emph{Speech
  Communication}, vol. 134, pp. 71--84, 2021.

\bibitem{childrenSpeechWorse}
A.~Potamianos and S.~Narayanan, ``Robust recognition of children's speech,''
  \emph{IEEE Transactions on Speech and Audio Processing}, vol.~11, no.~6, pp.
  603--616, 2003.

\bibitem{kwasny2021gender}
D.~Kwasny and D.~Hemmerling, ``Gender and age estimation methods based on
  speech using deep neural networks,'' \emph{Sensors}, vol.~21, no.~14, p.
  4785, 2021.

\bibitem{koolagudi2012emotion}
S.~G. Koolagudi and K.~S. Rao, ``Emotion recognition from speech: a review,''
  \emph{International journal of speech technology}, vol.~15, pp. 99--117,
  2012.

\bibitem{li2023asr}
Y.~Li, Z.~Zhao, O.~Klejch, P.~Bell, and C.~Lai, ``{ASR and Emotional Speech: A
  Word-Level Investigation of the Mutual Impact of Speech and Emotion
  Recognition},'' in \emph{Proc. INTERSPEECH 2023}, 2023, pp. 1449--1453.

\bibitem{li2014overview}
J.~Li, L.~Deng, Y.~Gong, and R.~Haeb-Umbach, ``An overview of noise-robust
  automatic speech recognition,'' \emph{IEEE/ACM Transactions on Audio, Speech,
  and Language Processing}, vol.~22, no.~4, pp. 745--777, 2014.

\bibitem{king2017robust}
B.~King, I.-F. Chen, Y.~Vaizman, Y.~Liu, R.~Maas, S.~H.~K. Parthasarathi, and
  B.~Hoffmeister, ``{Robust Speech Recognition via Anchor Word
  Representations},'' in \emph{Proc. Interspeech 2017}, 2017, pp. 2471--2475.

\bibitem{russell1996applications}
M.~Russell, C.~Brown, A.~Skilling, R.~Series, J.~Wallace, B.~Bonham, and
  P.~Barker, ``Applications of automatic speech recognition to speech and
  language development in young children,'' in \emph{Proceeding of Fourth
  International Conference on Spoken Language Processing. ICSLP'96},
  vol.~1.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 1996, pp. 176--179.

\bibitem{benzeghiba2007automatic}
M.~Benzeghiba, R.~De~Mori, O.~Deroo, S.~Dupont, T.~Erbes, D.~Jouvet,
  L.~Fissore, P.~Laface, A.~Mertins, C.~Ris \emph{et~al.}, ``Automatic speech
  recognition and speech variability: A review,'' \emph{Speech communication},
  vol.~49, no. 10-11, pp. 763--786, 2007.

\bibitem{karpagavalli2016review}
S.~Karpagavalli and E.~Chandra, ``A review on automatic speech recognition
  architecture and approaches,'' \emph{International Journal of Signal
  Processing, Image Processing and Pattern Recognition}, vol.~9, no.~4, pp.
  393--404, 2016.

\bibitem{arora2012automatic}
S.~J. Arora and R.~P. Singh, ``Automatic speech recognition: a review,''
  \emph{International Journal of Computer Applications}, vol.~60, no.~9, 2012.

\bibitem{first_asr}
\BIBentryALTinterwordspacing
K.~H. Davis, R.~Biddulph, and S.~Balashek, ``Automatic recognition of spoken
  digits,'' \emph{The Journal of the Acoustical Society of America}, vol.~24,
  no.~6, pp. 637--642, 1952. [Online]. Available:
  \url{https://doi.org/10.1121/1.1906946}
\BIBentrySTDinterwordspacing

\bibitem{htk_book}
S.~Young, G.~Evermann, M.~Gales, T.~Hain, D.~Kershaw, X.~Liu, G.~Moore,
  J.~Odell, D.~Ollason, D.~Povey \emph{et~al.}, ``The {HTK} book,''
  \emph{Cambridge university engineering department}, vol.~3, no. 175, p.~12,
  2002.

\bibitem{darpa1992}
P.~C. Woodland and S.~J. Young, ``The {HTK} tied-state continuous speech
  recogniser.'' in \emph{Eurospeech}, 1993.

\bibitem{virkkunen2023finnish}
A.~Virkkunen, A.~Rouhe, N.~Phan, and M.~Kurimo, ``Finnish parliament asr
  corpus: Analysis, benchmarks and statistics,'' \emph{Language Resources and
  Evaluation}, pp. 1--26, 2023.

\bibitem{hmm-dnn}
G.~Hinton, L.~Deng, D.~Yu, G.~E. Dahl, A.-r. Mohamed, N.~Jaitly, A.~Senior,
  V.~Vanhoucke, P.~Nguyen, T.~N. Sainath, and B.~Kingsbury, ``Deep neural
  networks for acoustic modeling in speech recognition: The shared views of
  four research groups,'' \emph{IEEE Signal Processing Magazine}, vol.~29,
  no.~6, pp. 82--97, 2012.

\bibitem{mfcc}
S.~Davis and P.~Mermelstein, ``Comparison of parametric representations for
  monosyllabic word recognition in continuously spoken sentences,'' \emph{IEEE
  Transactions on Acoustics, Speech, and Signal Processing}, vol.~28, no.~4,
  pp. 357--366, 1980.

\bibitem{Dragon_system}
J.~Baker, ``The {DRAGON} system--an overview,'' \emph{IEEE Transactions on
  Acoustics, Speech, and Signal Processing}, vol.~23, no.~1, pp. 24--29, 1975.

\bibitem{bizzocchi2017many}
A.~L. Bizzocchi, ``How many phonemes does the english language have?''
  \emph{International Journal on Studies in English Language and Literature
  (IJSELL)}, vol.~5, no.~10, pp. 36--46, 2017.

\bibitem{schwartz1985context}
R.~Schwartz, Y.~Chow, O.~Kimball, S.~Roucos, M.~Krasner, and J.~Makhoul,
  ``Context-dependent modeling for acoustic-phonetic recognition of continuous
  speech,'' in \emph{ICASSP'85. IEEE International Conference on Acoustics,
  Speech, and Signal Processing}, vol.~10.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 1985, pp. 1205--1208.

\bibitem{bahl1991context}
L.~R. Bahl, P.~V. deSouza, P.~Gopalakrishnan, D.~Nahamoo, and M.~Picheny,
  ``Context dependent modeling of phones in continuous speech using decision
  trees,'' in \emph{Speech and Natural Language: Proceedings of a Workshop Held
  at Pacific Grove, California, February 19-22, 1991}, 1991.

\bibitem{bourlard2012connectionist}
H.~A. Bourlard and N.~Morgan, \emph{Connectionist speech recognition: a hybrid
  approach}.\hskip 1em plus 0.5em minus 0.4em\relax Springer Science \&
  Business Media, 2012, vol. 247.

\bibitem{meinedo2003audimus}
H.~Meinedo, D.~Caseiro, J.~Neto, and I.~Trancoso, ``Audimus. media: a broadcast
  news speech recognition system for the european portuguese language,'' in
  \emph{International Workshop on Computational Processing of the Portuguese
  Language}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2003, pp. 9--17.

\bibitem{lang1990time}
K.~J. Lang, A.~H. Waibel, and G.~E. Hinton, ``A time-delay neural network
  architecture for isolated word recognition,'' \emph{Neural networks}, vol.~3,
  no.~1, pp. 23--43, 1990.

\bibitem{sak2014long}
H.~Sak, A.~Senior, and F.~Beaufays, ``{Long short-term memory recurrent neural
  network architectures for large scale acoustic modeling},'' in \emph{Proc.
  Interspeech 2014}, 2014, pp. 338--342.

\bibitem{waibel2013phoneme}
A.~Waibel, T.~Hanazawa, G.~Hinton, K.~Shikano, and K.~J. Lang, ``Phoneme
  recognition using time-delay neural networks,'' in
  \emph{Backpropagation}.\hskip 1em plus 0.5em minus 0.4em\relax Psychology
  Press, 2013, pp. 35--61.

\bibitem{g2p}
K.~Yao and G.~Zweig, ``{Sequence-to-sequence neural net models for
  grapheme-to-phoneme conversion},'' in \emph{Proc. Interspeech 2015}, 2015,
  pp. 3330--3334.

\bibitem{n-grams-NLP}
G.~Sidorov, F.~Velasquez, E.~Stamatatos, A.~Gelbukh, and
  L.~Chanona-Hern{\'a}ndez, ``Syntactic n-grams as machine learning features
  for natural language processing,'' \emph{Expert Systems with Applications},
  vol.~41, no.~3, pp. 853--860, 2014.

\bibitem{n-grams-computational_biology}
\BIBentryALTinterwordspacing
S.~Vishnoi, P.~Garg, and P.~Arora, ``Physicochemical n-grams tool: A tool for
  protein physicochemical descriptor generation via chou’s 5-step rule,''
  \emph{Chemical Biology \& Drug Design}, vol.~95, no.~1, pp. 79--86, 2020.
  [Online]. Available:
  \url{https://onlinelibrary.wiley.com/doi/abs/10.1111/cbdd.13617}
\BIBentrySTDinterwordspacing

\bibitem{n-gram-compression}
\BIBentryALTinterwordspacing
V.~H. Nguyen, H.~T. Nguyen, H.~N. Duong, and V.~Snasel, ``n-{Gram}-{Based}
  {Text} {Compression},'' \emph{Computational Intelligence and Neuroscience},
  vol. 2016, p. 9483646, Nov. 2016, publisher: Hindawi Publishing Corporation.
  [Online]. Available: \url{https://doi.org/10.1155/2016/9483646}
\BIBentrySTDinterwordspacing

\bibitem{n-grams-smoothing}
S.~Chen and R.~Rosenfeld, ``A survey of smoothing techniques for me models,''
  \emph{IEEE Transactions on Speech and Audio Processing}, vol.~8, no.~1, pp.
  37--50, 2000.

\bibitem{Bert}
\BIBentryALTinterwordspacing
J.~Devlin, M.-W. Chang, K.~Lee, and K.~Toutanova, ``{BERT}: Pre-training of
  deep bidirectional transformers for language understanding,'' in
  \emph{Proceedings of the 2019 Conference of the North {A}merican Chapter of
  the Association for Computational Linguistics: Human Language Technologies,
  Volume 1 (Long and Short Papers)}, J.~Burstein, C.~Doran, and T.~Solorio,
  Eds.\hskip 1em plus 0.5em minus 0.4em\relax Minneapolis, Minnesota:
  Association for Computational Linguistics, Jun. 2019, pp. 4171--4186.
  [Online]. Available: \url{https://aclanthology.org/N19-1423}
\BIBentrySTDinterwordspacing

\bibitem{brown2020language}
T.~Brown, B.~Mann, N.~Ryder, M.~Subbiah, J.~D. Kaplan, P.~Dhariwal,
  A.~Neelakantan, P.~Shyam, G.~Sastry, A.~Askell \emph{et~al.}, ``Language
  models are few-shot learners,'' \emph{Advances in neural information
  processing systems}, vol.~33, pp. 1877--1901, 2020.

\bibitem{viterbi_decoder}
A.~Viterbi, ``Error bounds for convolutional codes and an asymptotically
  optimum decoding algorithm,'' \emph{IEEE Transactions on Information Theory},
  vol.~13, no.~2, pp. 260--269, 1967.

\bibitem{valtchev1994novel}
V.~Valtchev, J.~Odell, P.~Woodland, and S.~Young, ``A novel decoder design for
  large vocabulary recognition,'' in \emph{Proceedings of ICSLP}, 1994.

\bibitem{aubert1995large}
X.~Aubert and H.~Ney, ``Large vocabulary continuous speech recognition using
  word graphs,'' in \emph{1995 International Conference on Acoustics, Speech,
  and Signal Processing}, vol.~1.\hskip 1em plus 0.5em minus 0.4em\relax IEEE,
  1995, pp. 49--52.

\bibitem{mohri1997finite}
M.~Mohri, ``Finite-state transducers in language and speech processing,''
  \emph{Computational linguistics}, vol.~23, no.~2, pp. 269--311, 1997.

\bibitem{caseiro2002using}
D.~Caseiro and I.~Trancoso, ``Using dynamic {WFST} composition for recognizing
  broadcast news,'' in \emph{Seventh International Conference on Spoken
  Language Processing}, 2002.

\bibitem{kaldi}
D.~Povey, A.~Ghoshal, G.~Boulianne, L.~Burget, O.~Glembek, N.~Goel,
  M.~Hannemann, P.~Motlicek, Y.~Qian, P.~Schwarz \emph{et~al.}, ``The {Kaldi}
  speech recognition toolkit,'' in \emph{IEEE 2011 workshop on automatic speech
  recognition and understanding}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE
  Signal Processing Society, 2011.

\bibitem{richardson1995lattice}
F.~Richardson, M.~Ostendorf, and J.~R. Rohlicek, ``Lattice-based search
  strategies for large vocabulary speech recognition,'' in \emph{1995
  International Conference on Acoustics, Speech, and Signal Processing},
  vol.~1.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 1995, pp. 576--579.

\bibitem{hannun2014deep}
A.~Hannun, C.~Case, J.~Casper, B.~Catanzaro, G.~Diamos, E.~Elsen, R.~Prenger,
  S.~Satheesh, S.~Sengupta, A.~Coates \emph{et~al.}, ``Deep speech: Scaling up
  end-to-end speech recognition,'' \emph{arXiv preprint arXiv:1412.5567}, 2014.

\bibitem{hmmvse2e}
S.~Karita, N.~Chen, T.~Hayashi, T.~Hori, H.~Inaguma, Z.~Jiang, M.~Someki,
  N.~E.~Y. Soplin, R.~Yamamoto, X.~Wang, S.~Watanabe, T.~Yoshimura, and
  W.~Zhang, ``A comparative study on transformer vs rnn in speech
  applications,'' in \emph{2019 IEEE Automatic Speech Recognition and
  Understanding Workshop (ASRU)}, 2019, pp. 449--456.

\bibitem{hmm-end2end}
D.~Wang, X.~Wang, and S.~Lv, ``An overview of end-to-end automatic speech
  recognition,'' \emph{Symmetry}, vol.~11, p. 1018, 08 2019.

\bibitem{zheng2021using_OOV}
X.~Zheng, Y.~Liu, D.~Gunceler, and D.~Willett, ``Using synthetic audio to
  improve the recognition of out-of-vocabulary words in end-to-end asr
  systems,'' in \emph{ICASSP 2021-2021 IEEE International Conference on
  Acoustics, Speech and Signal Processing (ICASSP)}.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 2021, pp. 5674--5678.

\bibitem{First_End2End}
\BIBentryALTinterwordspacing
A.~Graves, S.~Fern\'{a}ndez, F.~Gomez, and J.~Schmidhuber, ``Connectionist
  temporal classification: Labelling unsegmented sequence data with recurrent
  neural networks,'' in \emph{Proceedings of the 23rd International Conference
  on Machine Learning}, ser. ICML '06.\hskip 1em plus 0.5em minus 0.4em\relax
  New York, NY, USA: Association for Computing Machinery, 2006, p. 369–376.
  [Online]. Available: \url{https://doi.org/10.1145/1143844.1143891}
\BIBentrySTDinterwordspacing

\bibitem{sutskever2014sequence}
I.~Sutskever, O.~Vinyals, and Q.~V. Le, ``Sequence to sequence learning with
  neural networks,'' \emph{Advances in neural information processing systems},
  vol.~27, 2014.

\bibitem{bahdanau2014neural}
D.~Bahdanau, K.~Cho, and Y.~Bengio, ``Neural machine translation by jointly
  learning to align and translate,'' in \emph{3rd International Conference on
  Learning Representations, ICLR 2015}, 2015.

\bibitem{seq2seq_imagecaption}
O.~Vinyals, A.~Toshev, S.~Bengio, and D.~Erhan, ``Show and tell: A neural image
  caption generator,'' in \emph{2015 IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, 2015, pp. 3156--3164.

\bibitem{vinyals2015neural}
O.~Vinyals and Q.~Le, ``A neural conversational model,'' \emph{arXiv preprint
  arXiv:1506.05869}, 2015.

\bibitem{nallapati2016abstractive}
\BIBentryALTinterwordspacing
R.~Nallapati, B.~Zhou, C.~Gulcehre, B.~Xiang \emph{et~al.}, ``Abstractive text
  summarization using sequence-to-sequence {RNN}s and beyond,'' in
  \emph{Proceedings of the 20th {SIGNLL} Conference on Computational Natural
  Language Learning}.\hskip 1em plus 0.5em minus 0.4em\relax Berlin, Germany:
  Association for Computational Linguistics, 2016, pp. 280--290. [Online].
  Available: \url{https://aclanthology.org/K16-1028}
\BIBentrySTDinterwordspacing

\bibitem{dong2018speech}
L.~Dong, S.~Xu, and B.~Xu, ``Speech-transformer: a no-recurrence
  sequence-to-sequence model for speech recognition,'' in \emph{2018 IEEE
  International Conference on Acoustics, Speech and Signal Processing
  (ICASSP)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2018, pp. 5884--5888.

\bibitem{tuske2021limit}
Z.~Tüske, G.~Saon, and B.~Kingsbury, ``{On the Limit of English Conversational
  Speech Recognition},'' in \emph{Proc. Interspeech 2021}, 2021, pp.
  2062--2066.

\bibitem{bermuth2021scribosermo}
D.~Bermuth, A.~Poeppel, and W.~Reif, ``Scribosermo: fast speech-to-text models
  for german and other languages,'' \emph{arXiv preprint arXiv:2110.07982},
  2021.

\bibitem{chan2021speechstew}
W.~Chan, D.~Park, C.~Lee, Y.~Zhang, Q.~Le, and M.~Norouzi, ``Speechstew: Simply
  mix all available speech recognition data to train one large neural
  network,'' \emph{arXiv preprint arXiv:2104.02133}, 2021.

\bibitem{lee97b_eurospeech}
S.~Lee, A.~Potamianos, and S.~Narayanan, ``{Analysis of children's speech:
  duration, pitch and formants},'' in \emph{Proc. 5th European Conference on
  Speech Communication and Technology (Eurospeech 1997)}, 1997, pp. 473--476.

\bibitem{first_vowel_study}
\BIBentryALTinterwordspacing
G.~E. Peterson and H.~L. Barney, ``Control methods used in a study of the
  vowels,'' \emph{The Journal of the Acoustical Society of America}, vol.~24,
  no.~2, pp. 175--184, 1952. [Online]. Available:
  \url{https://doi.org/10.1121/1.1906875}
\BIBentrySTDinterwordspacing

\bibitem{why_children_speech_no_working}
Q.~Li and M.~J. Russell, ``{Why is automatic recognition of children's speech
  difficult?}'' in \emph{Proc. 7th European Conference on Speech Communication
  and Technology (Eurospeech 2001)}, 2001, pp. 2671--2674.

\bibitem{segment_definition}
D.~CRYSTAL, ``A dictionary of linguistics and phonetics,'' \emph{Journal of the
  International Phonetic Association}, vol.~34, pp. 100 -- 101, 01 2004.

\bibitem{moats2000speech}
L.~C. Moats and S.~Brady, \emph{Speech to print: Language essentials for
  teachers}.\hskip 1em plus 0.5em minus 0.4em\relax Paul H. Brookes Pub., 2000.

\bibitem{language_children}
H.~Tulsiani, P.~Swarup, and P.~Rao, ``Acoustic and language modeling for
  children's read speech assessment,'' in \emph{2017 Twenty-third National
  Conference on Communications (NCC)}.\hskip 1em plus 0.5em minus 0.4em\relax
  IEEE, 2017, pp. 1--6.

\bibitem{clark1977psychology}
H.~H. Clark and E.~V. Clark, ``Psychology and language,'' \emph{Journal of
  Child Language}, vol.~4, p. b1–b3, 1977.

\bibitem{language_children2}
A.~Potamianos and S.~Narayanan, ``Spoken dialog systems for children,'' in
  \emph{ICASSP, IEEE International Conference on Acoustics, Speech and Signal
  Processing - Proceedings}, vol.~1, 06 1998, pp. 197 -- 200 vol.1.

\bibitem{Children_language_model}
S.~Das, D.~Nix, and M.~Picheny, ``Improvements in children's speech recognition
  performance,'' \emph{Proceedings of the 1998 IEEE International Conference on
  Acoustics, Speech and Signal Processing, ICASSP '98 (Cat. No.98CH36181)},
  vol.~1, pp. 433--436 vol.1, 1998.

\bibitem{children_language_model2}
S.~S. Gray, D.~Willett, J.~Lu, J.~Pinto, P.~Maergner, and N.~Bodenstab, ``Child
  automatic speech recognition for us english: child interaction with
  living-room-electronic-devices,'' in \emph{WOCCI}, 2014.

\bibitem{radford2023robust}
A.~Radford, J.~W. Kim, T.~Xu, G.~Brockman, C.~McLeavey, and I.~Sutskever,
  ``Robust speech recognition via large-scale weak supervision,'' in
  \emph{International Conference on Machine Learning}.\hskip 1em plus 0.5em
  minus 0.4em\relax PMLR, 2023, pp. 28\,492--28\,518.

\bibitem{librispeech}
V.~Panayotov, G.~Chen, D.~Povey, and S.~Khudanpur, ``Librispeech: An asr corpus
  based on public domain audio books,'' in \emph{ICASSP}, 2015, pp. 5206--5210.

\bibitem{chen2021gigaspeech}
G.~Chen, S.~Chai, G.-B. Wang, J.~Du, W.-Q. Zhang, C.~Weng, D.~Su, D.~Povey,
  J.~Trmal, J.~Zhang, M.~Jin, S.~Khudanpur, S.~Watanabe, S.~Zhao, W.~Zou,
  X.~Li, X.~Yao, Y.~Wang, Z.~You, and Z.~Yan, ``{GigaSpeech: An Evolving,
  Multi-Domain ASR Corpus with 10,000 Hours of Transcribed Audio},'' in
  \emph{Proc. Interspeech 2021}, 2021, pp. 3670--3674.

\bibitem{MyST}
W.~Ward, R.~Cole, D.~Bola{\~n}os, C.~Buchenroth-Martin, E.~Svirsky, and T.~B.
  Weston, ``My science tutor: A conversational multimedia virtual tutor.''
  \emph{Journal of Educational Psychology}, vol. 105, pp. 1115--1125, 2013.

\bibitem{singakids}
N.~F. Chen, R.~Tong, D.~Wee, P.~X. Lee, B.~Ma, and H.~Li, ``Singakids-mandarin:
  Speech corpus of singaporean children speaking mandarin chinese.'' in
  \emph{Interspeech}, 2016, pp. 1545--1549.

\bibitem{ahmed2021auskidtalk}
B.~Ahmed, K.~Ballard, D.~Burnham, T.~Sirojan, H.~Mehmood, D.~Estival, E.~Baker,
  F.~Cox, J.~Arciuli, T.~Benders \emph{et~al.}, ``Auskidtalk: an
  auditory-visual corpus of 3-to 12-year-old australian children's speech,'' in
  \emph{Annual Conference of the International Speech Communication Association
  (22nd: 2021)}.\hskip 1em plus 0.5em minus 0.4em\relax International Speech
  Communication Association, 2021, pp. 3680--3684.

\bibitem{cmu}
M.~Eskenazi, J.~Mostow, and D.~Graff, ``The cmu kids speech corpus,''
  \emph{Corpus of children's read speech digitized and transcribed on two
  CD-ROMs, with assistance from Multicom Research and David Graff. Published by
  the Linguistic Data Consortium, University of Pennsylvania}, 1997.

\bibitem{cslu}
K.~Shobaki, J.-P. Hosom, and R.~Cole, ``The ogi kids’ speech corpus and
  recognizers,'' in \emph{Proc. of ICSLP}, 2000, pp. 564--567.

\bibitem{pfstar}
M.~Russell, S.~D'Arcy, M.~Wong, A.~Batliner, M.~Blomberg, and M.~Gerosa, ``The
  pf-star children's speech corpus,'' in \emph{Interspeech 2005}, 2005.

\bibitem{asr-google}
H.~Liao, G.~Pundak, O.~Siohan, M.~Carroll, N.~Coccaro, Q.-M. Jiang, T.~N.
  Sainath, A.~Senior, F.~Beaufays, and M.~Bacchiani, ``Large vocabulary
  automatic speech recognition for children,'' in \emph{Interspeech}, 2015.

\bibitem{ghai2009exploring}
S.~Ghai and R.~Sinha, ``Exploring the role of spectral smoothing in context of
  children's speech recognition,'' in \emph{Tenth Annual Conference of the
  International Speech Communication Association}, 2009.

\bibitem{ghai2011addressing}
S.~Ghai, ``Addressing pitch mismatch for children's automatic speech
  recognition,'' Ph.D. dissertation, Indian Institute of technology Guwahati,
  2011.

\bibitem{Hermansky1990PerceptualLP}
H.~Hermansky, ``Perceptual linear predictive (plp) analysis of speech.''
  \emph{The Journal of the Acoustical Society of America}, vol. 87 4, pp.
  1738--52, 1990.

\bibitem{shahnawazuddin2023gammatone}
S.~Shahnawazuddin, Ankita, A.~Kumar, and H.~K. Kathania, ``Gammatone-filterbank
  based pitch-normalized cepstral coefficients for zero-resource children’s
  asr,'' in \emph{International Conference on Speech and Computer}.\hskip 1em
  plus 0.5em minus 0.4em\relax Springer, 2023, pp. 494--505.

\bibitem{feat_ext_from_raw}
S.~P. Dubagunta, S.~Hande~Kabil, and M.~Magimai.-Doss, ``Improving children
  speech recognition through feature learning from raw speech signal,'' in
  \emph{ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech
  and Signal Processing (ICASSP)}, 2019, pp. 5736--5740.

\bibitem{Sincnet}
M.~Ravanelli and Y.~Bengio, ``Speaker recognition from raw waveform with
  sincnet,'' in \emph{2018 IEEE spoken language technology workshop
  (SLT)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2018, pp. 1021--1028.

\bibitem{sincnet_adapt}
J.~Fainberg, O.~Klejch, E.~Loweimi, P.~Bell, and S.~Renals, ``Acoustic model
  adaptation from raw waveforms with sincnet,'' in \emph{2019 IEEE Automatic
  Speech Recognition and Understanding Workshop (ASRU)}, 2019, pp. 897--904.

\bibitem{VTLN}
L.~Lee and R.~C. Rose, ``Speaker normalization using efficient frequency
  warping procedures,'' in \emph{1996 IEEE International Conference on
  Acoustics, Speech, and Signal Processing Conference Proceedings},
  vol.~1.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 1996, pp. 353--356.

\bibitem{VTLN2}
R.~Serizel and D.~Giuliani, ``Vocal tract length normalisation approaches to
  dnn-based children's and adults' speech recognition,'' in \emph{SLT
  Workshop}, 2014, pp. 135--140.

\bibitem{claus2013survey}
F.~Claus, H.~Gamboa~Rosales, R.~Petrick, H.-U. Hain, and R.~Hoffmann, ``A
  survey about asr for children,'' in \emph{Speech and Language Technology in
  Education}, 2013.

\bibitem{potamianos1997automatic}
A.~Potamianos, S.~Narayanan, and S.~Lee, ``Automatic speech recognition for
  children,'' in \emph{Fifth European Conference on Speech Communication and
  Technology}, 1997.

\bibitem{potamianos1997combining}
A.~Potamianos and R.~C. Rose, ``On combining frequency warping and spectral
  shaping in hmm based speech recognition,'' in \emph{1997 IEEE International
  Conference on Acoustics, Speech, and Signal Processing}, vol.~2.\hskip 1em
  plus 0.5em minus 0.4em\relax IEEE, 1997, pp. 1275--1278.

\bibitem{f0norm}
G.~Yeung and A.~Alwan, ``A frequency normalization technique for kindergarten
  speech recognition inspired by the role of f0 in vowel perception,''
  \emph{Interspeech 2019}, 2019.

\bibitem{pitchnorm}
S.~Shahnawazuddin, R.~Sinha, and G.~Pradhan, ``Pitch-normalized acoustic
  features for robust children's speech recognition,'' \emph{IEEE Signal
  Processing Letters}, vol.~24, no.~8, pp. 1128--1132, 2017.

\bibitem{pitch_adapt_norm}
S.~Shahnawazuddin, A.~Dey, and R.~Sinha, ``Pitch-adaptive front-end features
  for robust children's asr,'' in \emph{INTERSPEECH}, 2016.

\bibitem{formant_norm}
H.~Kathania, S.~Kadiri, P.~Alku, and M.~Kurimo, ``A formant modification method
  for improved asr of children’s speech,'' \emph{Speech Communication}, vol.
  136, pp. 98--106, 01 2022.

\bibitem{kumar2023effect}
U.~L. Kumar, M.~Kurimo, and H.~K. Kathania, ``Effect of linear prediction order
  to modify formant locations for children speech recognition,'' in
  \emph{International Conference on Speech and Computer}.\hskip 1em plus 0.5em
  minus 0.4em\relax Springer, 2023, pp. 483--493.

\bibitem{speaking_rate}
H.~K. Kathania, S.~Shahnawazuddin, W.~Ahmad, N.~Adiga, S.~K. Jana, and A.~B.
  Samaddar, ``Improving children's speech recognition through time scale
  modification based speaking rate adaptation,'' in \emph{2018 International
  Conference on Signal Processing and Communications (SPCOM)}.\hskip 1em plus
  0.5em minus 0.4em\relax IEEE, 2018, pp. 257--261.

\bibitem{adversarial-adapt1}
R.~Duan and N.~F. Chen, ``Senone-aware adversarial multi-task training for
  unsupervised child to adult speech adaptation,'' in \emph{ICASSP 2021 - 2021
  IEEE International Conference on Acoustics, Speech and Signal Processing
  (ICASSP)}, 2021, pp. 7758--7762.

\bibitem{adversarial-adapt2}
L.~Rumberg, H.~Ehlert, U.~L{\"u}dtke, and J.~Ostermann, ``Age-invariant
  training for end-to-end child speech recognition using adversarial multi-task
  learning,'' \emph{Proc. Interspeech 2021}, pp. 3850--3854, 2021.

\bibitem{ivector}
A.~Senior and I.~Lopez-Moreno, ``Improving dnn speaker independence with
  i-vector inputs,'' in \emph{ICASSP}, 2014, pp. 225--229.

\bibitem{shivakumar2020transfer}
P.~G. Shivakumar and P.~Georgiou, ``Transfer learning from adult to children
  for speech recognition: Evaluation, analysis and recommendations,''
  \emph{Computer speech \& language}, vol.~63, p. 101077, 2020.

\bibitem{prosody_feat}
H.~K. Kathania, S.~Shahnawazuddin, N.~Adiga, and W.~Ahmad, ``Role of prosodic
  features on children's speech recognition,'' in \emph{2018 IEEE International
  Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 2018, pp.
  5519--5523.

\bibitem{kadyan2023prosody}
V.~Kadyan, T.~Hasija, and A.~Singh, ``Prosody features based low resource
  punjabi children asr and t-nt classifier using data augmentation,''
  \emph{Multimedia Tools and Applications}, vol.~82, no.~3, pp. 3973--3994,
  2023.

\bibitem{linguistic-children}
J.~Wilpon and C.~Jacobsen, ``A study of speech recognition for children and the
  elderly,'' in \emph{ICASSP}, vol.~1, 1996, pp. 349--352 vol. 1.

\bibitem{gale2019improving}
R.~Gale, L.~Chen, J.~Dolata, J.~Van~Santen, and M.~Asgari, ``Improving asr
  systems for children with autism and language impairment using domain-focused
  dnn transfer techniques,'' in \emph{Interspeech}, vol. 2019.\hskip 1em plus
  0.5em minus 0.4em\relax NIH Public Access, 2019, p.~11.

\bibitem{subwords}
\BIBentryALTinterwordspacing
A.~Hagen, B.~Pellom, and R.~Cole, ``Highly accurate children’s speech
  recognition for interactive reading tutors using subword units,''
  \emph{Speech Communication}, vol.~49, no.~12, pp. 861--873, 2007. [Online].
  Available:
  \url{https://www.sciencedirect.com/science/article/pii/S0167639307000878}
\BIBentrySTDinterwordspacing

\bibitem{pronunciation}
P.~G. Shivakumar, A.~Potamianos, S.~Lee, and S.~S. Narayanan, ``Improving
  speech recognition for children using acoustic adaptation and pronunciation
  modeling.'' in \emph{WOCCI}, 2014, pp. 15--19.

\bibitem{pronunciation2}
Q.~Li and M.~J. Russell, ``An analysis of the causes of increased error rates
  in children's speech recognition,'' in \emph{Seventh International Conference
  on Spoken Language Processing}, 2002.

\bibitem{bhardwaj2022automatic}
V.~Bhardwaj, M.~T. Ben~Othman, V.~Kukreja, Y.~Belkhier, M.~Bajaj, B.~S. Goud,
  A.~U. Rehman, M.~Shafiq, and H.~Hamam, ``Automatic speech recognition (asr)
  systems for children: A systematic literature review,'' \emph{Applied
  Sciences}, vol.~12, no.~9, p. 4419, 2022.

\bibitem{tdnn}
V.~Peddinti, D.~Povey, and S.~Khudanpur, ``A time delay neural network
  architecture for efficient modeling of long temporal contexts,'' in
  \emph{Sixteenth annual conference of the international speech communication
  association}, 2015.

\bibitem{kumar2020leveraging}
M.~Kumar, S.~H. Kim, C.~Lord, T.~D. Lyon, and S.~Narayanan, ``Leveraging
  linguistic context in dyadic interactions to improve automatic speech
  recognition for children,'' \emph{Computer speech \& language}, vol.~63, p.
  101101, 2020.

\bibitem{TDNN-F}
D.~Povey, G.~Cheng, Y.~Wang, K.~Li, H.~Xu, M.~Yarmohammadi, and S.~Khudanpur,
  ``Semi-orthogonal low-rank matrix factorization for deep neural networks.''
  in \emph{Interspeech}, 2018, pp. 3743--3747.

\bibitem{chen2020data}
G.~Chen, X.~Na, Y.~Wang, Z.~Yan, J.~Zhang, S.~Ma, and Y.~Wang, ``Data
  augmentation for children's speech recognition--the ``ethiopian" system for
  the slt 2021 children speech recognition challenge,'' \emph{arXiv preprint
  arXiv:2011.04547}, 2020.

\bibitem{ng2020cuhk}
S.-I. Ng, W.~Liu, Z.~Peng, S.~Feng, H.-P. Huang, O.~Scharenborg, and T.~Lee,
  ``The {CUHK-TUDELFT} system for the {SLT} 2021 children speech recognition
  challenge,'' \emph{arXiv preprint arXiv:2011.06239}, 2020.

\bibitem{chan2015listen}
W.~Chan, N.~Jaitly, Q.~Le, and O.~Vinyals, ``Listen, attend and spell: A neural
  network for large vocabulary conversational speech recognition,'' in
  \emph{2016 IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP)}, 2016, pp. 4960--4964.

\bibitem{targ2016resnet}
S.~Targ, D.~Almeida, and K.~Lyman, ``Resnet in resnet: Generalizing residual
  architectures,'' \emph{arXiv preprint arXiv:1603.08029}, 2016.

\bibitem{Transformer}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez,
  {\L}.~Kaiser, and I.~Polosukhin, ``Attention is all you need,''
  \emph{Advances in neural information processing systems}, vol.~30, 2017.

\bibitem{adultAUGMENT1}
M.~Qian, I.~McLoughlin, W.~Quo, and L.~Dai, ``Mismatched training data
  enhancement for automatic recognition of children's speech using dnn-hmm,''
  in \emph{2016 10th International Symposium on Chinese Spoken Language
  Processing (ISCSLP)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2016, pp.
  1--5.

\bibitem{adultAUGMENT2}
J.~Fainberg, P.~Bell, M.~Lincoln, and S.~Renals, ``Improving children's speech
  recognition through out-of-domain data augmentation.'' in \emph{Interspeech},
  2016, pp. 1598--1602.

\bibitem{nonnative}
M.~Matassoni, R.~Gretter, D.~Falavigna, and D.~Giuliani, ``Non-native children
  speech recognition through transfer learning,'' in \emph{ICASSP}, 2018, pp.
  6229--6233.

\bibitem{nagano2019data}
T.~Nagano, T.~Fukuda, M.~Suzuki, and G.~Kurata, ``Data augmentation based on
  vowel stretch for improving children's speech recognition,'' in \emph{2019
  IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)}.\hskip
  1em plus 0.5em minus 0.4em\relax IEEE, 2019, pp. 502--508.

\bibitem{yeung2021fundamental}
G.~Yeung, R.~Fan, and A.~Alwan, ``Fundamental frequency feature normalization
  and data augmentation for child speech recognition,'' in \emph{ICASSP
  2021-2021 IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2021, pp.
  6993--6997.

\bibitem{dua2022spectral}
M.~Dua, V.~Kadyan, N.~Banthia, A.~Bansal, and T.~Agarwal, ``Spectral warping
  and data augmentation for low resource language asr system under mismatched
  conditions,'' \emph{Applied Acoustics}, vol. 190, p. 108643, 2022.

\bibitem{shuyangdata}
S.~Zhao, M.~Singh, A.~Woubie, and R.~Karhila, ``{Data augmentation for children
  ASR and child-adult speaker classification using voice conversion methods},''
  in \emph{Proc. INTERSPEECH 2023}, 2023, pp. 4593--4597.

\bibitem{GANS}
P.~Sheng, Z.~Yang, and Y.~Qian, ``Gans for children: A generative data
  augmentation strategy for children speech recognition,'' in \emph{2019 IEEE
  Automatic Speech Recognition and Understanding Workshop (ASRU)}.\hskip 1em
  plus 0.5em minus 0.4em\relax IEEE, 2019, pp. 129--135.

\bibitem{shen2018natural}
J.~Shen, R.~Pang, R.~J. Weiss, M.~Schuster, N.~Jaitly, Z.~Yang, Z.~Chen,
  Y.~Zhang, Y.~Wang, R.~Skerrv-Ryan \emph{et~al.}, ``Natural tts synthesis by
  conditioning wavenet on mel spectrogram predictions,'' in \emph{2018 IEEE
  international conference on acoustics, speech and signal processing
  (ICASSP)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2018, pp. 4779--4783.

\bibitem{kim2021conditional}
J.~Kim, J.~Kong, and J.~Son, ``Conditional variational autoencoder with
  adversarial learning for end-to-end text-to-speech,'' in \emph{International
  Conference on Machine Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR,
  2021, pp. 5530--5540.

\bibitem{laptev2020you}
A.~Laptev, R.~Korostik, A.~Svischev, A.~Andrusenko, I.~Medennikov, and
  S.~Rybin, ``You do not need more data: Improving end-to-end speech
  recognition by text-to-speech data augmentation,'' in \emph{2020 13th
  International Congress on Image and Signal Processing, BioMedical Engineering
  and Informatics (CISP-BMEI)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE,
  2020, pp. 439--444.

\bibitem{wang2021towards}
W.~Wang, Z.~Zhou, Y.~Lu, H.~Wang, C.~Du, and Y.~Qian, ``Towards data selection
  on {TTS} data for children’s speech recognition,'' in \emph{2021 IEEE
  International Conference on Acoustics, Speech and Signal Processing
  (ICASSP)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2021, pp. 6888--6892.

\bibitem{liu2003noise}
F.-H. Liu, Y.~Gao, L.~Gu, and M.~Picheny, ``Noise robustness in speech to
  speech translation,'' in \emph{Eighth European Conference on Speech
  Communication and Technology}, 2003.

\bibitem{whitenoise}
\BIBentryALTinterwordspacing
C.~Ris and S.~Dupont, ``Assessing local noise level estimation methods:
  Application to noise robust asr,'' \emph{Speech Communication}, vol.~34,
  no.~1, pp. 141--158, 2001, noise Robust ASR. [Online]. Available:
  \url{https://www.sciencedirect.com/science/article/pii/S0167639300000510}
\BIBentrySTDinterwordspacing

\bibitem{gelin2020babble}
L.~Gelin, M.~Daniel, T.~Pellegrini, and J.~Pinquier, ``Babble noise
  augmentation for phone recognition applied to children reading aloud in a
  classroom environment,'' in \emph{Speech in Noise Workshop (SPiN)}, 2020.

\bibitem{couvreur2000use}
L.~Couvreur and C.~Couvreur, ``On the use of artificial reverberation for asr
  in highly reverberant environments,'' in \emph{Proc. 2nd IEEE Benelux Signal
  Processing Symposium (SPS-2000), Hilvarenbeek, The Netherlands}.\hskip 1em
  plus 0.5em minus 0.4em\relax Citeseer, 2000, pp. S001--S004.

\bibitem{malek2017robust}
J.~Malek, J.~Zdansky, and P.~Cerva, ``Robust automatic recognition of speech
  with background music,'' in \emph{2017 IEEE International Conference on
  Acoustics, Speech and Signal Processing (ICASSP)}.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 2017, pp. 5210--5214.

\bibitem{lo2020ntnu}
T.-H. Lo, F.-A. Chao, S.-Y. Weng, and B.~Chen, ``{The NTNU System at the
  Interspeech 2020 Non-Native Children’s Speech ASR Challenge},'' in
  \emph{Proc. Interspeech 2020}, 2020, pp. 250--254.

\bibitem{singh2022spectral}
V.~P. Singh, H.~Sailor, S.~Bhattacharya, and A.~Pandey, ``{Spectral
  Modification Based Data Augmentation For Improving End-to-End ASR For
  Children’s Speech},'' in \emph{Proc. Interspeech 2022}, 2022, pp.
  3213--3217.

\bibitem{VTLP}
N.~Jaitly and G.~E. Hinton, ``Vocal tract length perturbation (vtlp) improves
  speech recognition,'' in \emph{Proc. ICML Workshop on Deep Learning for
  Audio, Speech and Language}, vol. 117, 2013, p.~21.

\bibitem{specaugment}
D.~S. Park, W.~Chan, Y.~Zhang, C.-C. Chiu, B.~Zoph, E.~D. Cubuk, and Q.~V. Le,
  ``Specaugment: A simple augmentation method for automatic speech
  recognition,'' in \emph{INTERSPEECH}, 2019.

\bibitem{gelin2021simulating}
L.~Gelin, T.~Pellegrini, J.~Pinquier, and M.~Daniel, ``Simulating reading
  mistakes for child speech transformer-based phone recognition,'' in
  \emph{Annual Conference of the International Speech Communication Association
  (INTERSPEECH)}, 2021.

\bibitem{asr-improved2}
D.~Elenius and M.~Blomberg, ``Adaptation and normalization experiments in
  speech recognition for 4 to 8 year old children.'' in \emph{Interspeech},
  2005, pp. 2749--2752.

\bibitem{tfbased}
Y.~Bengio, A.~Courville, and P.~Vincent, ``Representation learning: A review
  and new perspectives,'' \emph{IEEE Transactions on Pattern Analysis and
  Machine Intelligence}, vol.~35, no.~8, pp. 1798--1828, 2013.

\bibitem{yosinski2014transferable}
\BIBentryALTinterwordspacing
J.~Yosinski, J.~Clune, Y.~Bengio, and H.~Lipson, ``How transferable are
  features in deep neural networks?'' in \emph{Advances in Neural Information
  Processing Systems}, Z.~Ghahramani, M.~Welling, C.~Cortes, N.~Lawrence, and
  K.~Weinberger, Eds., vol.~27.\hskip 1em plus 0.5em minus 0.4em\relax Curran
  Associates, Inc., 2014. [Online]. Available:
  \url{https://proceedings.neurips.cc/paper_files/paper/2014/file/375c71349b295fbe2dcdca9206f20a06-Paper.pdf}
\BIBentrySTDinterwordspacing

\bibitem{tfcharacter}
D.~C. Cireşan, U.~Meier, and J.~Schmidhuber, ``Transfer learning for latin and
  chinese characters with deep neural networks,'' in \emph{The 2012
  International Joint Conference on Neural Networks (IJCNN)}, 2012, pp. 1--6.

\bibitem{tfpathology}
R.~Takashima, T.~Takiguchi, and Y.~Ariki, ``Two-step acoustic model adaptation
  for dysarthric speech recognition,'' in \emph{ICASSP}, 2020, pp. 6104--6108.

\bibitem{TransferLF}
R.~Tong, L.~Wang, and B.~Ma, ``Transfer learning for children's speech
  recognition,'' \emph{2017 International Conference on Asian Language
  Processing (IALP)}, pp. 36--39, 2017.

\bibitem{zhang2018overview}
Y.~Zhang and Q.~Yang, ``An overview of multi-task learning,'' \emph{National
  Science Review}, vol.~5, no.~1, pp. 30--43, 2018.

\bibitem{multi-nlp}
\BIBentryALTinterwordspacing
R.~Collobert and J.~Weston, ``A unified architecture for natural language
  processing: Deep neural networks with multitask learning,'' in \emph{ICML},
  ser. ICML '08.\hskip 1em plus 0.5em minus 0.4em\relax New York, NY, USA:
  Association for Computing Machinery, 2008, p. 160–167. [Online]. Available:
  \url{https://doi.org/10.1145/1390156.1390177}
\BIBentrySTDinterwordspacing

\bibitem{mtl_computervision}
R.~Girshick, ``{Fast R-CNN},'' in \emph{Proceedings of the IEEE international
  conference on computer vision}, 2015, pp. 1440--1448.

\bibitem{bioinfo}
L.~Xie, S.~He, Z.~Zhang, K.~Lin, X.~Bo, S.~Yang, B.~Feng, K.~Wan, K.~Yang,
  J.~Yang \emph{et~al.}, ``Domain-adversarial multi-task framework for novel
  therapeutic property prediction of compounds,'' \emph{Bioinformatics},
  vol.~36, no.~9, pp. 2848--2855, 2020.

\bibitem{MTL-LFMMI}
S.~R. Madikeri, B.~K. Khonglah, S.~Tong, P.~Motlicek, H.~Bourlard, and
  D.~Povey, ``Lattice-free maximum mutual information training of multilingual
  speech recognition systems.'' in \emph{INTERSPEECH}, 2020, pp. 4746--4750.

\bibitem{abad2020}
A.~Abad, P.~Bell, A.~Carmantini, and S.~Renais, ``Cross lingual transfer
  learning for zero-resource domain adaptation,'' in \emph{ICASSP}, 2020, pp.
  6909--6913.

\bibitem{2019multi}
L.~Wei, W.~Dong, B.~Lin, and J.~Zhang, ``Multi-task based mispronunciation
  detection of children speech using multi-lingual information,'' in
  \emph{APSIPA ASC}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2019, pp.
  1791--1794.

\bibitem{zavaliagkos1998utilizing}
G.~Zavaliagkos, M.-H. Siu, T.~Colthurst, and J.~Billa, ``{Using untranscribed
  training data to improve performance},'' in \emph{Proc. 5th International
  Conference on Spoken Language Processing (ICSLP 1998)}, 1998, p. paper 1007.

\bibitem{ma2006unsupervised}
J.~Ma, S.~Matsoukas, O.~Kimball, and R.~Schwartz, ``Unsupervised training on
  large amounts of broadcast news data,'' in \emph{2006 IEEE International
  Conference on Acoustics Speech and Signal Processing Proceedings},
  vol.~3.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2006, pp. III--III.

\bibitem{sarzynska2021detecting}
J.~Sarzynska-Wawer, A.~Wawer, A.~Pawlak, J.~Szymanowska, I.~Stefaniak,
  M.~Jarkiewicz, and L.~Okruszek, ``Detecting formal thought disorder by deep
  contextualized word representations,'' \emph{Psychiatry Research}, vol. 304,
  p. 114135, 2021.

\bibitem{henaff2020data}
O.~Henaff, ``Data-efficient image recognition with contrastive predictive
  coding,'' in \emph{International conference on machine learning}.\hskip 1em
  plus 0.5em minus 0.4em\relax PMLR, 2020, pp. 4182--4192.

\bibitem{Pascual2019}
S.~Pascual, M.~Ravanelli, J.~Serrà, A.~Bonafonte, and Y.~Bengio, ``{Learning
  Problem-Agnostic Speech Representations from Multiple Self-Supervised
  Tasks},'' in \emph{Proceedings of Interspeech 2019}, Graz, Austria, 2019, pp.
  161--165.

\bibitem{Ravanelli2020}
M.~Ravanelli, J.~Zhong, S.~Pascual, P.~Swietojanski, J.~Monteiro, J.~Trmal, and
  Y.~Bengio, ``{Multi-Task Self-Supervised Learning for Robust Speech
  Recognition},'' in \emph{{2020 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}}, 2020, pp. 6989--6993.

\bibitem{baevski2020wav2vec}
A.~Baevski, Y.~Zhou, A.~Mohamed, and M.~Auli, ``wav2vec 2.0: A framework for
  self-supervised learning of speech representations,'' \emph{Advances in
  Neural Information Processing Systems}, vol.~33, pp. 12\,449--12\,460, 2020.

\bibitem{hsu2021hubert}
W.-N. Hsu, B.~Bolte, Y.-H.~H. Tsai, K.~Lakhotia, R.~Salakhutdinov, and
  A.~Mohamed, ``Hubert: Self-supervised speech representation learning by
  masked prediction of hidden units,'' \emph{IEEE/ACM Transactions on Audio,
  Speech, and Language Processing}, vol.~29, pp. 3451--3460, 2021.

\bibitem{riviere2020unsupervised}
M.~Riviere, A.~Joulin, P.-E. Mazar{\'e}, and E.~Dupoux, ``Unsupervised
  pretraining transfers well across languages,'' in \emph{IEEE International
  Conference on Acoustics, Speech and Signal Processing (ICASSP)}.\hskip 1em
  plus 0.5em minus 0.4em\relax IEEE, 2020, pp. 7414--7418.

\bibitem{wang2022wav2vec}
Y.~Wang, J.~Li, H.~Wang, Y.~Qian, C.~Wang, and Y.~Wu, ``Wav2vec-switch:
  Contrastive learning from original-noisy speech pairs for robust speech
  recognition,'' in \emph{2022 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 2022, pp. 7097--7101.

\bibitem{li2021accent}
J.~Li, V.~Manohar, P.~Chitkara, A.~Tjandra, M.~Picheny, F.~Zhang, X.~Zhang, and
  Y.~Saraf, ``Accent-robust automatic speech recognition using supervised and
  unsupervised wav2vec embeddings,'' \emph{arXiv preprint arXiv:2110.03520},
  2021.

\bibitem{xu2021tal}
G.~Xu, S.~Yang, L.~Ma, C.~Li, and Z.~Wu, ``{The TAL System for the
  INTERSPEECH2021 Shared Task on Automatic Speech Recognition for Non-Native
  Childrens Speech.}'' in \emph{Interspeech}, 2021, pp. 1294--1298.

\bibitem{jain2023wav2vec2}
R.~Jain, A.~Barcovschi, M.~Y. Yiwere, D.~Bigioi, P.~Corcoran, and H.~Cucu, ``{A
  WAV2VEC2-Based Experimental Study on Self-Supervised Learning Methods to
  Improve Child Speech Recognition},'' \emph{IEEE Access}, vol.~11, pp.
  46\,938--46\,948, 2023.

\bibitem{jain2023adaptation}
R.~Jain, A.~Barcovschi, M.~Yiwere, P.~Corcoran, and H.~Cucu, ``{Adaptation of
  Whisper models to child speech recognition},'' in \emph{Proc. INTERSPEECH
  2023}, 2023, pp. 5242--5246.

\bibitem{fan2022draft}
R.~Fan and A.~Alwan, ``{DRAFT: A Novel Framework to Reduce Domain Shifting in
  Self-supervised Learning and Its Application to Children’s ASR},'' in
  \emph{Proc. Interspeech 2022}, 2022, pp. 4900--4904.

\bibitem{providence}
K.~Demuth, J.~Culbertson, and J.~Alter, ``Word-minimality, epenthesis and coda
  licensing in the early acquisition of english,'' \emph{Language and speech},
  vol.~49, no.~2, pp. 137--173, 2006.

\bibitem{LyonSC}
K.~Demuth and A.~Tremblay, ``Prosodically-conditioned variability in children's
  production of french determiners,'' \emph{Journal of child language},
  vol.~35, no.~1, pp. 99--127, 2008.

\bibitem{cass_child}
J.~Gao, A.~Li, and Z.~Xiong, ``Mandarin multimedia child speech corpus:
  Cass\_child,'' in \emph{2012 International Conference on Speech Database and
  Assessments}, 2012, pp. 7--12.

\bibitem{demuth1992acquisition}
K.~Demuth, ``The acquisition of sesotho,'' in \emph{The crosslinguistic study
  of language acquisition}.\hskip 1em plus 0.5em minus 0.4em\relax Psychology
  Press, 1992, pp. 557--638.

\bibitem{nitk}
P.~B. Ramteke, S.~Supanekar, P.~Hegde, H.~Nelson, V.~Aithal, and S.~G.
  Koolagudi, ``{NITK Kids’ Speech Corpus},'' in \emph{Proc. Interspeech
  2019}, 2019, pp. 331--335.

\bibitem{chiede}
M.~Garrote and A.~Moreno~Sandoval, ``Chiede, a spontaneous child language
  corpus of spanish,'' in \emph{Proceedings of the 3rd International LABLITA
  Workshop in Corpus Linguistics}, 2008.

\bibitem{cuchild}
S.-I. Ng, C.~W.-Y. Ng, J.~Wang, T.~Lee, K.~Y.-S. Lee, and M.~C.-F. Tong,
  ``{CUCHILD: A Large-Scale Cantonese Corpus of Child Speech for Phonology and
  Articulation Assessment},'' in \emph{Proc. Interspeech 2020}, 2020, pp.
  424--428.

\bibitem{emochildru}
E.~Lyakso, O.~Frolova, E.~Dmitrieva, A.~Grigorev, H.~Kaya, A.~A. Salah, and
  A.~Karpov, ``Emochildru: emotional child russian speech corpus,'' in
  \emph{International Conference on Speech and Computer}.\hskip 1em plus 0.5em
  minus 0.4em\relax Springer, 2015, pp. 144--152.

\bibitem{hamalainen2013cng}
A.~H{\"a}m{\"a}l{\"a}inen, S.~Rodrigues, A.~J{\'u}dice, S.~M. Silva, A.~Calado,
  F.~M. Pinto, and M.~S. Dias, ``{The CNG corpus of European Portuguese
  children’s speech},'' in \emph{International Conference on Text, Speech and
  Dialogue}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2013, pp.
  544--551.

\bibitem{yeung2019robotic}
G.~Yeung, A.~L. Bailey, A.~Afshan, M.~Tinkler, M.~Q. P{\'e}rez, A.~Martin,
  A.~A. Pogossian, S.~Spaulding, H.~W. Park, M.~Muco \emph{et~al.}, ``A robotic
  interface for the administration of language, literacy, and speech pathology
  assessments for children.'' in \emph{SLaTE}, 2019, pp. 41--42.

\bibitem{yu2021slt}
F.~Yu, Z.~Yao, X.~Wang, K.~An, L.~Xie, Z.~Ou, B.~Liu, X.~Li, and G.~Miao,
  ``{The SLT 2021 children speech recognition challenge: Open datasets, rules
  and baselines},'' in \emph{2021 IEEE Spoken Language Technology Workshop
  (SLT)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2021, pp. 1117--1123.

\bibitem{ad-child_ru}
E.~Lyakso, O.~Frolova, A.~Kaliyev, V.~Gorodnyi, A.~Grigorev, and Y.~Matveev,
  ``{AD-Child RU: Speech corpus for Russian children with atypical
  development},'' in \emph{International Conference on Speech and
  Computer}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2019, pp.
  299--308.

\bibitem{tball}
A.~Kazemzadeh, H.~You, M.~Iseli, B.~Jones, X.~Cui, M.~Heritage, P.~Price,
  E.~Anderson, S.~Narayanan, and A.~Alwan, ``Tball data collection: the making
  of a young children's speech corpus,'' in \emph{Ninth European Conference on
  Speech Communication and Technology}, 2005.

\bibitem{speco}
F.~Csat{\'a}ri, Z.~Bakcsi, and K.~Vicsi, ``{A Hungarian child database for
  speech processing applications},'' in \emph{Sixth European Conference on
  Speech Communication and Technology}, 1999.

\bibitem{eshky2019ultrasuite}
A.~Eshky, M.~S. Ribeiro, J.~Cleland, K.~Richmond, Z.~Roxburgh, J.~M. Scobbie,
  and A.~Wrench, ``{UltraSuite: A Repository of Ultrasound and Acoustic Data
  from Child Speech Therapy Sessions},'' in \emph{Proc. Interspeech 2018},
  2018, pp. 1888--1892.

\bibitem{khanzadi2022persian}
M.~Khanzadi, H.~Veisi, R.~Alinaghizade, and Z.~Soleymani, ``Persian phoneme and
  syllable recognition using recurrent neural networks for phonological
  awareness assessment,'' \emph{Journal of AI and Data Mining}, vol.~10, no.~1,
  pp. 117--126, 2022.

\bibitem{letsread}
J.~Proen{\c{c}}a, D.~Celorico, S.~Candeias, C.~Lopes, and F.~Perdig{\~a}o,
  ``{The LetsRead corpus of Portuguese children reading aloud for performance
  evaluation},'' in \emph{Proceedings of the Tenth International Conference on
  Language Resources and Evaluation (LREC'16)}, 2016, pp. 781--785.

\bibitem{CFSC}
R.~M. Pascual and R.~C.~L. Guevara, ``Developing a children's filipino speech
  corpus for application in automatic detection of reading miscues and
  disfluencies,'' in \emph{TENCON 2012 IEEE Region 10 Conference}, 2012, pp.
  1--6.

\bibitem{PEREZESPINOSA202055}
\BIBentryALTinterwordspacing
H.~Pérez-Espinosa, J.~Martínez-Miranda, I.~Espinosa-Curiel,
  J.~Rodríguez-Jacobo, L.~Villaseñor-Pineda, and H.~Avila-George,
  ``{IESC-Child: An Interactive Emotional Children’s Speech Corpus},''
  \emph{Computer Speech \& Language}, vol.~59, pp. 55--74, 2020. [Online].
  Available:
  \url{https://www.sciencedirect.com/science/article/pii/S0885230817301547}
\BIBentrySTDinterwordspacing

\bibitem{hagen2003children}
A.~Hagen, B.~Pellom, and R.~Cole, ``Children's speech recognition with
  application to interactive books and tutors,'' in \emph{2003 IEEE Workshop on
  Automatic Speech Recognition and Understanding (IEEE Cat. No.
  03EX721)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2003, pp. 186--191.

\bibitem{chorec}
L.~Cleuren, J.~Duchateau, P.~Ghesquiere \emph{et~al.}, ``{Children’s oral
  reading corpus (CHOREC): description and assessment of annotator
  agreement},'' \emph{LREC 2008 Proceedings}, pp. 998--1005, 2008.

\bibitem{childit2}
P.~Cosi, G.~Paci, G.~Sommavilla, and F.~Tesser, ``Childit2--a new children read
  speech corpus,'' \emph{Book series Studi AISV}, vol.~2, pp. 269--273, 2016.

\bibitem{leonard1993tidigits}
R.~Leonard, ``A database for speaker-independent digit recognition,'' in
  \emph{ICASSP '84. IEEE International Conference on Acoustics, Speech, and
  Signal Processing}, vol.~9, 1984, pp. 328--331.

\bibitem{gerosa2006acoustic}
M.~Gerosa, ``Acoustic modeling for automatic recognition of children’s
  speech,'' Ph.D. dissertation, Ph. D. thesis, University of Trento, 2006.

\bibitem{burkhardt2010database}
F.~Burkhardt, M.~Eckert, W.~Johannsen, and J.~Stegmann, ``A database of age and
  gender annotated telephone speech,'' in \emph{Proceedings of the Seventh
  International Conference on Language Resources and Evaluation (LREC'10)},
  2010.

\bibitem{JASMIN}
\BIBentryALTinterwordspacing
C.~Cucchiarini, J.~Driesen, H.~Van~hamme, and E.~Sanders, ``Recording speech of
  children, non-natives and elderly people for {HLT} applications: the
  {JASMIN}-{CGN} corpus.'' in \emph{Proceedings of the Sixth International
  Conference on Language Resources and Evaluation ({LREC}'08)}.\hskip 1em plus
  0.5em minus 0.4em\relax Marrakech, Morocco: European Language Resources
  Association (ELRA), May 2008. [Online]. Available:
  \url{http://www.lrec-conf.org/proceedings/lrec2008/pdf/366_paper.pdf}
\BIBentrySTDinterwordspacing

\bibitem{bell2005swedish}
L.~Bell, J.~Boye, J.~Gustafson, M.~Heldner, A.~Lindstr{\"o}m, and M.~Wir{\'e}n,
  ``The swedish nice corpus--spoken dialogues between children and embodied
  characters in a computer game scenario,'' in \emph{Interspeech
  2005-Eurospeech, 9th European Conference on Speech Communication and
  Technology, Lisbon, Portugal, September 4-8, 2005}.\hskip 1em plus 0.5em
  minus 0.4em\relax ISCA, 2005, pp. 2765--2768.

\bibitem{SPEECONS}
D.~J. Iskra, B.~Grosskopf, K.~Marasek, H.~van~den Heuvel, F.~Diehl, and
  A.~Kiessling, ``Speecon – speech databases for consumer devices: Database
  specification and validation,'' in \emph{LREC}, 2002.

\bibitem{etlt}
\BIBentryALTinterwordspacing
R.~Gretter, M.~Matassoni, S.~Bann{\`o}, and F.~Daniele,
  ``\BIBforeignlanguage{English}{{TLT}-school: a corpus of non native children
  speech},'' in \emph{\BIBforeignlanguage{English}{Proceedings of the Twelfth
  Language Resources and Evaluation Conference - LREC}}.\hskip 1em plus 0.5em
  minus 0.4em\relax Marseille, France: European Language Resources Association,
  May 2020, pp. 378--385. [Online]. Available:
  \url{https://aclanthology.org/2020.lrec-1.47}
\BIBentrySTDinterwordspacing

\bibitem{grissemann2000zurcher}
H.~Grissemann and M.~Linder, ``Z{\"u}rcher lesetest,'' \emph{Bern: Huber
  Verlag}, 2000.

\bibitem{steidl2009automatic}
S.~Steidl, \emph{Automatic classification of emotion related user states in
  spontaneous children's speech}.\hskip 1em plus 0.5em minus 0.4em\relax
  Logos-Verlag Berlin, Germany, 2009.

\bibitem{bell2003child}
L.~Bell and J.~Gustafson, ``{Child and adult speaker adaptation during error
  resolution in a publicly available spoken dialogue system},'' in \emph{Proc.
  8th European Conference on Speech Communication and Technology (Eurospeech
  2003)}, 2003, pp. 613--616.

\bibitem{takemaru}
R.~Nisimura, A.~Lee, H.~Saruwatari, and K.~Shikano, ``Public speech-oriented
  guidance system with adult and child discrimination capability,'' in
  \emph{2004 IEEE International Conference on Acoustics, Speech, and Signal
  Processing}, vol.~1.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2004, pp.
  I--433.

\bibitem{callslt}
M.~Rayner, N.~Tsourakis, C.~Baur, P.~Bouillon, and J.~Gerlach, ``Call-slt: A
  spoken call system: based on grammar and speech recognition,''
  \emph{Linguistic Issues in Language Technology}, vol.~10, 01 2014.

\bibitem{sphinx2}
\BIBentryALTinterwordspacing
X.~Huang, F.~Alleva, M.-Y. Hwang, and R.~Rosenfeld, ``An overview of the
  sphinx-ii speech recognition system,'' in \emph{Proceedings of the Workshop
  on Human Language Technology}, ser. HLT '93.\hskip 1em plus 0.5em minus
  0.4em\relax USA: Association for Computational Linguistics, 1993, p. 81–86.
  [Online]. Available: \url{https://doi.org/10.3115/1075671.1075690}
\BIBentrySTDinterwordspacing

\bibitem{big_review_childASR}
V.~Bhardwaj, V.~Kukreja, Y.~Belkhier, M.~Bajaj, S.~G. .B, A.~Rehman, H.~Hamam,
  and M.~Othman, ``Automatic speech recognition ({ASR}) system for
  children’s: A systematic literature review,'' \emph{Applied Sciences}, 04
  2022.

\bibitem{tribus}
C.~F. Carvalho and A.~Abad, ``Tribus: An end-to-end automatic speech
  recognition system for european portuguese,'' \emph{IberSPEECH 2021}, 2021.

\bibitem{bdpublico}
J.~P. Neto, C.~A. Martins, H.~Meinedo, and L.~B. Almeida, ``The design of a
  large vocabulary speech corpus for portuguese,'' in \emph{Fifth European
  Conference on Speech Communication and Technology}, 1997.

\bibitem{ssc}
K.~Paliwal, ``Spectral subband centroid features for speech recognition,'' in
  \emph{ICASSP}, vol.~2, 1998, pp. 617--620 vol.2.

\bibitem{babu2021xlsr}
A.~Babu, C.~Wang, A.~Tjandra, K.~Lakhotia, Q.~Xu, N.~Goyal, K.~Singh, P.~{von
  Platen}, Y.~Saraf, J.~Pino, A.~Baevski, A.~Conneau, and M.~Auli, ``{XLS-R:
  Self-supervised Cross-lingual Speech Representation Learning at Scale},'' in
  \emph{Proc. Interspeech 2022}, 2022, pp. 2278--2282.

\bibitem{zeyer2019comparison}
A.~Zeyer, P.~Bahar, K.~Irie, R.~Schl{\"u}ter, and H.~Ney, ``A comparison of
  transformer and lstm encoder decoder models for asr,'' in \emph{2019 IEEE
  Automatic Speech Recognition and Understanding Workshop (ASRU)}.\hskip 1em
  plus 0.5em minus 0.4em\relax IEEE, 2019, pp. 8--15.

\bibitem{zeineldeen2022Conformer}
M.~Zeineldeen, J.~Xu, C.~L{\"u}scher, W.~Michel, A.~Gerstenberger,
  R.~Schl{\"u}ter, and H.~Ney, ``Conformer-based hybrid asr system for
  switchboard dataset,'' in \emph{ICASSP 2022-2022 IEEE International
  Conference on Acoustics, Speech and Signal Processing (ICASSP)}.\hskip 1em
  plus 0.5em minus 0.4em\relax IEEE, 2022, pp. 7437--7441.

\bibitem{luscher2019rwth}
C.~Lüscher, E.~Beck, K.~Irie, M.~Kitza, W.~Michel, A.~Zeyer, R.~Schlüter, and
  H.~Ney, ``{RWTH ASR Systems for LibriSpeech: Hybrid vs Attention},'' in
  \emph{Proc. Interspeech 2019}, 2019, pp. 231--235.

\bibitem{soltau2016neural}
H.~Soltau, H.~Liao, and H.~Sak, ``{Neural Speech Recognizer: Acoustic-to-Word
  LSTM Model for Large Vocabulary Speech Recognition},'' in \emph{Proc.
  Interspeech 2017}, 2017, pp. 3707--3711.

\bibitem{battenberg2017exploring}
E.~Battenberg, J.~Chen, R.~Child, A.~Coates, Y.~G.~Y. Li, H.~Liu, S.~Satheesh,
  A.~Sriram, and Z.~Zhu, ``Exploring neural transducers for end-to-end speech
  recognition,'' in \emph{2017 IEEE Automatic Speech Recognition and
  Understanding Workshop (ASRU)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE,
  2017, pp. 206--213.

\bibitem{dosovitskiy2020image}
\BIBentryALTinterwordspacing
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai,
  T.~Unterthiner, M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly, J.~Uszkoreit,
  and N.~Houlsby, ``An image is worth 16x16 words: Transformers for image
  recognition at scale,'' in \emph{International Conference on Learning
  Representations}, 2021. [Online]. Available:
  \url{https://openreview.net/forum?id=YicbFdNTTy}
\BIBentrySTDinterwordspacing

\bibitem{bahrini2023chatgpt}
A.~Bahrini, M.~Khamoshifar, H.~Abbasimehr, R.~J. Riggs, M.~Esmaeili, R.~M.
  Majdabadkohne, and M.~Pasehvar, ``Chatgpt: Applications, opportunities, and
  threats,'' in \emph{2023 Systems and Information Engineering Design Symposium
  (SIEDS)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2023, pp. 274--279.

\bibitem{ramesh2021zero}
A.~Ramesh, M.~Pavlov, G.~Goh, S.~Gray, C.~Voss, A.~Radford, M.~Chen, and
  I.~Sutskever, ``Zero-shot text-to-image generation,'' in \emph{International
  Conference on Machine Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR,
  2021, pp. 8821--8831.

\bibitem{bello2019attention}
I.~Bello, B.~Zoph, A.~Vaswani, J.~Shlens, and Q.~V. Le, ``Attention augmented
  convolutional networks,'' in \emph{Proceedings of the IEEE/CVF international
  conference on computer vision}, 2019, pp. 3286--3295.

\bibitem{yang2019convolutional}
\BIBentryALTinterwordspacing
B.~Yang, L.~Wang, D.~F. Wong, L.~S. Chao, and Z.~Tu, ``Convolutional
  self-attention networks,'' in \emph{Proceedings of the 2019 Conference of the
  North {A}merican Chapter of the Association for Computational Linguistics:
  Human Language Technologies, Volume 1 (Long and Short Papers)}.\hskip 1em
  plus 0.5em minus 0.4em\relax Minneapolis, Minnesota: Association for
  Computational Linguistics, Jun. 2019, pp. 4040--4045. [Online]. Available:
  \url{https://aclanthology.org/N19-1407}
\BIBentrySTDinterwordspacing

\bibitem{gulati2020conformer}
A.~Gulati, J.~Qin, C.-C. Chiu, N.~Parmar, Y.~Zhang, J.~Yu, W.~Han, S.~Wang,
  Z.~Zhang, Y.~Wu, and R.~Pang, ``{Conformer: Convolution-augmented Transformer
  for Speech Recognition},'' in \emph{Proc. Interspeech 2020}, 2020, pp.
  5036--5040.

\bibitem{lu2019understanding}
Y.~Lu, Z.~Li, D.~He, Z.~Sun, B.~Dong, T.~Qin, L.~Wang, and T.-Y. Liu,
  ``Understanding and improving transformer from a multi-particle dynamic
  system point of view,'' \emph{arXiv preprint arXiv:1906.02762}, 2019.

\bibitem{wu2020lite}
\BIBentryALTinterwordspacing
Z.~Wu, Z.~Liu, J.~Lin, Y.~Lin, and S.~Han, ``Lite transformer with long-short
  range attention,'' in \emph{8th International Conference on Learning
  Representations, {ICLR} 2020, Addis Ababa, Ethiopia, April 26-30,
  2020}.\hskip 1em plus 0.5em minus 0.4em\relax OpenReview.net, 2020. [Online].
  Available: \url{https://openreview.net/forum?id=ByeMPlHKPH}
\BIBentrySTDinterwordspacing

\bibitem{dauphin2017language}
Y.~N. Dauphin, A.~Fan, M.~Auli, and D.~Grangier, ``Language modeling with gated
  convolutional networks,'' in \emph{International conference on machine
  learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2017, pp. 933--941.

\bibitem{Prajit2017Searching}
\BIBentryALTinterwordspacing
P.~Ramachandran, B.~Zoph, and Q.~V. Le, ``Searching for activation functions,''
  in \emph{6th International Conference on Learning Representations, {ICLR}
  2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Workshop Track
  Proceedings}.\hskip 1em plus 0.5em minus 0.4em\relax OpenReview.net, 2018.
  [Online]. Available: \url{https://openreview.net/forum?id=Hkuq2EkPf}
\BIBentrySTDinterwordspacing

\bibitem{kovaleva-etal-2019-revealing}
\BIBentryALTinterwordspacing
O.~Kovaleva, A.~Romanov, A.~Rogers, and A.~Rumshisky, ``Revealing the dark
  secrets of {BERT},'' in \emph{Proceedings of the 2019 Conference on Empirical
  Methods in Natural Language Processing and the 9th International Joint
  Conference on Natural Language Processing (EMNLP-IJCNLP)}, K.~Inui, J.~Jiang,
  V.~Ng, and X.~Wan, Eds.\hskip 1em plus 0.5em minus 0.4em\relax Hong Kong,
  China: Association for Computational Linguistics, Nov. 2019, pp. 4365--4374.
  [Online]. Available: \url{https://aclanthology.org/D19-1445}
\BIBentrySTDinterwordspacing

\bibitem{michel2019sixteen}
P.~Michel, O.~Levy, and G.~Neubig, ``Are sixteen heads really better than
  one?'' \emph{Advances in neural information processing systems}, vol.~32,
  2019.

\bibitem{ye2023partial}
P.~Ye, Y.~Huang, C.~Tu, M.~Li, T.~Chen, T.~He, and W.~Ouyang, ``Partial
  fine-tuning: A successor to full fine-tuning for vision transformers,''
  \emph{arXiv preprint arXiv:2312.15681}, 2023.

\bibitem{mccarley2019structured}
J.~McCarley, R.~Chakravarti, and A.~Sil, ``Structured pruning of a bert-based
  question answering model,'' \emph{arXiv preprint arXiv:1910.06360}, 2019.

\bibitem{sanh2019distilbert}
V.~Sanh, L.~Debut, J.~Chaumond, and T.~Wolf, ``Distilbert, a distilled version
  of bert: smaller, faster, cheaper and lighter,'' \emph{arXiv preprint
  arXiv:1910.01108}, 2019.

\bibitem{shen2021partial}
Z.~Shen, Z.~Liu, J.~Qin, M.~Savvides, and K.-T. Cheng, ``Partial is better than
  all: revisiting fine-tuning strategy for few-shot learning,'' in
  \emph{Proceedings of the AAAI Conference on Artificial Intelligence},
  vol.~35, no.~11, 2021, pp. 9594--9602.

\bibitem{wang2021fine}
Y.~Wang, A.~Boumadane, and A.~Heba, ``A fine-tuned wav2vec 2.0/hubert benchmark
  for speech emotion recognition, speaker verification and spoken language
  understanding,'' \emph{arXiv preprint arXiv:2111.02735}, 2021.

\bibitem{frankle2018lottery}
\BIBentryALTinterwordspacing
J.~Frankle and M.~Carbin, ``The lottery ticket hypothesis: Finding sparse,
  trainable neural networks,'' in \emph{International Conference on Learning
  Representations}, 2019. [Online]. Available:
  \url{https://openreview.net/forum?id=rJl-b3RcF7}
\BIBentrySTDinterwordspacing

\bibitem{gandhi2023distilwhisper}
S.~Gandhi, P.~von Platen, and A.~M. Rush, ``Distil-whisper: Robust knowledge
  distillation via large-scale pseudo labelling,'' \emph{arXiv preprint
  arXiv:2311.00430}, 2023.

\bibitem{chang2022distilhubert}
H.-J. Chang, S.-w. Yang, and H.-y. Lee, ``Distilhubert: Speech representation
  learning by layer-wise distillation of hidden-unit bert,'' in \emph{ICASSP
  2022-2022 IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2022, pp.
  7087--7091.

\bibitem{peng23c_interspeech}
Y.~Peng, Y.~Sudo, S.~Muhammad, and S.~Watanabe, ``{DPHuBERT: Joint Distillation
  and Pruning of Self-Supervised Speech Models},'' in \emph{Proc. INTERSPEECH
  2023}, 2023, pp. 62--66.

\bibitem{speechbrain}
M.~Ravanelli, T.~Parcollet, P.~Plantinga, A.~Rouhe, S.~Cornell, L.~Lugosch,
  C.~Subakan, N.~Dawalatabad, A.~Heba, J.~Zhong, J.-C. Chou, S.-L. Yeh, S.-W.
  Fu, C.-F. Liao, E.~Rastorgueva, F.~Grondin, W.~Aris, H.~Na, Y.~Gao, R.~D.
  Mori, and Y.~Bengio, ``{SpeechBrain}: A general-purpose speech toolkit,''
  2021, arXiv:2106.04624.

\bibitem{SCTK_nist}
{National Institute of Standards and technology}, ``{SCTK, the NIST Scoring
  Toolkit},'' 2021, accessed Febuary 11th, 2024.
  \url{https://www.yale.edu/about-yale/yale-facts}.

\bibitem{geva2020transformer}
M.~Geva, R.~Schuster, J.~Berant, and O.~Levy, ``Transformer feed-forward layers
  are key-value memories,'' in \emph{Empirical Methods in Natural Language
  Processing (EMNLP)}, 2021.

\bibitem{Kaplan2020ScalingLF}
\BIBentryALTinterwordspacing
J.~Kaplan, S.~McCandlish, T.~J. Henighan, T.~B. Brown, B.~Chess, R.~Child,
  S.~Gray, A.~Radford, J.~Wu, and D.~Amodei, ``Scaling laws for neural language
  models,'' \emph{ArXiv}, vol. abs/2001.08361, 2020. [Online]. Available:
  \url{https://api.semanticscholar.org/CorpusID:210861095}
\BIBentrySTDinterwordspacing

\bibitem{zheng22d_interspeech}
W.~Zheng, A.~Xiao, G.~Keren, D.~Le, F.~Zhang, C.~Fuegen, O.~Kalinli, Y.~Saraf,
  and A.~Mohamed, ``{Scaling ASR Improves Zero and Few Shot Learning},'' in
  \emph{Proc. Interspeech 2022}, 2022, pp. 5135--5139.

\bibitem{houlsby}
N.~Houlsby, A.~Giurgiu, S.~Jastrzebski, B.~Morrone, Q.~De~Laroussilhe,
  A.~Gesmundo, M.~Attariyan, and S.~Gelly, ``Parameter-efficient transfer
  learning for nlp,'' in \emph{International Conference on Machine
  Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2019, pp. 2790--2799.

\bibitem{pfeiffer}
J.~Pfeiffer, I.~Vuli{\'c}, I.~Gurevych, and S.~Ruder, ``{MAD-X}: {A}n
  {A}dapter-{B}ased {F}ramework for {M}ulti-{T}ask {C}ross-{L}ingual
  {T}ransfer,'' in \emph{Proceedings of the 2020 Conference on Empirical
  Methods in Natural Language Processing (EMNLP)}.\hskip 1em plus 0.5em minus
  0.4em\relax Online: Association for Computational Linguistics, Nov. 2020, pp.
  7654--7673.

\bibitem{ruckle2020adapterdrop}
\BIBentryALTinterwordspacing
A.~R{\"u}ckl{\'e}, G.~Geigle, M.~Glockner, T.~Beck, J.~Pfeiffer, N.~Reimers,
  and I.~Gurevych, ``{AdapterDrop}: {O}n the efficiency of adapters in
  transformers,'' in \emph{Proceedings of the 2021 Conference on Empirical
  Methods in Natural Language Processing}, M.-F. Moens, X.~Huang, L.~Specia,
  and S.~W.-t. Yih, Eds.\hskip 1em plus 0.5em minus 0.4em\relax Online and
  Punta Cana, Dominican Republic: Association for Computational Linguistics,
  Nov. 2021, pp. 7930--7946. [Online]. Available:
  \url{https://aclanthology.org/2021.emnlp-main.626}
\BIBentrySTDinterwordspacing

\bibitem{cappellazzo2023parameter}
U.~Cappellazzo, D.~Falavigna, A.~Brutti, and M.~Ravanelli,
  ``Parameter-efficient transfer learning of audio spectrogram transformers,''
  \emph{arXiv preprint arXiv:2312.03694}, 2023.

\bibitem{chen2023efficient}
N.~Chen, I.~Shafran, Y.~Zhang, C.-C. Chiu, H.~Soltau, J.~Qin, and Y.~Wu,
  ``Efficient adapters for giant speech models,'' \emph{arXiv preprint
  arXiv:2306.08131}, 2023.

\bibitem{10095837}
S.~V. Eeckt and H.~Van~Hamme, ``Using adapters to overcome catastrophic
  forgetting in end-to-end automatic speech recognition,'' in \emph{ICASSP 2023
  - 2023 IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP)}, 2023, pp. 1--5.

\bibitem{kannan2019large}
A.~Kannan, A.~Datta, T.~N. Sainath, E.~Weinstein, B.~Ramabhadran, Y.~Wu,
  A.~Bapna, Z.~Chen, and S.~Lee, ``{Large-Scale Multilingual Speech Recognition
  with a Streaming End-to-End Model},'' in \emph{Proc. Interspeech 2019}, 2019,
  pp. 2130--2134.

\bibitem{hou2021exploiting}
W.~Hou, H.~Zhu, Y.~Wang, J.~Wang, T.~Qin, R.~Xu, and T.~Shinozaki, ``Exploiting
  adapters for cross-lingual low-resource speech recognition,'' \emph{IEEE/ACM
  Transactions on Audio, Speech, and Language Processing}, vol.~30, pp.
  317--329, 2021.

\bibitem{kulkarni2023adapting}
A.~Kulkarni, A.~Kulkarni, M.~Couceiro, and H.~Aldarmaki, ``Adapting the
  adapters for code-switching in multilingual asr,'' \emph{arXiv preprint
  arXiv:2310.07423}, 2023.

\bibitem{thomas2022efficient}
B.~Thomas, S.~Kessler, and S.~Karout, ``Efficient adapter transfer of
  self-supervised speech models for automatic speech recognition,'' in
  \emph{ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE,
  2022, pp. 7102--7106.

\bibitem{tomanek2021residual}
\BIBentryALTinterwordspacing
K.~Tomanek, V.~Zayats, D.~Padfield, K.~Vaillancourt, and F.~Biadsy, ``Residual
  adapters for parameter-efficient {ASR} adaptation to atypical and accented
  speech,'' in \emph{Proceedings of the 2021 Conference on Empirical Methods in
  Natural Language Processing}.\hskip 1em plus 0.5em minus 0.4em\relax Online
  and Punta Cana, Dominican Republic: Association for Computational
  Linguistics, Nov. 2021, pp. 6751--6760. [Online]. Available:
  \url{https://aclanthology.org/2021.emnlp-main.541}
\BIBentrySTDinterwordspacing

\bibitem{he2022towards}
\BIBentryALTinterwordspacing
J.~He, C.~Zhou, X.~Ma, T.~Berg-Kirkpatrick, and G.~Neubig, ``Towards a unified
  view of parameter-efficient transfer learning,'' in \emph{International
  Conference on Learning Representations}, 2022. [Online]. Available:
  \url{https://openreview.net/forum?id=0RDcd5Axok}
\BIBentrySTDinterwordspacing

\bibitem{snyder2018x}
D.~Snyder, D.~Garcia-Romero, G.~Sell, D.~Povey, and S.~Khudanpur, ``X-vectors:
  Robust dnn embeddings for speaker recognition,'' in \emph{2018 IEEE
  international conference on acoustics, speech and signal processing
  (ICASSP)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2018, pp. 5329--5333.

\bibitem{glorot2010understanding}
X.~Glorot and Y.~Bengio, ``Understanding the difficulty of training deep
  feedforward neural networks,'' in \emph{Proceedings of the thirteenth
  international conference on artificial intelligence and statistics}.\hskip
  1em plus 0.5em minus 0.4em\relax JMLR Workshop and Conference Proceedings,
  2010, pp. 249--256.

\bibitem{fazel21_interspeech}
A.~Fazel, W.~Yang, Y.~Liu, R.~Barra-Chicote, Y.~Meng, R.~Maas, and J.~Droppo,
  ``{SynthASR: Unlocking Synthetic Data for Speech Recognition},'' in
  \emph{Proc. Interspeech 2021}, 2021, pp. 896--900.

\bibitem{hu2022synt++}
T.-Y. Hu, M.~Armandpour, A.~Shrivastava, J.-H.~R. Chang, H.~Koppula, and
  O.~Tuzel, ``Synt++: Utilizing imperfect synthetic data to improve speech
  recognition,'' in \emph{ICASSP 2022-2022 IEEE International Conference on
  Acoustics, Speech and Signal Processing (ICASSP)}.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 2022, pp. 7682--7686.

\bibitem{casanova2022asr}
E.~Casanova, C.~Shulby, A.~Korolev, A.~C. Junior, A.~da~Silva~Soares,
  S.~Aluísio, and M.~A. Ponti, ``{ASR data augmentation in low-resource
  settings using cross-lingual multi-speaker TTS and cross-lingual voice
  conversion},'' in \emph{Proc. INTERSPEECH 2023}, 2023, pp. 1244--1248.

\bibitem{9688218}
S.~Ueno, M.~Mimura, S.~Sakai, and T.~Kawahara, ``Data augmentation for asr
  using tts via a discrete representation,'' in \emph{2021 IEEE Automatic
  Speech Recognition and Understanding Workshop (ASRU)}, 2021, pp. 68--75.

\bibitem{vqwav2vec}
\BIBentryALTinterwordspacing
A.~Baevski, S.~Schneider, and M.~Auli, ``vq-wav2vec: Self-supervised learning
  of discrete speech representations,'' in \emph{8th International Conference
  on Learning Representations, {ICLR} 2020, Addis Ababa, Ethiopia, April 26-30,
  2020}.\hskip 1em plus 0.5em minus 0.4em\relax OpenReview.net, 2020. [Online].
  Available: \url{https://openreview.net/forum?id=rylwJxrYDS}
\BIBentrySTDinterwordspacing

\bibitem{philip2020monolingual}
J.~Philip, A.~Berard, M.~Gall{\'e}, and L.~Besacier, ``Monolingual adapters for
  zero-shot neural machine translation,'' in \emph{Proceedings of the 2020
  Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  2020, pp. 4465--4470.

\bibitem{mao-etal-2022-unipelt}
\BIBentryALTinterwordspacing
Y.~Mao, L.~Mathias, R.~Hou, A.~Almahairi, H.~Ma, J.~Han, S.~Yih, and M.~Khabsa,
  ``{U}ni{PELT}: A unified framework for parameter-efficient language model
  tuning,'' in \emph{Proceedings of the 60th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, S.~Muresan, P.~Nakov,
  and A.~Villavicencio, Eds.\hskip 1em plus 0.5em minus 0.4em\relax Dublin,
  Ireland: Association for Computational Linguistics, May 2022, pp. 6253--6264.
  [Online]. Available: \url{https://aclanthology.org/2022.acl-long.433}
\BIBentrySTDinterwordspacing

\bibitem{casanova2022yourtts}
\BIBentryALTinterwordspacing
E.~Casanova, J.~Weber, C.~D. Shulby, A.~C. Junior, E.~G{\"o}lge, and M.~A.
  Ponti, ``{Y}our{TTS}: Towards zero-shot multi-speaker {TTS} and zero-shot
  voice conversion for everyone,'' in \emph{Proceedings of the 39th
  International Conference on Machine Learning}, ser. Proceedings of Machine
  Learning Research, K.~Chaudhuri, S.~Jegelka, L.~Song, C.~Szepesvari, G.~Niu,
  and S.~Sabato, Eds., vol. 162.\hskip 1em plus 0.5em minus 0.4em\relax PMLR,
  17--23 Jul 2022, pp. 2709--2720. [Online]. Available:
  \url{https://proceedings.mlr.press/v162/casanova22a.html}
\BIBentrySTDinterwordspacing

\bibitem{45819}
\BIBentryALTinterwordspacing
L.~Dinh, J.~Sohl{-}Dickstein, and S.~Bengio, ``Density estimation using real
  {NVP},'' in \emph{5th International Conference on Learning Representations,
  {ICLR} 2017, Toulon, France, April 24-26, 2017, Conference Track
  Proceedings}.\hskip 1em plus 0.5em minus 0.4em\relax OpenReview.net, 2017.
  [Online]. Available: \url{https://openreview.net/forum?id=HkpbnH9lx}
\BIBentrySTDinterwordspacing

\bibitem{45774}
A.~{van den Oord}, S.~Dieleman, H.~Zen, K.~Simonyan, O.~Vinyals, A.~Graves,
  N.~Kalchbrenner, A.~Senior, and K.~Kavukcuoglu, ``{WaveNet: A Generative
  Model for Raw Audio},'' in \emph{Proc. 9th ISCA Workshop on Speech Synthesis
  Workshop (SSW 9)}, 2016, p. 125.

\bibitem{kong2020hifi}
J.~Kong, J.~Kim, and J.~Bae, ``Hifi-gan: Generative adversarial networks for
  efficient and high fidelity speech synthesis,'' \emph{Advances in Neural
  Information Processing Systems}, vol.~33, pp. 17\,022--17\,033, 2020.

\bibitem{VAE}
\BIBentryALTinterwordspacing
D.~P. Kingma and M.~Welling, ``Auto-encoding variational bayes,'' in \emph{2nd
  International Conference on Learning Representations, {ICLR} 2014, Banff, AB,
  Canada, April 14-16, 2014, Conference Track Proceedings}, Y.~Bengio and
  Y.~LeCun, Eds., 2014. [Online]. Available:
  \url{http://arxiv.org/abs/1312.6114}
\BIBentrySTDinterwordspacing

\bibitem{heo2020clova}
H.~S. Heo, B.-J. Lee, J.~Huh, and J.~S. Chung, ``{Clova baseline system for the
  voxceleb speaker recognition challenge 2020},'' \emph{arXiv preprint
  arXiv:2009.14153}, 2020.

\bibitem{veaux2016superseded}
{Christophe Veaux and Junichi Yamagishi and Kirsten MacDonald }, ``{SUPERSEDED
  - CSTR VCTK Corpus: English Multi-speaker Corpus for CSTR Voice Cloning
  Toolkit},'' 2016, accessed Febuary 08, 2024.
  \url{https://datashare.ed.ac.uk/handle/10283/2119}.

\bibitem{casanova2022tts}
E.~Casanova, A.~C. Junior, C.~Shulby, F.~S.~d. Oliveira, J.~P. Teixeira, M.~A.
  Ponti, and S.~Alu{\'\i}sio, ``Tts-portuguese corpus: a corpus for speech
  synthesis in brazilian portuguese,'' \emph{Language Resources and
  Evaluation}, vol.~56, no.~3, pp. 1043--1055, 2022.

\bibitem{mailabs}
{Munich Artificial Intelligence Laboratories GmbH}, ``The mailabs speech
  dataset – caito,'' 2017, accessed January 15, 2024.
  \url{https://www.caito.de/2019/01/03/the-m-ailabs-speech-dataset/}.

\bibitem{desplanques20_interspeech}
B.~Desplanques, J.~Thienpondt, and K.~Demuynck, ``{ECAPA-TDNN: Emphasized
  Channel Attention, Propagation and Aggregation in TDNN Based Speaker
  Verification},'' in \emph{Proc. Interspeech 2020}, 2020, pp. 3830--3834.

\bibitem{chen2023exploring}
Z.-C. Chen, C.-L. Fu, C.-Y. Liu, S.-W.~D. Li, and H.-y. Lee, ``Exploring
  efficient-tuning methods in self-supervised speech models,'' in \emph{2022
  IEEE Spoken Language Technology Workshop (SLT)}.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 2023, pp. 1120--1127.

\bibitem{hu2022lora}
\BIBentryALTinterwordspacing
E.~J. Hu, Y.~Shen, P.~Wallis, Z.~Allen-Zhu, Y.~Li, S.~Wang, L.~Wang, and
  W.~Chen, ``Lo{RA}: Low-rank adaptation of large language models,'' in
  \emph{International Conference on Learning Representations}, 2022. [Online].
  Available: \url{https://openreview.net/forum?id=nZeVKeeFYf9}
\BIBentrySTDinterwordspacing

\bibitem{lester-etal-2021-power}
\BIBentryALTinterwordspacing
B.~Lester, R.~Al-Rfou, and N.~Constant, ``The power of scale for
  parameter-efficient prompt tuning,'' in \emph{Proceedings of the 2021
  Conference on Empirical Methods in Natural Language Processing}, M.-F. Moens,
  X.~Huang, L.~Specia, and S.~W.-t. Yih, Eds.\hskip 1em plus 0.5em minus
  0.4em\relax Online and Punta Cana, Dominican Republic: Association for
  Computational Linguistics, Nov. 2021, pp. 3045--3059. [Online]. Available:
  \url{https://aclanthology.org/2021.emnlp-main.243}
\BIBentrySTDinterwordspacing

\bibitem{li-liang-2021-prefix}
\BIBentryALTinterwordspacing
X.~L. Li and P.~Liang, ``Prefix-tuning: Optimizing continuous prompts for
  generation,'' in \emph{Proceedings of the 59th Annual Meeting of the
  Association for Computational Linguistics and the 11th International Joint
  Conference on Natural Language Processing (Volume 1: Long Papers)}, C.~Zong,
  F.~Xia, W.~Li, and R.~Navigli, Eds.\hskip 1em plus 0.5em minus 0.4em\relax
  Online: Association for Computational Linguistics, Aug. 2021, pp. 4582--4597.
  [Online]. Available: \url{https://aclanthology.org/2021.acl-long.353}
\BIBentrySTDinterwordspacing

\bibitem{pires2023one}
\BIBentryALTinterwordspacing
T.~P. Pires, A.~V. Lopes, Y.~Assogba, and H.~Setiawan, ``One wide feedforward
  is all you need,'' in \emph{EMNLP Workshop}, 2024. [Online]. Available:
  \url{https://arxiv.org/abs/2309.01826}
\BIBentrySTDinterwordspacing

\bibitem{gong2022layer}
Y.~Qian, X.~Gong, and H.~Huang, ``Layer-wise fast adaptation for end-to-end
  multi-accent speech recognition,'' \emph{IEEE/ACM Transactions on Audio,
  Speech, and Language Processing}, vol.~30, pp. 2842--2853, 2022.

\bibitem{9879745}
Z.~Liu, H.~Mao, C.-Y. Wu, C.~Feichtenhofer, T.~Darrell, and S.~Xie, ``A convnet
  for the 2020s,'' in \emph{2022 IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, 2022, pp. 11\,966--11\,976.

\bibitem{yang23p_interspeech}
L.-J. Yang, C.-H.~H. Yang, and J.-T. Chien, ``{Parameter-Efficient Learning for
  Text-to-Speech Accent Adaptation},'' in \emph{Proc. INTERSPEECH 2023}, 2023,
  pp. 4354--4358.

\bibitem{muthuchamyselvaraj23_interspeech}
N.~{Muthuchamy Selvaraj}, X.~Guo, A.~Kong, B.~Shen, and A.~Kot, ``{Adapter
  Incremental Continual Learning of Efficient Audio Spectrogram
  Transformers},'' in \emph{Proc. INTERSPEECH 2023}, 2023, pp. 909--913.

\bibitem{jie2022convolutional}
S.~Jie and Z.-H. Deng, ``Convolutional bypasses are better vision transformer
  adapters,'' \emph{arXiv preprint arXiv:2207.07039}, 2022.

\bibitem{li2023evaluating}
Y.~Li, A.~Mehrish, S.~Zhao, R.~Bhardwaj, A.~Zadeh, N.~Majumder, R.~Mihalcea,
  and S.~Poria, ``Evaluating parameter-efficient transfer learning approaches
  on sure benchmark for speech understanding,'' in \emph{ICASSP}, 2023.

\bibitem{hu2018squeeze}
J.~Hu, L.~Shen, and G.~Sun, ``Squeeze-and-excitation networks,'' in
  \emph{Proceedings of the IEEE conference on computer vision and pattern
  recognition}, 2018, pp. 7132--7141.

\bibitem{ben-zaken-etal-2022-bitfit}
\BIBentryALTinterwordspacing
E.~Ben~Zaken, Y.~Goldberg, and S.~Ravfogel, ``{B}it{F}it: Simple
  parameter-efficient fine-tuning for transformer-based masked
  language-models,'' in \emph{Proceedings of the 60th Annual Meeting of the
  Association for Computational Linguistics (Volume 2: Short Papers)},
  S.~Muresan, P.~Nakov, and A.~Villavicencio, Eds.\hskip 1em plus 0.5em minus
  0.4em\relax Dublin, Ireland: Association for Computational Linguistics, May
  2022, pp. 1--9. [Online]. Available:
  \url{https://aclanthology.org/2022.acl-short.1}
\BIBentrySTDinterwordspacing

\bibitem{hsieh23_interspeech}
C.-P. Hsieh, S.~Ghosh, and B.~Ginsburg, ``{Adapter-Based Extension of
  Multi-Speaker Text-To-Speech Model for New Speakers},'' in \emph{Proc.
  INTERSPEECH 2023}, 2023, pp. 3028--3032.

\bibitem{ng23c_interspeech2}
D.~Ng, C.~Zhang, R.~Zhang, Y.~Ma, T.~H. Nguyen, C.~Ni, S.~Zhao, Q.~Chen,
  W.~Wang, E.~S. Chng, and B.~Ma, ``{Adapter-tuning with Effective
  Token-dependent Representation Shift for Automatic Speech Recognition},'' in
  \emph{Proc. INTERSPEECH 2023}, 2023, pp. 1319--1323.

\bibitem{lian2022scaling}
D.~Lian, D.~Zhou, J.~Feng, and X.~Wang, ``Scaling \& shifting your features: A
  new baseline for efficient model tuning,'' \emph{Advances in Neural
  Information Processing Systems}, vol.~35, pp. 109--123, 2022.

\bibitem{wu2018group}
Y.~Wu and K.~He, ``Group normalization,'' in \emph{Proceedings of the European
  conference on computer vision (ECCV)}, 2018, pp. 3--19.

\bibitem{huang2017arbitrary}
X.~Huang and S.~Belongie, ``Arbitrary style transfer in real-time with adaptive
  instance normalization,'' in \emph{Proceedings of the IEEE international
  conference on computer vision}, 2017, pp. 1501--1510.

\bibitem{sun2016return}
B.~Sun, J.~Feng, and K.~Saenko, ``Return of frustratingly easy domain
  adaptation,'' in \emph{Proceedings of the AAAI conference on artificial
  intelligence}, vol.~30, no.~1, 2016.

\bibitem{fu-etal-2022-adapterbias}
\BIBentryALTinterwordspacing
C.-L. Fu, Z.-C. Chen, Y.-R. Lee, and H.-y. Lee, ``{A}dapter{B}ias:
  Parameter-efficient token-dependent representation shift for adapters in
  {NLP} tasks,'' in \emph{Findings of the Association for Computational
  Linguistics: NAACL 2022}, M.~Carpuat, M.-C. de~Marneffe, and I.~V. Meza~Ruiz,
  Eds.\hskip 1em plus 0.5em minus 0.4em\relax Seattle, United States:
  Association for Computational Linguistics, Jul. 2022, pp. 2608--2621.
  [Online]. Available: \url{https://aclanthology.org/2022.findings-naacl.199}
\BIBentrySTDinterwordspacing

\bibitem{hauptman2019identifying}
Y.~Hauptman, R.~Aloni-Lavi, I.~Lapidot, T.~Gurevich, Y.~Manor, S.~Naor,
  N.~Diamant, and I.~Opher, ``Identifying distinctive acoustic and spectral
  features in parkinson's disease.'' in \emph{Interspeech}, 2019, pp.
  2498--2502.

\bibitem{botelho2019speech}
M.~C. Botelho, I.~Trancoso, A.~Abad, and T.~Paiva, ``Speech as a biomarker for
  obstructive sleep apnea detection,'' in \emph{ICASSP 2019-2019 IEEE
  International Conference on Acoustics, Speech and Signal Processing
  (ICASSP)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2019, pp. 5851--5855.

\bibitem{laaridh17_interspeech}
I.~Laaridh, W.~B. Kheder, C.~Fredouille, and C.~Meunier, ``{Automatic
  Prediction of Speech Evaluation Metrics for Dysarthric Speech},'' in
  \emph{Proc. Interspeech 2017}, 2017, pp. 1834--1838.

\bibitem{pappagari2020x}
R.~Pappagari, T.~Wang, J.~Villalba, N.~Chen, and N.~Dehak, ``x-vectors meet
  emotions: A study on dependencies between emotion and speaker recognition,''
  in \emph{ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech
  and Signal Processing (ICASSP)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE,
  2020, pp. 7169--7173.

\bibitem{perero2019modeling}
J.~M. Perero-Codosero, F.~Espinoza-Cuadros, J.~Ant{\'o}n-Mart{\'\i}n, M.~A.
  Barbero-Alvarez, and L.~A. Hern{\'a}ndez-G{\'o}mez, ``Modeling obstructive
  sleep apnea voices using deep neural network embeddings and
  domain-adversarial training,'' \emph{IEEE Journal of Selected Topics in
  Signal Processing}, vol.~14, no.~2, pp. 240--250, 2019.

\bibitem{zargarbashi2019multi}
S.~Zargarbashi and B.~Babaali, ``A multi-modal feature embedding approach to
  diagnose alzheimer disease from spoken language,'' \emph{arXiv preprint
  arXiv:1910.00330}, 2019.

\bibitem{botelho2020pathological}
C.~Botelho, F.~Teixeira, T.~Rolland, A.~Abad, and I.~Trancoso, ``Pathological
  speech detection using x-vector embeddings,'' \emph{arXiv preprint
  arXiv:2003.00864}, 2020.

\bibitem{snyder2017deep}
D.~Snyder, D.~Garcia-Romero, D.~Povey, and S.~Khudanpur, ``Deep neural network
  embeddings for text-independent speaker verification.'' in
  \emph{Interspeech}, vol. 2017, 2017, pp. 999--1003.

\bibitem{kenny2007joint}
P.~Kenny, G.~Boulianne, P.~Ouellet, and P.~Dumouchel, ``Joint factor analysis
  versus eigenchannels in speaker recognition,'' \emph{IEEE Transactions on
  Audio, Speech, and Language Processing}, vol.~15, no.~4, pp. 1435--1447,
  2007.

\bibitem{reynolds2000speaker}
D.~A. Reynolds, T.~F. Quatieri, and R.~B. Dunn, ``Speaker verification using
  adapted gaussian mixture models,'' \emph{Digital signal processing}, vol.~10,
  no. 1-3, pp. 19--41, 2000.

\bibitem{dehak2010front}
N.~Dehak, P.~J. Kenny, R.~Dehak, P.~Dumouchel, and P.~Ouellet, ``Front-end
  factor analysis for speaker verification,'' \emph{IEEE Transactions on Audio,
  Speech, and Language Processing}, vol.~19, no.~4, pp. 788--798, 2010.

\bibitem{hamalainen2014easr}
A.~H{\"a}m{\"a}l{\"a}inen, J.~Avelar, S.~Rodrigues, J.~Dias, A.~Kolesinski,
  T.~Fegy{\'o}, G.~N{\'e}meth, P.~Csob{\'a}nka, K.~Ting, and D.~Hewson, ``{The
  EASR Corpora of European Portuguese, French, Hungarian and Polish Elderly
  Speech},'' \emph{The EASR Corpora of European Portuguese, French, Hungarian
  and Polish elderly speech}, pp. 1458--1464, 2014.

\bibitem{pinto2016dysarthria}
S.~Pinto, R.~Cardoso, J.~Sadat, I.~Guimar{\~a}es, C.~Mercier, H.~Santos,
  C.~Atkinson-Clement, J.~Carvalho, P.~Welby, P.~Oliveira \emph{et~al.},
  ``Dysarthria in individuals with parkinson's disease: a protocol for a
  binational, cross-sectional, case-controlled study in french and european
  portuguese (fralusopark),'' \emph{BMJ open}, vol.~6, no.~11, p. e012885,
  2016.

\bibitem{orozco2014new}
J.~R. Orozco-Arroyave, J.~D. Arias-Londo{\~n}o, J.~F. Vargas-Bonilla, M.~C.
  Gonzalez-R{\'a}tiva, and E.~N{\"o}th, ``New spanish speech corpus database
  for the analysis of people suffering from parkinson's disease.'' in
  \emph{LREC}, 2014, pp. 342--347.

\bibitem{pompili2017automatic}
A.~Pompili, A.~Abad, P.~Romano, I.~P. Martins, R.~Cardoso, H.~Santos,
  J.~Carvalho, I.~Guimaraes, and J.~J. Ferreira, ``Automatic detection of
  parkinson’s disease: an experimental analysis of common speech production
  tasks used for diagnosis,'' in \emph{International Conference on Text,
  Speech, and Dialogue}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2017,
  pp. 411--419.

\bibitem{eyben2015geneva}
F.~Eyben, K.~R. Scherer, B.~W. Schuller, J.~Sundberg, E.~Andr{\'e}, C.~Busso,
  L.~Y. Devillers, J.~Epps, P.~Laukka, S.~S. Narayanan \emph{et~al.}, ``The
  geneva minimalistic acoustic parameter set (gemaps) for voice research and
  affective computing,'' \emph{IEEE transactions on affective computing},
  vol.~7, no.~2, pp. 190--202, 2015.

\bibitem{eyben2013recent}
F.~Eyben, F.~Weninger, F.~Gross, and B.~Schuller, ``Recent developments in
  opensmile, the munich open-source multimedia feature extractor,'' in
  \emph{Proceedings of the 21st ACM international conference on Multimedia},
  2013, pp. 835--838.

\bibitem{paszke2019pytorch}
A.~Paszke, S.~Gross, F.~Massa, A.~Lerer, J.~Bradbury, G.~Chanan, T.~Killeen,
  Z.~Lin, N.~Gimelshein, L.~Antiga \emph{et~al.}, ``Pytorch: An imperative
  style, high-performance deep learning library,'' \emph{Advances in neural
  information processing systems}, vol.~32, 2019.

\bibitem{pompili2020inesc}
A.~Pompili, T.~Rolland, and A.~Abad, ``{The INESC-ID Multi-Modal System for the
  ADReSS 2020 Challenge},'' in \emph{Proc. Interspeech 2020}, 2020, pp.
  2202--2206.

\bibitem{konig2015automatic}
A.~K{\"o}nig, A.~Satt, A.~Sorin, R.~Hoory, O.~Toledo-Ronen, A.~Derreumaux,
  V.~Manera, F.~Verhey, P.~Aalten, P.~H. Robert \emph{et~al.}, ``Automatic
  speech analysis for the assessment of patients with predementia and
  alzheimer's disease,'' \emph{Alzheimer's \& Dementia: Diagnosis, Assessment
  \& Disease Monitoring}, vol.~1, no.~1, pp. 112--124, 2015.

\bibitem{fraser2016linguistic}
K.~C. Fraser, J.~A. Meltzer, and F.~Rudzicz, ``Linguistic features identify
  alzheimer’s disease in narrative speech,'' \emph{Journal of Alzheimer's
  Disease}, vol.~49, no.~2, pp. 407--422, 2016.

\bibitem{gosztolya2019identifying}
G.~Gosztolya, V.~Vincze, L.~T{\'o}th, M.~P{\'a}k{\'a}ski, J.~K{\'a}lm{\'a}n,
  and I.~Hoffmann, ``Identifying mild cognitive impairment and mild
  alzheimer’s disease based on spontaneous speech using asr and linguistic
  features,'' \emph{Computer Speech \& Language}, vol.~53, pp. 181--197, 2019.

\bibitem{warnita18_interspeech}
T.~Warnita, N.~Inoue, and K.~Shinoda, ``{Detecting Alzheimer’s Disease Using
  Gated Convolutional Neural Network from Audio Data},'' in \emph{Proc.
  Interspeech 2018}, 2018, pp. 1706--1710.

\bibitem{karlekar-etal-2018-detecting}
\BIBentryALTinterwordspacing
S.~Karlekar, T.~Niu, and M.~Bansal, ``Detecting linguistic characteristics of
  {A}lzheimer{'}s dementia by interpreting neural models,'' in
  \emph{Proceedings of the 2018 Conference of the North {A}merican Chapter of
  the Association for Computational Linguistics: Human Language Technologies,
  Volume 2 (Short Papers)}, M.~Walker, H.~Ji, and A.~Stent, Eds.\hskip 1em plus
  0.5em minus 0.4em\relax New Orleans, Louisiana: Association for Computational
  Linguistics, Jun. 2018, pp. 701--707. [Online]. Available:
  \url{https://aclanthology.org/N18-2110}
\BIBentrySTDinterwordspacing

\bibitem{goodglass2001bdae}
H.~Goodglass, E.~Kaplan, and S.~Weintraub, \emph{BDAE: The Boston diagnostic
  aphasia examination}.\hskip 1em plus 0.5em minus 0.4em\relax Lippincott
  Williams \& Wilkins Philadelphia, PA, 2001.

\bibitem{luz2020alzheimer}
\BIBentryALTinterwordspacing
S.~Luz, F.~Haider, S.~de~la Fuente, D.~Fromm, and B.~MacWhinney,
  ``{Alzheimer's} dementia recognition through spontaneous speech: The {ADReSS
  Challenge},'' in \emph{Proceedings of INTERSPEECH 2020}, Shanghai, China,
  2020. [Online]. Available: \url{https://arxiv.org/abs/2004.06833}
\BIBentrySTDinterwordspacing

\bibitem{nagrani17_interspeech}
A.~Nagrani, J.~S. Chung, and A.~Zisserman, ``{VoxCeleb: A Large-Scale Speaker
  Identification Dataset},'' in \emph{Proc. Interspeech 2017}, 2017, pp.
  2616--2620.

\bibitem{schuller2020interspeech}
B.~W. Schuller, A.~Batliner, C.~Bergler, E.-M. Messner, A.~Hamilton,
  S.~Amiriparian, A.~Baird, G.~Rizos, M.~Schmitt, L.~Stappen \emph{et~al.},
  ``{The INTERSPEECH 2020 Computational Paralinguistics Challenge: Elderly
  Emotion, Breathing \& Masks},'' \emph{Proceedings INTERSPEECH. Shanghai,
  China: ISCA}, 2020.

\bibitem{mirheidari2018detecting}
B.~Mirheidari, D.~Blackburn, T.~Walker, A.~Venneri, M.~Reuber, and
  H.~Christensen, ``Detecting signs of dementia using word vector
  representations.'' in \emph{Interspeech}, 2018, pp. 1893--1897.

\bibitem{SoleraUrea2021TransferLC}
\BIBentryALTinterwordspacing
R.~Solera-Ure{\~n}a, C.~Botelho, F.~Teixeira, T.~Rolland, A.~Abad, and
  I.~Trancoso, ``Transfer learning-based cough representations for automatic
  detection of covid-19,'' in \emph{Interspeech}, 2021. [Online]. Available:
  \url{https://api.semanticscholar.org/CorpusID:237489901}
\BIBentrySTDinterwordspacing

\bibitem{schuller21_interspeech}
B.~W. Schuller, A.~Batliner, C.~Bergler, C.~Mascolo, J.~Han, I.~Lefter,
  H.~Kaya, S.~Amiriparian, A.~Baird, L.~Stappen, S.~Ottl, M.~Gerczuk,
  P.~Tzirakis, C.~Brown, J.~Chauhan, A.~Grammenos, A.~Hasthanasombat,
  D.~Spathis, T.~Xia, P.~Cicuta, L.~J. Rothkrantz, J.~A. Zwerts, J.~Treep, and
  C.~S. Kaandorp, ``{The INTERSPEECH 2021 Computational Paralinguistics
  Challenge: COVID-19 Cough, COVID-19 Speech, Escalation and Primates},'' in
  \emph{Proc. Interspeech 2021}, 2021, pp. 431--435.

\bibitem{pramono2016cough}
R.~X.~A. Pramono, S.~A. Imtiaz, and E.~Rodriguez-Villegas, ``A cough-based
  algorithm for automatic diagnosis of pertussis,'' \emph{PloS one}, vol.~11,
  no.~9, p. e0162128, 2016.

\bibitem{Hershey2017}
S.~{Hershey}, S.~{Chaudhuri}, D.~P.~W. {Ellis}, J.~F. {Gemmeke}, A.~{Jansen},
  R.~C. {Moore}, M.~{Plakal}, D.~{Platt}, R.~A. {Saurous}, B.~{Seybold},
  M.~{Slaney}, R.~J. {Weiss}, and K.~{Wilson}, ``{CNN architectures for
  large-scale audio classification},'' in \emph{{2017 IEEE International
  Conference on Acoustics, Speech and Signal Processing (ICASSP)}}, 2017, pp.
  131--135.

\bibitem{Chloe2020}
C.~Brown, J.~Chauhan, A.~Grammenos, J.~Han, A.~Hasthanasombat, D.~Spathis,
  T.~Xia, P.~Cicuta, and C.~Mascolo, ``{Exploring Automatic Diagnosis of
  COVID-19 from Crowdsourced Respiratory Sound Data},'' in \emph{Proceedings of
  the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data
  Mining}, Virtual Event, CA, USA, 2020, p. 3474–3484.

\bibitem{Bagad2020}
P.~Bagad, A.~Dalmia, J.~Doshi, A.~Nagrani, P.~Bhamare, A.~Mahale, S.~Rane,
  N.~Agarwal, and R.~Panicker, ``{Cough Against COVID: Evidence of COVID-19
  Signature in Cough Sounds},'' \emph{preprint arXiv:2009.08790}, 2020.

\bibitem{Imran2020}
A.~Imran, I.~Posokhova, H.~N. Qureshi, U.~Masood, M.~S. Riaz, K.~Ali, C.~N.
  John, M.~I. Hussain, and M.~Nabeel, ``{AI4COVID-19: AI enabled preliminary
  diagnosis for COVID-19 from cough samples via an app},'' \emph{Informatics in
  Medicine Unlocked}, vol.~20, p. 100378, 2020.

\bibitem{Chaudhari2021}
G.~Chaudhari, X.~Jiang, A.~Fakhry, A.~Han, J.~Xiao, S.~Shen, and A.~Khanzada,
  ``{Virufy: Global Applicability of Crowdsourced and Clinical Datasets for AI
  Detection of COVID-19 from Cough},'' \emph{preprint arXiv:2011.13320}, 2021.

\bibitem{Han2021}
J.~Han, C.~Brown, J.~Chauhan, A.~Grammenos, A.~Hasthanasombat, D.~Spathis,
  T.~Xia, P.~Cicuta, and C.~Mascolo, ``{Exploring Automatic COVID-19 Diagnosis
  via Voice and Symptoms from Crowdsourced Data},'' in \emph{2021 IEEE
  International Conference on Acoustics, Speech and Signal Processing
  (ICASSP)}, 2021, pp. 8328--8332.

\bibitem{Orlandic2020}
L.~Orlandic, T.~Teijeiro, and D.~Atienza, ``The coughvid crowdsourcing dataset,
  a corpus for the study of large-scale cough analysis algorithms,''
  \emph{Scientific Data}, vol.~8, no.~1, p. 156, 2021.

\bibitem{villalbaSRE182020}
J.~Villalba, N.~Chen, D.~Snyder, D.~Garcia-Romero, A.~McCree, G.~Sell,
  J.~Borgstrom, L.~P. García-Perera, F.~Richardson, R.~Dehak, P.~A.
  Torres-Carrasquillo, and N.~Dehak, ``{State-of-the-art speaker recognition
  with neural network embeddings in NIST SRE18 and Speakers in the Wild
  evaluations},'' \emph{{Computer Speech \& Language}}, vol.~60, p. 101026,
  2020.

\bibitem{Simonyan2015}
K.~Simonyan and A.~Zisserman, ``{Very Deep Convolutional Networks for
  Large-Scale Image Recognition},'' in \emph{{3rd International Conference on
  Learning Representations, ICLR 2015}}, San Diego, CA, USA, 2015.

\bibitem{yang21c_interspeech}
S.~wen Yang, P.-H. Chi, Y.-S. Chuang, C.-I.~J. Lai, K.~Lakhotia, Y.~Y. Lin,
  A.~T. Liu, J.~Shi, X.~Chang, G.-T. Lin, T.-H. Huang, W.-C. Tseng, K.~tik Lee,
  D.-R. Liu, Z.~Huang, S.~Dong, S.-W. Li, S.~Watanabe, A.~Mohamed, and
  H.~yi~Lee, ``{SUPERB: Speech Processing Universal PERformance Benchmark},''
  in \emph{Proc. Interspeech 2021}, 2021, pp. 1194--1198.

\bibitem{chang2021exploration}
X.~Chang, T.~Maekaku, P.~Guo, J.~Shi, Y.-J. Lu, A.~S. Subramanian, T.~Wang,
  S.-w. Yang, Y.~Tsao, H.-y. Lee \emph{et~al.}, ``An exploration of
  self-supervised pretrained representations for end-to-end speech
  recognition,'' in \emph{2021 IEEE Automatic Speech Recognition and
  Understanding Workshop (ASRU)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE,
  2021, pp. 228--235.

\bibitem{mockingjay}
\BIBentryALTinterwordspacing
A.~T. Liu, S.-w. Yang, P.-H. Chi, P.-c. Hsu, and H.-y. Lee, ``Mockingjay:
  Unsupervised speech representation learning with deep bidirectional
  transformer encoders,'' \emph{ICASSP 2020 - 2020 IEEE International
  Conference on Acoustics, Speech and Signal Processing (ICASSP)}, May 2020.
  [Online]. Available: \url{http://dx.doi.org/10.1109/ICASSP40776.2020.9054458}
\BIBentrySTDinterwordspacing

\bibitem{chi2021audio}
P.-H. Chi, P.-H. Chung, T.-H. Wu, C.-C. Hsieh, Y.-H. Chen, S.-W. Li, and H.-y.
  Lee, ``Audio albert: A lite bert for self-supervised learning of audio
  representation,'' in \emph{2021 IEEE Spoken Language Technology Workshop
  (SLT)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2021, pp. 344--350.

\bibitem{liu21l_interspeech}
A.~H. Liu, Y.-A. Chung, and J.~Glass, ``{Non-Autoregressive Predictive Coding
  for Learning Speech Representations from Local Dependencies},'' in
  \emph{Proc. Interspeech 2021}, 2021, pp. 3730--3734.

\bibitem{chung19_interspeech}
Y.-A. Chung, W.-N. Hsu, H.~Tang, and J.~Glass, ``{An Unsupervised
  Autoregressive Model for Speech Representation Learning},'' in \emph{Proc.
  Interspeech 2019}, 2019, pp. 146--150.

\bibitem{liu2021tera}
A.~T. Liu, S.-W. Li, and H.-y. Lee, ``Tera: Self-supervised learning of
  transformer encoder representation for speech,'' \emph{IEEE/ACM Transactions
  on Audio, Speech, and Language Processing}, vol.~29, pp. 2351--2366, 2021.

\bibitem{librilight}
J.~{Kahn}, M.~{Rivière}, W.~{Zheng}, E.~{Kharitonov}, Q.~{Xu}, P.~E.
  {Mazaré}, J.~{Karadayi}, V.~{Liptchinsky}, R.~{Collobert}, C.~{Fuegen},
  T.~{Likhomanenko}, G.~{Synnaeve}, A.~{Joulin}, A.~{Mohamed}, and E.~{Dupoux},
  ``Libri-light: A benchmark for asr with limited or no supervision,'' in
  \emph{ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech
  and Signal Processing (ICASSP)}, 2020, pp. 7669--7673,
  \url{https://github.com/facebookresearch/libri-light}.

\bibitem{mcauliffe2017montreal}
M.~McAuliffe, M.~Socolof, S.~Mihuc, M.~Wagner, and M.~Sonderegger, ``Montreal
  forced aligner: Trainable text-speech alignment using kaldi.'' in
  \emph{Interspeech}, vol. 2017, 2017, pp. 498--502.

\bibitem{phdthesis}
L.~Gelin, ``Reconnaissance automatique de la parole d'enfants apprenant·e·s
  lecteur·ice·s en salle de classe : modélisation acoustique de phonèmes,''
  Ph.D. dissertation, Toulouse III - Paul Sabatier University, 02 2022.

\end{thebibliography}
