\babel@toc {english}{}
\addvspace {10\p@ }
\contentsline {xchapter}{Introduction}{1}{chapter.1}
\contentsline {figure}{\numberline {1.1}{\ignorespaces Illustrated herein are some examples of children's Speech and Language Technology applications that were developed during the course of this thesis. On the left is a running platformer game, where the user's voice controls the character. Pitch dictates running and jumping actions, while energy modulates the velocity of these actions. On the right, a reading task game is depicted, wherein a robot instructs the user to read designated words.\relax }}{5}{figure.caption.5}
\addvspace {10\p@ }
\contentsline {xchapter}{Background - Children automatic speech recognition}{9}{chapter.2}
\contentsline {figure}{\numberline {2.1}{\ignorespaces Formant and cepstral variability. Figures taken from \cite {reviewASRchildren}\relax }}{14}{figure.caption.6}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Changes in F1-F2 vowel space as a function of age}}}{14}{figure.caption.6}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Mean cepstral distance between the two repetitions of the same vowels}}}{14}{figure.caption.6}
\contentsline {figure}{\numberline {2.2}{\ignorespaces Segmental duration variability. Figures taken from \cite {Acoustic_change_children}\relax }}{15}{figure.caption.7}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Averaged-vowel duration across all vowels and subjects in each age group}}}{15}{figure.caption.7}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Within- and between-subject variations. The between-subject variation is reduced by a factor of 2.0}}}{15}{figure.caption.7}
\contentsline {figure}{\numberline {2.3}{\ignorespaces Example of a standard digit pattern from Davis et al. 1952\relax }}{20}{figure.caption.8}
\contentsline {figure}{\numberline {2.4}{\ignorespaces Example of a decoding graph from the Harpy system for the sentence "GIVE ME" from \cite {klatt1977review}\relax }}{22}{figure.caption.9}
\contentsline {figure}{\numberline {2.5}{\ignorespaces Architecture of a HMM-based speech recognition system\relax }}{23}{figure.caption.10}
\contentsline {figure}{\numberline {2.6}{\ignorespaces Principal block scheme of main speech features for ASR: Melspec, fbanks and MFCC coefficients from \cite {kiktova2013comparison}\relax }}{25}{figure.caption.11}
\contentsline {figure}{\numberline {2.7}{\ignorespaces Three-state Hidden Markov Model for modelling phones\relax }}{26}{figure.caption.12}
\contentsline {figure}{\numberline {2.8}{\ignorespaces Phoneme set and examples of CMU dictionary using 39 phonemes from \cite {weide1998carnegie}\relax }}{28}{figure.caption.13}
\contentsline {figure}{\numberline {2.9}{\ignorespaces Architecture of an end-to-end speech recognition system\relax }}{31}{figure.caption.14}
\contentsline {figure}{\numberline {2.10}{\ignorespaces Transfer learning approaches. Figures from \cite {TFchildren}\relax }}{42}{figure.caption.15}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Acoustic adaptation}}}{42}{figure.caption.15}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Pronunciation adaptation}}}{42}{figure.caption.15}
\contentsline {figure}{\numberline {2.11}{\ignorespaces Multilingual approach using each language as a task in a multi-task learning context.\relax }}{44}{figure.caption.16}
\addvspace {10\p@ }
\contentsline {xchapter}{Hybrid models for children automatic speech recognition}{51}{chapter.3}
\contentsline {figure}{\numberline {3.1}{\ignorespaces Multilingual transfer learning approach. Language-specific layers can be randomly initialized for a language not present during the MTL phase or use the corresponding pre-trained layers in case the target language was present during the MTL phase. Grey blocks are pre-trained during MTL phase.\relax }}{58}{figure.caption.21}
\addvspace {10\p@ }
\contentsline {xchapter}{End-to-End children automatic speech recognition}{63}{chapter.4}
\contentsline {figure}{\numberline {4.1}{\ignorespaces Architecture of the standard Transformer \cite {vaswani2017attention}. a) scaled dot-product attention, b) multi-head self-attention, c) Transformer-encoder, d) Transformer-decoder.\relax }}{66}{figure.caption.24}
\contentsline {figure}{\numberline {4.2}{\ignorespaces Architecture of a Conformer layer\relax }}{68}{figure.caption.25}
\contentsline {figure}{\numberline {4.3}{\ignorespaces Convolution module in the context of a conformer layer\relax }}{69}{figure.caption.26}
\contentsline {figure}{\numberline {4.4}{\ignorespaces Layers-wise up-way and down-way transfer learning experiment for Transformer and Conformer architecture\relax }}{73}{figure.caption.29}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Results of the transfer learning layer wise for the Transformer model}}}{73}{figure.caption.29}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Results of the transfer learning layer wise for the Conformer model}}}{73}{figure.caption.29}
\addvspace {10\p@ }
\contentsline {xchapter}{Exploring Parameter-Efficient Strategies in Transfer Learning for Child-Focused ASR Systems}{77}{chapter.5}
\contentsline {figure}{\numberline {5.1}{\ignorespaces Residual Adapter architecture\relax }}{80}{figure.caption.31}
\contentsline {figure}{\numberline {5.2}{\ignorespaces Transformer block with various residual adapter configurations. Normalisation layers are not display in this figure\relax }}{82}{figure.caption.32}
\contentsline {figure}{\numberline {5.3}{\ignorespaces Conformer block with various residual adapter configurations. Normalisation layers are not display in this figure\relax }}{82}{figure.caption.33}
\addvspace {10\p@ }
\contentsline {xchapter}{Integration of synthetic speech for data augmentation}{89}{chapter.6}
\contentsline {figure}{\numberline {6.1}{\ignorespaces Overview of ``Double way Adapter fine-tuning" within th context of an Transformer model\relax }}{93}{figure.caption.36}
\contentsline {figure}{\numberline {6.2}{\ignorespaces Architecture of the YourTTS model taken from \cite {casanova2022yourtts}\relax }}{96}{figure.caption.37}
\contentsline {figure}{\numberline {6.3}{\ignorespaces Overview of ``Double way Adapter fine-tuning" within th context of an Conformer architecture\relax }}{102}{figure.caption.42}
\addvspace {10\p@ }
\contentsline {xchapter}{Alternative approaches to parameter-efficient transfer learning}{105}{chapter.7}
\contentsline {figure}{\numberline {7.1}{\ignorespaces Th architecture of the ConvPass adapter. $k$ is the kernel size of the 1D convolution. All Convoluation are depth-wise convolution.\relax }}{109}{figure.caption.44}
\contentsline {figure}{\numberline {7.2}{\ignorespaces AdapterBias, consisting of a linear layer $L_\alpha $ and a vector $\mathcal {V}$, is added after the second feed-forward layer only in each FFN module.\relax }}{111}{figure.caption.45}
\contentsline {figure}{\numberline {7.3}{\ignorespaces Different paramter efficent procedure for children ASR in conformer model\relax }}{112}{figure.caption.46}
\contentsline {figure}{\numberline {7.4}{\ignorespaces Shared-Adapter setup in a Conformer model\relax }}{114}{figure.caption.48}
\contentsline {figure}{\numberline {7.5}{\ignorespaces Different paramter efficent procedure for children ASR in conformer model with shared-Adapters\relax }}{116}{figure.caption.49}
\addvspace {10\p@ }
\contentsline {xchapter}{Conclusions}{117}{chapter.8}
\addvspace {10\p@ }
\contentsline {xchapter}{Pathological speech detection through pre-trained models}{149}{appendix.A}
\contentsline {figure}{\numberline {A.1}{\ignorespaces Overview of the multimodal system based on embeddding appraoches\relax }}{156}{figure.caption.55}
\addvspace {10\p@ }
\contentsline {xchapter}{Sefl-supervised learning as feature extractor for children's ASR}{165}{appendix.B}
\contentsline {figure}{\numberline {B.1}{\ignorespaces Overview of the discriminative SSL Wav2vec2 and HuBert models\relax }}{167}{figure.caption.61}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Illustration of the Wav2vec2 architecture taken from \cite {baevski2020wav2vec}}}}{167}{figure.caption.61}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Illustration of the HuBert architecture taken from \cite {hsu2021hubert}}}}{167}{figure.caption.61}
\contentsline {figure}{\numberline {B.2}{\ignorespaces (a) Fbanks (b) TERA (c) Wav2Vec 2.0 (d) HuBERT T-SNE plot of the different extracted features using the same speech data using phoneme labels\relax }}{170}{figure.caption.64}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{170}{figure.caption.64}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{170}{figure.caption.64}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{170}{figure.caption.64}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{170}{figure.caption.64}
