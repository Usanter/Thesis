@inproceedings{reviewASRchildren,
author = {Gerosa, Matteo and Giuliani, Diego and Narayanan, Shrikanth and Potamianos, Alexandros},
title = {A Review of {ASR} Technologies for Children's Speech},
year = {2009},
isbn = {9781605586908},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1640377.1640384},
doi = {10.1145/1640377.1640384},
abstract = {In this paper, we review: (1) the acoustic and linguistic properties of children's
speech for both read and spontaneous speech, and (2) the developments in automatic
speech recognition for children with application to spoken dialogue and multimodal
dialogue system design. First, the effect of developmental changes on the absolute
values and variability of acoustic correlates is presented for read speech for children
ages 6 and up. Then, verbal child-machine spontaneous interaction is reviewed and
results from recent studies are presented. Age trends of acoustic, linguistic and
interaction parameters are discussed, such as sentence duration, filled pauses, politeness
and frustration markers, and modality usage. Some differences between child-machine
and human-human interaction are pointed out. The implications for acoustic modeling,
linguistic modeling and spoken dialogue system design for children are presented.
We conclude with a review of relevant applications of spoken dialogue technologies
for children.},
booktitle = {Proceedings of the 2nd Workshop on Child, Computer and Interaction},
articleno = {7},
numpages = {8},
keywords = {children's speech analysis, spoken dialogue, children's speech recognition},
location = {Cambridge, Massachusetts},
series = {WOCCI '09}
}

@article{Acoustic_change_children,
author = {Lee,Sungbok  and Potamianos,Alexandros  and Narayanan,Shrikanth },
title = {Acoustics of children’s speech: Developmental changes of temporal and spectral parameters},
journal = {The Journal of the Acoustical Society of America},
volume = {105},
number = {3},
pages = {1455-1468},
year = {1999},
doi = {10.1121/1.426686},

URL = { 
        https://doi.org/10.1121/1.426686
    
},
eprint = { 
        https://doi.org/10.1121/1.426686
    
}

}

@ARTICLE{childrenSpeechWorse, 
author={A. Potamianos and S. Narayanan}, 
journal={IEEE Transactions on Speech and Audio Processing}, 
title={Robust recognition of children's speech}, 
year={2003}, 
volume={11}, 
number={6}, 
pages={603-616}, 
keywords={error analysis;speech recognition;piecewise linear techniques;spectral analysis;children speech recognition;age-dependent spectral variability;age-dependent temporal variability;age-related acoustic characteristics;automatic speech recognition;frequency scaling;spectral envelope parameters;acoustic models;word error rate;speaker normalization algorithm;frequency warping;piecewise linear algorithm;phoneme-dependent algorithm;formant scaling;vocal tract normalization;Robustness;Speech recognition;Automatic speech recognition;Frequency;Speech analysis;Acoustic testing;Error analysis;Loudspeakers;Degradation;Piecewise linear techniques}, 
doi={10.1109/TSA.2003.818026}, 
ISSN={1063-6676}, 
}
@article{MyST,
  title={My Science Tutor: A Conversational Multimedia Virtual Tutor.},
  author={W. Ward and R. Cole and Daniel Bola{\~n}os and Cindy Buchenroth-Martin and Edward Svirsky and Timothy B. Weston},
  journal={Journal of Educational Psychology},
  year={2013},
  volume={105},
  pages={1115-1125}
}
@INPROCEEDINGS{librispeech,
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={ICASSP}, 
  title={Librispeech: An ASR corpus based on public domain audio books}, 
  year={2015},
  volume={},
  number={},
  pages={5206-5210},
  doi={10.1109/ICASSP.2015.7178964}}


@inproceedings{singakids,
  title={SingaKids-Mandarin: Speech Corpus of Singaporean Children Speaking Mandarin Chinese.},
  author={Chen, Nancy F and Tong, Rong and Wee, Darren and Lee, Pei Xuan and Ma, Bin and Li, Haizhou},
  booktitle={Interspeech},
  pages={1545--1549},
  year={2016}
}


@inproceedings{cslu,
  title={The OGI kids’ speech corpus and recognizers},
  author={Shobaki, Khaldoun and Hosom, John-Paul and Cole, Ronald},
  booktitle={Proc. of ICSLP},
  pages={564--567},
  year={2000}
}



@article{cmu,
  title={The CMU kids speech corpus},
  author={Eskenazi, Maxine and Mostow, Jack and Graff, David},
  journal={Corpus of children's read speech digitized and transcribed on two CD-ROMs, with assistance from Multicom Research and David Graff. Published by the Linguistic Data Consortium, University of Pennsylvania},
  year={1997}
}

@article{segmental_duration,
author = {Knutsen,Sten  and Stromswold,Karin  and Kleinschmidt,Dave F. },
title = {Segmental duration as a cue to sentence structure},
journal = {The Journal of the Acoustical Society of America},
volume = {145},
number = {3},
pages = {1910-1910},
year = {2019},
doi = {10.1121/1.5101929},

URL = { 
        https://doi.org/10.1121/1.5101929
    
},
eprint = { 
        https://doi.org/10.1121/1.5101929
    
}

}


@article{first_vowel_study,
author = {Peterson,Gordon E.  and Barney,Harold L. },
title = {Control Methods Used in a Study of the Vowels},
journal = {The Journal of the Acoustical Society of America},
volume = {24},
number = {2},
pages = {175-184},
year = {1952},
doi = {10.1121/1.1906875},

URL = { 
        https://doi.org/10.1121/1.1906875
    
},
eprint = { 
        https://doi.org/10.1121/1.1906875
    
}

}
@inproceedings{asr-google,
title	= {Large Vocabulary Automatic Speech Recognition for Children},
author	= {Hank Liao and Golan Pundak and Olivier Siohan and Melissa Carroll and Noah Coccaro and Qi-Ming Jiang and Tara N. Sainath and Andrew Senior and Françoise Beaufays and Michiel Bacchiani},
year	= {2015},
booktitle	= {Interspeech}
}
@inproceedings{why_children_speech_no_working,
  author={Qun Li and Martin J. Russell},
  title={{Why is automatic recognition of children's speech difficult?}},
  year=2001,
  booktitle={Proc. 7th European Conference on Speech Communication and Technology (Eurospeech 2001)},
  pages={2671--2674}
}
@article{segment_definition,
author = {DAVID CRYSTAL},
year = {2004},
month = {01},
pages = {100 - 101},
title = {A Dictionary of Linguistics and Phonetics},
volume = {34},
journal = {Journal of the International Phonetic Association},
doi = {10.1017/S0025100304231681}
}

@article{Children_language_model,
  title={Improvements in children's speech recognition performance},
  author={SubrataKumar Das and Don Nix and Michael Picheny},
  journal={Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP '98 (Cat. No.98CH36181)},
  year={1998},
  volume={1},
  pages={433-436 vol.1}
}
@inproceedings{children_language_model2,
  title={Child automatic speech recognition for US English: child interaction with living-room-electronic-devices},
  author={Sharmistha S. Gray and Daniel Willett and Jianhua Lu and Joel Pinto and Paul Maergner and Nathan Bodenstab},
  booktitle={WOCCI},
  year={2014}
}


@inproceedings{language_children,
  title={Acoustic and language modeling for children's read speech assessment},
  author={Tulsiani, Hitesh and Swarup, Prakhar and Rao, Preeti},
  booktitle={2017 Twenty-third National Conference on Communications (NCC)},
  pages={1--6},
  year={2017},
  organization={IEEE}
}


@inproceedings{language_children2,
author = {Potamianos, Alexandros and Narayanan, Shrikanth},
year = {1998},
month = {06},
pages = {197 - 200 vol.1},
title = {Spoken dialog systems for children},
volume = {1},
isbn = {0-7803-4428-6},
booktitle={ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
doi = {10.1109/ICASSP.1998.674401}
}


@inproceedings{darpa1992,
  title={The {HTK} tied-state continuous speech recogniser.},
  author={Woodland, Philip C and Young, Steve J},
  booktitle={Eurospeech},
  year={1993}
}

@article{htk_book,
  title={The {HTK} book},
  author={Young, Steve and Evermann, Gunnar and Gales, Mark and Hain, Thomas and Kershaw, Dan and Liu, Xunying and Moore, Gareth and Odell, Julian and Ollason, Dave and Povey, Dan and others},
  journal={Cambridge university engineering department},
  volume={3},
  number={175},
  pages={12},
  year={2002}
}


@ARTICLE{hmm-dnn,
  author={Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George E. and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Sainath, Tara N. and Kingsbury, Brian},
  journal={IEEE Signal Processing Magazine}, 
  title={Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups}, 
  year={2012},
  volume={29},
  number={6},
  pages={82-97},
  doi={10.1109/MSP.2012.2205597}}
  
  
 @article{first_asr,
author = {Davis,K. H.  and Biddulph,R.  and Balashek,S. },
title = {Automatic Recognition of Spoken Digits},
journal = {The Journal of the Acoustical Society of America},
volume = {24},
number = {6},
pages = {637-642},
year = {1952},
doi = {10.1121/1.1906946},

URL = { 
        https://doi.org/10.1121/1.1906946
    
},
eprint = { 
        https://doi.org/10.1121/1.1906946
    
}

}
@ARTICLE{mfcc,
  author={Davis, S. and Mermelstein, P.},
  journal={IEEE Transactions on Acoustics, Speech, and Signal Processing}, 
  title={Comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences}, 
  year={1980},
  volume={28},
  number={4},
  pages={357-366},
  doi={10.1109/TASSP.1980.1163420}}
@ARTICLE{Dragon_system,
  author={Baker, J.},
  journal={IEEE Transactions on Acoustics, Speech, and Signal Processing}, 
  title={The {DRAGON} system--An overview}, 
  year={1975},
  volume={23},
  number={1},
  pages={24-29},
  doi={10.1109/TASSP.1975.1162650}}

@inproceedings{g2p,
  author={Kaisheng Yao and Geoffrey Zweig},
  title={{Sequence-to-sequence neural net models for grapheme-to-phoneme conversion}},
  year=2015,
  booktitle={Proc. Interspeech 2015},
  pages={3330--3334},
  doi={10.21437/Interspeech.2015-134}
}

@article{n-grams-computational_biology,
author = {Vishnoi, Shubham and Garg, Prabha and Arora, Pooja},
title = {Physicochemical N-Grams Tool: A tool for protein physicochemical descriptor generation via Chou’s 5-step rule},
journal = {Chemical Biology \& Drug Design},
volume = {95},
number = {1},
pages = {79-86},
keywords = {descriptor generation, machine learning, n-Grams, physicochemical parameter, proteomics science},
doi = {https://doi.org/10.1111/cbdd.13617},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cbdd.13617},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cbdd.13617},
abstract = {Abstract Physicochemical n-Grams Tool (PnGT) is an open-source standalone software for calculating physicochemical descriptors of protein. PnGT was developed using the Python scripting language and developed the user interface using Tkinter. The software currently calculates 33 physicochemical descriptors along with the sequence length for the given protein primary sequence. The descriptor generated by this tool can be directly utilized as the feature vector for the development of proteomics statistical or machine learning predictive model.},
year = {2020}
}

@article{n-gram-compression,
	title = {n-{Gram}-{Based} {Text} {Compression}},
	volume = {2016},
	issn = {1687-5265},
	url = {https://doi.org/10.1155/2016/9483646},
	doi = {10.1155/2016/9483646},
	abstract = {We propose an efficient method for compressing Vietnamese text using{\textless}italic{\textgreater} n{\textless}/italic{\textgreater}-gram dictionaries. It has a significant compression ratio in comparison with those of state-of-the-art methods on the same dataset. Given a text, first, the proposed method splits it into{\textless}italic{\textgreater} n{\textless}/italic{\textgreater}-grams and then encodes them based on{\textless}italic{\textgreater} n{\textless}/italic{\textgreater}-gram dictionaries. In the encoding phase, we use a sliding window with a size that ranges from bigram to five grams to obtain the best encoding stream. Each{\textless}italic{\textgreater} n{\textless}/italic{\textgreater}-gram is encoded by two to four bytes accordingly based on its corresponding{\textless}italic{\textgreater} n{\textless}/italic{\textgreater}-gram dictionary. We collected 2.5\&\#x2009;GB text corpus from some Vietnamese news agencies to build{\textless}italic{\textgreater} n{\textless}/italic{\textgreater}-gram dictionaries from unigram to five grams and achieve dictionaries with a size of 12\&\#x2009;GB in total. In order to evaluate our method, we collected a testing set of 10 different text files with different sizes. The experimental results indicate that our method achieves compression ratio around 90\&\#x25; and outperforms state-of-the-art methods.},
	journal = {Computational Intelligence and Neuroscience},
	author = {Nguyen, Vu H. and Nguyen, Hien T. and Duong, Hieu N. and Snasel, Vaclav},
	editor = {Jo, Geun S.},
	month = nov,
	year = {2016},
	note = {Publisher: Hindawi Publishing Corporation},
	pages = {9483646},
}
@article{n-grams-NLP,
  title={Syntactic n-grams as machine learning features for natural language processing},
  author={Sidorov, Grigori and Velasquez, Francisco and Stamatatos, Efstathios and Gelbukh, Alexander and Chanona-Hern{\'a}ndez, Liliana},
  journal={Expert Systems with Applications},
  volume={41},
  number={3},
  pages={853--860},
  year={2014},
  publisher={Elsevier}
}


@article{transformer,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}


@inproceedings{Bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    editor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}

@inproceedings{First_End2End,
author = {Graves, Alex and Fern\'{a}ndez, Santiago and Gomez, Faustino and Schmidhuber, J\"{u}rgen},
title = {Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks},
year = {2006},
isbn = {1595933832},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1143844.1143891},
doi = {10.1145/1143844.1143891},
abstract = {Many real-world sequence learning tasks require the prediction of sequences of labels
from noisy, unsegmented input data. In speech recognition, for example, an acoustic
signal is transcribed into words or sub-word units. Recurrent neural networks (RNNs)
are powerful sequence learners that would seem well suited to such tasks. However,
because they require pre-segmented training data, and post-processing to transform
their outputs into label sequences, their applicability has so far been limited. This
paper presents a novel method for training RNNs to label unsegmented sequences directly,
thereby solving both problems. An experiment on the TIMIT speech corpus demonstrates
its advantages over both a baseline HMM and a hybrid HMM-RNN.},
booktitle = {Proceedings of the 23rd International Conference on Machine Learning},
pages = {369–376},
numpages = {8},
location = {Pittsburgh, Pennsylvania, USA},
series = {ICML '06}
}
@ARTICLE{n-grams-smoothing,
  author={Chen, S.F. and Rosenfeld, R.},
  journal={IEEE Transactions on Speech and Audio Processing}, 
  title={A survey of smoothing techniques for ME models}, 
  year={2000},
  volume={8},
  number={1},
  pages={37-50},
  doi={10.1109/89.817452}}
  
  
  @ARTICLE{tfbased,
  author={Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Representation Learning: A Review and New Perspectives}, 
  year={2013},
  volume={35},
  number={8},
  pages={1798-1828},
  doi={10.1109/TPAMI.2013.50}}

@INPROCEEDINGS{tfpathology,
  author={Takashima, Ryoichi and Takiguchi, Tetsuya and Ariki, Yasuo},
  booktitle={ICASSP}, 
  title={Two-Step Acoustic Model Adaptation for Dysarthric Speech Recognition}, 
  year={2020},
  volume={},
  number={},
  pages={6104-6108},
  doi={10.1109/ICASSP40776.2020.9053725}}

@INPROCEEDINGS{tfcharacter,
  author={Cireşan, Dan C. and Meier, Ueli and Schmidhuber, Jürgen},
  booktitle={The 2012 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Transfer learning for Latin and Chinese characters with Deep Neural Networks}, 
  year={2012},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/IJCNN.2012.6252544}}
  
  
@article{TransferLF,
  title={Transfer learning for children's speech recognition},
  author={R. Tong and Lei Wang and B. Ma},
  journal={2017 International Conference on Asian Language Processing (IALP)},
  year={2017},
  pages={36-39}
}


@article{TFchildren,
title = {Transfer learning from adult to children for speech recognition: Evaluation, analysis and recommendations},
journal = {Computer Speech \& Language},
volume = {63},
pages = {101077},
year = {2020},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2020.101077},
url = {https://www.sciencedirect.com/science/article/pii/S0885230820300103},
author = {Prashanth {Gurunath Shivakumar} and Panayiotis Georgiou},
keywords = {Analysis of children’s speech, Children speech recognition, Automatic speech recognition, Deep learning, Transfer learning, Deep neural network},
}

@inproceedings{yosinski2014transferable,
 author = {Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {How transferable are features in deep neural networks?},
 url = {https://proceedings.neurips.cc/paper_files/paper/2014/file/375c71349b295fbe2dcdca9206f20a06-Paper.pdf},
 volume = {27},
 year = {2014}
}


@ARTICLE{viterbi_decoder,
  author={Viterbi, A.},
  journal={IEEE Transactions on Information Theory}, 
  title={Error bounds for convolutional codes and an asymptotically optimum decoding algorithm}, 
  year={1967},
  volume={13},
  number={2},
  pages={260-269},
  doi={10.1109/TIT.1967.1054010}}
  
  @article{Hermansky1990PerceptualLP,
  title={Perceptual linear predictive (PLP) analysis of speech.},
  author={Hynek Hermansky},
  journal={The Journal of the Acoustical Society of America},
  year={1990},
  volume={87 4},
  pages={
          1738-52
        }
}

@inproceedings{VTLN,
  title={Speaker normalization using efficient frequency warping procedures},
  author={Lee, Li and Rose, Richard C},
  booktitle={1996 IEEE International Conference on Acoustics, Speech, and Signal Processing Conference Proceedings},
  volume={1},
  pages={353--356},
  year={1996},
  organization={IEEE}
}

@INPROCEEDINGS{feat_ext_from_raw,  author={Dubagunta, S. Pavankumar and Hande Kabil, Selen and Magimai.-Doss, Mathew},  booktitle={ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},   title={Improving Children Speech Recognition through Feature Learning from Raw Speech Signal},   year={2019},  volume={},  number={},  pages={5736-5740},  doi={10.1109/ICASSP.2019.8682826}}

@INPROCEEDINGS{sincnet_adapt,  author={Fainberg, Joachim and Klejch, Ondřej and Loweimi, Erfan and Bell, Peter and Renals, Steve},  booktitle={2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},   title={Acoustic Model Adaptation from Raw Waveforms with Sincnet},   year={2019},  volume={},  number={},  pages={897-904},  doi={10.1109/ASRU46091.2019.9003974}}


@inproceedings{Sincnet,
  title={Speaker recognition from raw waveform with sincnet},
  author={Ravanelli, Mirco and Bengio, Yoshua},
  booktitle={2018 IEEE spoken language technology workshop (SLT)},
  pages={1021--1028},
  year={2018},
  organization={IEEE}
}

@INPROCEEDINGS{ivector,
  author={Senior, Andrew and Lopez-Moreno, Ignacio},
  booktitle={ICASSP}, 
  title={Improving DNN speaker independence with I-vector inputs}, 
  year={2014},
  volume={},
  number={},
  pages={225-229},
  doi={10.1109/ICASSP.2014.6853591}}
  
  
  @INPROCEEDINGS{adversarial-adapt1,
  author={Duan, Richeng and Chen, Nancy F.},
  booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Senone-Aware Adversarial Multi-Task Training for Unsupervised Child to Adult Speech Adaptation}, 
  year={2021},
  volume={},
  number={},
  pages={7758-7762},
  doi={10.1109/ICASSP39728.2021.9413738}}
  
  @article{adversarial-adapt2,
  title={Age-Invariant Training for End-to-End Child Speech Recognition Using Adversarial Multi-Task Learning},
  author={Rumberg, Lars and Ehlert, Hanna and L{\"u}dtke, Ulrike and Ostermann, J{\"o}rn},
  journal={Proc. Interspeech 2021},
  pages={3850--3854},
  year={2021}
}

@article{f0norm,
  title={A Frequency Normalization Technique for Kindergarten Speech Recognition Inspired by the Role of f0 in Vowel Perception},
  author={Yeung, Gary and Alwan, Abeer},
  journal={Interspeech 2019},
  year={2019}
}

@ARTICLE{pitchnorm,
  author={Shahnawazuddin, Syed and Sinha, Rohit and Pradhan, Gayadhar},
  journal={IEEE Signal Processing Letters}, 
  title={Pitch-Normalized Acoustic Features for Robust Children's Speech Recognition}, 
  year={2017},
  volume={24},
  number={8},
  pages={1128-1132},
  doi={10.1109/LSP.2017.2705085}}
  
  @inproceedings{pitch_adapt_norm,
  title={Pitch-Adaptive Front-End Features for Robust Children's ASR},
  author={Syed Shahnawazuddin and Abhishek Dey and Rohit Sinha},
  booktitle={INTERSPEECH},
  year={2016}
}

@INPROCEEDINGS{prosody_feat,
  author={Kathania, Hemant K. and Shahnawazuddin, S. and Adiga, Nagaraj and Ahmad, Waquar},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Role of Prosodic Features on Children's Speech Recognition}, 
  year={2018},
  volume={},
  number={},
  pages={5519-5523},
  doi={10.1109/ICASSP.2018.8461668}}
  
  @inproceedings{speaking_rate,
  title={Improving Children's Speech Recognition Through Time Scale Modification Based Speaking Rate Adaptation},
  author={Kathania, Hemant K and Shahnawazuddin, S and Ahmad, Waquar and Adiga, Nagraj and Jana, Sanjay Kumar and Samaddar, Arun B},
  booktitle={2018 International Conference on Signal Processing and Communications (SPCOM)},
  pages={257--261},
  year={2018},
  organization={IEEE}
}

@article{formant_norm,
author = {Kathania, Hemant and Kadiri, Sudarsana and Alku, Paavo and Kurimo, Mikko},
year = {2022},
month = {01},
pages = {98-106},
title = {A formant modification method for improved ASR of children’s speech},
volume = {136},
journal = {Speech Communication},
doi = {10.1016/j.specom.2021.11.003}
}
@inproceedings{tdnn,
  title={A time delay neural network architecture for efficient modeling of long temporal contexts},
  author={Peddinti, Vijayaditya and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={Sixteenth annual conference of the international speech communication association},
  year={2015}
}
@inproceedings{tdnnf-children,
  title={Advances in Automatic Speech Recognition for Child Speech Using Factored Time Delay Neural Network.},
  author={Wu, Fei and Garc{\'\i}a-Perera, Leibny Paola and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={Interspeech},
  pages={1--5},
  year={2019}
}

@inproceedings{TDNN-F,
  title={Semi-orthogonal low-rank matrix factorization for deep neural networks.},
  author={Povey, Daniel and Cheng, Gaofeng and Wang, Yiming and Li, Ke and Xu, Hainan and Yarmohammadi, Mahsa and Khudanpur, Sanjeev},
  booktitle={Interspeech},
  pages={3743--3747},
  year={2018}
}

@inproceedings{xu21c_interspeech,
  author={Gaopeng Xu and Song Yang and Lu Ma and Chengfei Li and Zhongqin Wu},
  title={{The TAL System for the INTERSPEECH2021 Shared Task on Automatic Speech Recognition for Non-Native Childrens Speech}},
  year=2021,
  booktitle={Proc. Interspeech 2021},
  pages={1294--1298},
  doi={10.21437/Interspeech.2021-1104}
}


@inproceedings{adultAUGMENT1,
  title={Mismatched training data enhancement for automatic recognition of children's speech using DNN-HMM},
  author={Qian, Mengjie and McLoughlin, Ian and Quo, Wu and Dai, Lirong},
  booktitle={2016 10th International Symposium on Chinese Spoken Language Processing (ISCSLP)},
  pages={1--5},
  year={2016},
  organization={IEEE}
}

@inproceedings{adultAUGMENT2,
  title={Improving Children's Speech Recognition Through Out-of-Domain Data Augmentation.},
  author={Fainberg, Joachim and Bell, Peter and Lincoln, Mike and Renals, Steve},
  booktitle={Interspeech},
  pages={1598--1602},
  year={2016}
}
@INPROCEEDINGS{nonnative,
  author={Matassoni, Marco and Gretter, Roberto and Falavigna, Daniele and Giuliani, Diego},
  booktitle={ICASSP}, 
  title={Non-Native Children Speech Recognition Through Transfer Learning}, 
  year={2018},
  volume={},
  number={},
  pages={6229-6233},
  doi={10.1109/ICASSP.2018.8462059}}
  
    @inproceedings{specaugment,
title	= {SpecAugment: A Simple Augmentation Method for Automatic Speech Recognition},
author	= {Daniel S. Park and William Chan and Yu Zhang and Chung-Cheng Chiu and Barret Zoph and Ekin Dogus Cubuk and Quoc V. Le},
year	= {2019},
booktitle	= {INTERSPEECH}
}

@inproceedings{pronunciation,
  title={Improving speech recognition for children using acoustic adaptation and pronunciation modeling.},
  author={Shivakumar, Prashanth Gurunath and Potamianos, Alexandros and Lee, Sungbok and Narayanan, Shrikanth S},
  booktitle={WOCCI},
  pages={15--19},
  year={2014}
}
@inproceedings{pronunciation2,
  title={An analysis of the causes of increased error rates in children's speech recognition},
  author={Li, Qun and Russell, Martin J},
  booktitle={Seventh International Conference on Spoken Language Processing},
  year={2002}
}
@article{subwords,
title = {Highly accurate children’s speech recognition for interactive reading tutors using subword units},
journal = {Speech Communication},
volume = {49},
number = {12},
pages = {861-873},
year = {2007},
issn = {0167-6393},
doi = {https://doi.org/10.1016/j.specom.2007.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S0167639307000878},
author = {Andreas Hagen and Bryan Pellom and Ronald Cole},
keywords = {Literacy tutors, Subword unit based speech recognition, Language modeling, Reading tracking},
}

@article{gelin2021endtoend,
title = {End-to-end acoustic modelling for phone recognition of young readers},
journal = {Speech Communication},
volume = {134},
pages = {71-84},
year = {2021},
issn = {0167-6393},
doi = {https://doi.org/10.1016/j.specom.2021.08.003},
author = {Lucile Gelin and Morgane Daniel and Julien Pinquier and Thomas Pellegrini},
keywords = {Child speech, Phone recognition, Transformer, Connectionist temporal classification, Transfer learning, Low-resource},
}

@article{sri_end2end,
title = {End-to-end neural systems for automatic children speech recognition: An empirical study},
journal = {Computer Speech \& Language},
volume = {72},
pages = {101289},
year = {2022},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2021.101289},
author = {Prashanth {Gurunath Shivakumar} and Shrikanth Narayanan},
keywords = {Children speech recognition, End-to-end speech recognition, Residual network, Time depth separable convolutional network, Transformer},
}

@inproceedings{valtchev1994novel,
  title={A novel decoder design for large vocabulary recognition},
  author={Valtchev, V and Odell, J and Woodland, PC and Young, SJ},
  booktitle={Proceedings of ICSLP},
  year={1994}
}

@inproceedings{aubert1995large,
  title={Large vocabulary continuous speech recognition using word graphs},
  author={Aubert, Xavier and Ney, Hermann},
  booktitle={1995 International Conference on Acoustics, Speech, and Signal Processing},
  volume={1},
  pages={49--52},
  year={1995},
  organization={IEEE}
}

@inproceedings{kaldi,
  title={The {Kaldi} speech recognition toolkit},
  author={Povey, Daniel and Ghoshal, Arnab and Boulianne, Gilles and Burget, Lukas and Glembek, Ondrej and Goel, Nagendra and Hannemann, Mirko and Motlicek, Petr and Qian, Yanmin and Schwarz, Petr and others},
  booktitle={IEEE 2011 workshop on automatic speech recognition and understanding},
  year={2011},
  organization={IEEE Signal Processing Society}
}




@INPROCEEDINGS{linguistic-children,
  author={Wilpon, J.G. and Jacobsen, C.N.},
  booktitle={ICASSP}, 
  title={A study of speech recognition for children and the elderly}, 
  year={1996},
  volume={1},
  number={},
  pages={349-352 vol. 1},
  doi={10.1109/ICASSP.1996.541104}}
 

@inproceedings{asr-improved2,
  title={Adaptation and Normalization Experiments in Speech Recognition for 4 to 8 Year old Children.},
  author={Elenius, Daniel and Blomberg, Mats},
  booktitle={Interspeech},
  pages={2749--2752},
  year={2005}
}


@inproceedings{GANS,
  title={GANs for Children: A Generative Data Augmentation Strategy for Children Speech Recognition},
  author={Sheng, Peiyao and Yang, Zhuolin and Qian, Yanmin},
  booktitle={2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={129--135},
  year={2019},
  organization={IEEE}
}

@inproceedings{etlt,
    title = "{TLT}-school: a Corpus of Non Native Children Speech",
    author = "Gretter, Roberto  and
      Matassoni, Marco  and
      Bann{\`o}, Stefano  and
      Daniele, Falavigna",
    booktitle = "Proceedings of the Twelfth Language Resources and Evaluation Conference - LREC",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2020.lrec-1.47",
    pages = "378--385",
    abstract = "This paper describes {``}TLT-school{''} a corpus of speech utterances collected in schools of northern Italy for assessing the performance of students learning both English and German. The corpus was recorded in the years 2017 and 2018 from students aged between nine and sixteen years, attending primary, middle and high school. All utterances have been scored, in terms of some predefined proficiency indicators, by human experts. In addition, most of utterances recorded in 2017 have been manually transcribed carefully. Guidelines and procedures used for manual transcriptions of utterances will be described in detail, as well as results achieved by means of an automatic speech recognition system developed by us. Part of the corpus is going to be freely distributed to scientific community particularly interested both in non-native speech recognition and automatic assessment of second language proficiency.",
    language = "English",
    ISBN = "979-10-95546-34-4",
}

@article{chorec,
  title={{Children’s oral reading corpus (CHOREC): description and assessment of annotator agreement}},
  author={Cleuren, Leen and Duchateau, Jacques and Ghesquiere, Pol and others},
  journal={LREC 2008 Proceedings},
  pages={998--1005},
  year={2008},
  publisher={European Language Resources Association (ELRA); Parijs}
}


@inproceedings{sphinx2,
author = {Huang, Xuedong and Alleva, Fileno and Hwang, Mei-Yuh and Rosenfeld, Ronald},
title = {An Overview of the SPHINX-II Speech Recognition System},
year = {1993},
isbn = {1558603247},
publisher = {Association for Computational Linguistics},
address = {USA},
url = {https://doi.org/10.3115/1075671.1075690},
doi = {10.3115/1075671.1075690},
abstract = {In the past year at Carnegie Mellon steady progress has been made in the area of acoustic and language modeling. The result has been a dramatic reduction in speech recognition errors in the SPHINX-II system. In this paper, we review SPHINX-II and summarize our recent efforts on improved speech recognition. Recently SPHINX-II achieved the lowest error rate in the November 1992 DARPA evaluations. For 5000-word, speaker-independent, continuous, speech recognition, the error rate was reduced to 5%.},
booktitle = {Proceedings of the Workshop on Human Language Technology},
pages = {81–86},
numpages = {6},
location = {Princeton, New Jersey},
series = {HLT '93}
}


@inproceedings{letsread,
  title={{The LetsRead corpus of Portuguese children reading aloud for performance evaluation}},
  author={Proen{\c{c}}a, Jorge and Celorico, Dirce and Candeias, Sara and Lopes, Carla and Perdig{\~a}o, Fernando},
  booktitle={Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC'16)},
  pages={781--785},
  year={2016}
}

@inproceedings{pfstar,
  title={The PF-Star Children's Speech Corpus},
  author={Russell, Martin and D'Arcy, Shona and Wong, M and Batliner, A and Blomberg, M and Gerosa, M},
  booktitle={Interspeech 2005},
  year={2005}
}

@INPROCEEDINGS{ssc,
  author={Paliwal, K.K.},
  booktitle={ICASSP}, 
  title={Spectral subband centroid features for speech recognition}, 
  year={1998},
  volume={2},
  number={},
  pages={617-620 vol.2},
  doi={10.1109/ICASSP.1998.675340}}
  
  
 @inproceedings{2019multi,
  title={Multi-task based mispronunciation detection of children speech using multi-lingual information},
  author={Wei, Linxuan and Dong, Wenwei and Lin, Binghuai and Zhang, Jinsong},
  booktitle={APSIPA ASC},
  pages={1791--1794},
  year={2019},
  organization={IEEE}
}

@article{meyer2019multi,
  title={Multi-task and transfer learning in low-resource speech recognition},
  author={Meyer, Josh},
  year={2019},
  publisher={The University of Arizona.}
}

@inproceedings{multi-nlp,
author = {Collobert, Ronan and Weston, Jason},
title = {A Unified Architecture for Natural Language Processing: Deep Neural Networks with Multitask Learning},
year = {2008},
isbn = {9781605582054},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1390156.1390177},
doi = {10.1145/1390156.1390177},
abstract = {We describe a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense (grammatically and semantically) using a language model. The entire network is trained jointly on all these tasks using weight-sharing, an instance of multitask learning. All the tasks use labeled data except the language model which is learnt from unlabeled text and represents a novel form of semi-supervised learning for the shared tasks. We show how both multitask learning and semi-supervised learning improve the generalization of the shared tasks, resulting in state-of-the-art-performance.},
booktitle = {ICML},
pages = {160–167},
numpages = {8},
location = {Helsinki, Finland},
series = {ICML '08}
}


@INPROCEEDINGS{multi-speech,
  author={Huang, Jui-Ting and Li, Jinyu and Yu, Dong and Deng, Li and Gong, Yifan},
  booktitle={ICASSP}, 
  title={Cross-language knowledge transfer using multilingual deep neural network with shared hidden layers}, 
  year={2013},
  volume={},
  number={},
  pages={7304-7308},
  doi={10.1109/ICASSP.2013.6639081}}
  
    @INPROCEEDINGS{abad2020,
  author={Abad, Alberto and Bell, Peter and Carmantini, Andrea and Renais, Steve},
  booktitle={ICASSP}, 
  title={Cross Lingual Transfer Learning for Zero-Resource Domain Adaptation}, 
  year={2020},
  volume={},
  number={},
  pages={6909-6913},
  doi={10.1109/ICASSP40776.2020.9054468}}

@inproceedings{MTL-LFMMI,
  title={Lattice-Free Maximum Mutual Information Training of Multilingual Speech Recognition Systems.},
  author={Madikeri, Srikanth R and Khonglah, Banriskhem K and Tong, Sibo and Motlicek, Petr and Bourlard, Herv{\'e} and Povey, Daniel},
  booktitle={INTERSPEECH},
  pages={4746--4750},
  year={2020}
}

@INPROCEEDINGS{VTLN2,  author={Serizel, Romain and Giuliani, Diego},  booktitle={SLT Workshop},   title={Vocal tract length normalisation approaches to DNN-based children's and adults' speech recognition},   year={2014},  volume={},  number={},  pages={135-140},  doi={10.1109/SLT.2014.7078563}}

@article{madikeri2021multitask,
  title={Multitask adaptation with Lattice-Free MMI for multi-genre speech recognition of low resource languages},
  author={Madikeri, Srikanth and Motlicek, Petr and Bourlard, Herv{\'e}},
  journal={Proc. Interspeech 2021},
  pages={4329--4333},
  year={2021}
}

@inproceedings{tachbelie2020development,
  title={Development of Multilingual ASR Using GlobalPhone for Less-Resourced Languages: The Case of Ethiopian Languages.},
  author={Tachbelie, Martha Yifiru and Abate, Solomon Teferra and Schultz, Tanja},
  booktitle={Interspeech 2020},
  pages={1032--1036},
  year={2020}
}

@article{semi,
  title={Semi-supervised asr by end-to-end self-training},
  author={Chen, Yang and Wang, Weiran and Wang, Chao},
  journal={arXiv preprint arXiv:2001.09128},
  year={2020}
}

@inproceedings{mtl_computervision,
  title={{Fast R-CNN}},
  author={Girshick, Ross},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1440--1448},
  year={2015}
}

@article{bioinfo,
  title={Domain-adversarial multi-task framework for novel therapeutic property prediction of compounds},
  author={Xie, Lingwei and He, Song and Zhang, Zhongnan and Lin, Kunhui and Bo, Xiaochen and Yang, Shu and Feng, Boyuan and Wan, Kun and Yang, Kang and Yang, Jie and others},
  journal={Bioinformatics},
  volume={36},
  number={9},
  pages={2848--2855},
  year={2020},
  publisher={Oxford University Press}
}

@article{zhang2018overview,
  title={An overview of multi-task learning},
  author={Zhang, Yu and Yang, Qiang},
  journal={National Science Review},
  volume={5},
  number={1},
  pages={30--43},
  year={2018},
  publisher={Oxford University Press}
}

@article{VTLN_wfun,
author = {Saito, Yuki and Takamichi, Shinnosuke and Saruwatari, Hiroshi},
year = {2019},
month = {06},
pages = {},
title = {Vocoder-free text-to-speech synthesis incorporating generative adversarial networks using low-/multi-frequency STFT amplitude spectra},
volume = {58},
journal = {Computer Speech \& Language},
doi = {10.1016/j.csl.2019.05.008}
}
@inproceedings{SPEECONS,
  title={SPEECON – Speech Databases for Consumer Devices: Database Specification and Validation},
  author={Dorota J. Iskra and Beate Grosskopf and Krzysztof Marasek and Henk van den Heuvel and Frank Diehl and Andreas Kiessling},
  booktitle={LREC},
  year={2002}
}

@article{callslt,
author = {Rayner, Manny and Tsourakis, Nikos and Baur, Claudia and Bouillon, Pierrette and Gerlach, Johanna},
year = {2014},
month = {01},
pages = {},
title = {CALL-SLT: A Spoken CALL System: based on grammar and speech recognition},
volume = {10},
journal = {Linguistic Issues in Language Technology},
doi = {10.33011/lilt.v10i.1353}
}


@article{childit2,
  title={CHILDIT2--A New Children Read Speech Corpus},
  author={Cosi, Piero and Paci, Giulio and Sommavilla, Giacomo and Tesser, Fabio},
  journal={Book series Studi AISV},
  volume={2},
  pages={269--273},
  year={2016}
}

@inproceedings{JASMIN,
    title = "Recording Speech of Children, Non-Natives and Elderly People for {HLT} Applications: the {JASMIN}-{CGN} Corpus.",
    author = "Cucchiarini, Catia  and
      Driesen, Joris  and
      Van hamme, Hugo  and
      Sanders, Eric",
    booktitle = "Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08)",
    month = may,
    year = "2008",
    address = "Marrakech, Morocco",
    publisher = "European Language Resources Association (ELRA)",
    url = "http://www.lrec-conf.org/proceedings/lrec2008/pdf/366_paper.pdf",
    abstract = "Within the framework of the Dutch-Flemish programme STEVIN, the JASMIN-CGN (Jongeren, Anderstaligen en Senioren in Mens-machine Interactie Corpus Gesproken Nederlands) project was carried out, which was aimed at collecting speech of children, non-natives and elderly people. The JASMIN-CGN project is an extension of the Spoken Dutch Corpus (CGN) along three dimensions. First, by collecting a corpus of contemporary Dutch as spoken by children of different age groups, elderly people and non-natives with different mother tongues, an extension along the age and mother tongue dimensions was achieved. In addition, we collected speech material in a communication setting that was not envisaged in the CGN: human-machine interaction. One third of the data was collected in Flanders and two thirds in the Netherlands. In this paper we report on our experiences in collecting this corpus and we describe some of the important decisions that we made in the attempt to combine efficiency and high quality.",
}

@inproceedings{takemaru,
  title={Public speech-oriented guidance system with adult and child discrimination capability},
  author={Nisimura, Ryuichi and Lee, Akinobu and Saruwatari, Hiroshi and Shikano, Kiyohiro},
  booktitle={2004 IEEE International Conference on Acoustics, Speech, and Signal Processing},
  volume={1},
  pages={I--433},
  year={2004},
  organization={IEEE}
}


@inproceedings{speco,
  title={{A Hungarian child database for speech processing applications}},
  author={Csat{\'a}ri, Ferenc and Bakcsi, Zs and Vicsi, Kl{\'a}ra},
  booktitle={Sixth European Conference on Speech Communication and Technology},
  year={1999}
}

@inproceedings{tball,
  title={Tball data collection: the making of a young children's speech corpus},
  author={Kazemzadeh, Abe and You, Hong and Iseli, Markus and Jones, Barbara and Cui, Xiaodong and Heritage, Margaret and Price, Patti and Anderson, Elaine and Narayanan, Shrikanth and Alwan, Abeer},
  booktitle={Ninth European Conference on Speech Communication and Technology},
  year={2005}
}
@inproceedings{ad-child_ru,
  title={{AD-Child RU: Speech corpus for Russian children with atypical development}},
  author={Lyakso, Elena and Frolova, Olga and Kaliyev, Arman and Gorodnyi, Viktor and Grigorev, Aleksey and Matveev, Yuri},
  booktitle={International Conference on Speech and Computer},
  pages={299--308},
  year={2019},
  organization={Springer}
}

@inproceedings{cuchild,
  author={Si-Ioi Ng and Cymie Wing-Yee Ng and Jiarui Wang and Tan Lee and Kathy Yuet-Sheung Lee and Michael Chi-Fai Tong},
  title={{CUCHILD: A Large-Scale Cantonese Corpus of Child Speech for Phonology and Articulation Assessment}},
  year=2020,
  booktitle={Proc. Interspeech 2020},
  pages={424--428},
  doi={10.21437/Interspeech.2020-2148}
}

@INPROCEEDINGS{cass_child,
author={Gao, Jun and Li, Aijun and Xiong, Ziyu},
booktitle={2012 International Conference on Speech Database and Assessments},
title={Mandarin multimedia child speech corpus: Cass\_Child},
year={2012},
volume={},
number={},
pages={7-12}, 
doi={10.1109/ICSDA.2012.6422462}}


@article{providence,
  title={Word-minimality, epenthesis and coda licensing in the early acquisition of English},
  author={Demuth, Katherine and Culbertson, Jennifer and Alter, Jennifer},
  journal={Language and speech},
  volume={49},
  number={2},
  pages={137--173},
  year={2006},
  publisher={Sage Publications Sage UK: London, England}
}

@article{LyonSC,
  title={Prosodically-conditioned variability in children's production of French determiners},
  author={Demuth, Katherine and Tremblay, Annie},
  journal={Journal of child language},
  volume={35},
  number={1},
  pages={99--127},
  year={2008},
  publisher={Cambridge University Press}
}


@incollection{demuth1992acquisition,
  title={The acquisition of Sesotho},
  author={Demuth, Katherine},
  booktitle={The crosslinguistic study of language acquisition},
  pages={557--638},
  year={1992},
  publisher={Psychology Press}
}

@inproceedings{nitk,
  author={Pravin Bhaskar Ramteke and Sujata Supanekar and Pradyoth Hegde and Hanna Nelson and Venkataraja Aithal and Shashidhar G. Koolagudi},
  title={{NITK Kids’ Speech Corpus}},
  year=2019,
  booktitle={Proc. Interspeech 2019},
  pages={331--335},
  doi={10.21437/Interspeech.2019-2061}
}

@inproceedings{chiede,
  title={CHIEDE, a spontaneous child language corpus of Spanish},
  author={Garrote, Marta and Moreno Sandoval, A},
  booktitle={Proceedings of the 3rd International LABLITA Workshop in Corpus Linguistics},
  year={2008}
}

@inproceedings{emochildru,
  title={EmoChildRu: emotional child Russian speech corpus},
  author={Lyakso, Elena and Frolova, Olga and Dmitrieva, Evgeniya and Grigorev, Aleksey and Kaya, Heysem and Salah, Albert Ali and Karpov, Alexey},
  booktitle={International Conference on Speech and Computer},
  pages={144--152},
  year={2015},
  organization={Springer}
}

@inproceedings{ahmed2021auskidtalk,
  title={AusKidTalk: an auditory-visual corpus of 3-to 12-year-old Australian children's speech},
  author={Ahmed, Beena and Ballard, Kirrie and Burnham, Denis and Sirojan, Tharmakulasingam and Mehmood, Hadi and Estival, Dominique and Baker, Elise and Cox, Felicity and Arciuli, Joanne and Benders, Titia and others},
  booktitle={Annual Conference of the International Speech Communication Association (22nd: 2021)},
  pages={3680--3684},
  year={2021},
  organization={International Speech Communication Association}
}

@inproceedings{eshky2019ultrasuite,
  author={Aciel Eshky and Manuel Sam Ribeiro and Joanne Cleland and Korin Richmond and Zoe Roxburgh and James M Scobbie and Alan Wrench},
  title={{UltraSuite: A Repository of Ultrasound and Acoustic Data from Child Speech Therapy Sessions}},
  year=2018,
  booktitle={Proc. Interspeech 2018},
  pages={1888--1892},
  doi={10.21437/Interspeech.2018-1736}
}


@INPROCEEDINGS{CFSC,  author={Pascual, Ronald M. and Guevara, Rowena Cristina L.},  booktitle={TENCON 2012 IEEE Region 10 Conference},   title={Developing a children's Filipino speech corpus for application in automatic detection of reading miscues and disfluencies},   year={2012},  volume={},  number={},  pages={1-6},  doi={10.1109/TENCON.2012.6412235}}

@inproceedings{hagen2003children,
  title={Children's speech recognition with application to interactive books and tutors},
  author={Hagen, Andreas and Pellom, Bryan and Cole, Ronald},
  booktitle={2003 IEEE Workshop on Automatic Speech Recognition and Understanding (IEEE Cat. No. 03EX721)},
  pages={186--191},
  year={2003},
  organization={IEEE}
}

@INPROCEEDINGS{leonard1993tidigits,
  author={Leonard, R.},
  booktitle={ICASSP '84. IEEE International Conference on Acoustics, Speech, and Signal Processing}, 
  title={A database for speaker-independent digit recognition}, 
  year={1984},
  volume={9},
  number={},
  pages={328-331},
  keywords={Databases;Humans;Loudspeakers;Microphones;Instruments;Laboratories;Vocabulary;Speech analysis;Algorithm design and analysis;Speech recognition},
  doi={10.1109/ICASSP.1984.1172716}}


@phdthesis{gerosa2006acoustic,
  title={Acoustic modeling for automatic recognition of children’s speech},
  author={Gerosa, M},
  year={2006},
  school={Ph. D. thesis, University of Trento}
}

@inproceedings{burkhardt2010database,
  title={A database of age and gender annotated telephone speech},
  author={Burkhardt, Felix and Eckert, Martin and Johannsen, Wiebke and Stegmann, Joachim},
  booktitle={Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC'10)},
  year={2010}
}

@inproceedings{bell2005swedish,
  title={The Swedish NICE Corpus--Spoken dialogues between children and embodied characters in a computer game scenario},
  author={Bell, Linda and Boye, Johan and Gustafson, Joakim and Heldner, Mattias and Lindstr{\"o}m, Anders and Wir{\'e}n, Mats},
  booktitle={Interspeech 2005-Eurospeech, 9th European Conference on Speech Communication and Technology, Lisbon, Portugal, September 4-8, 2005},
  pages={2765--2768},
  year={2005},
  organization={ISCA}
}

@article{grissemann2000zurcher,
  title={Z{\"u}rcher Lesetest},
  author={Grissemann, Hans and Linder, M},
  journal={Bern: Huber Verlag},
  year={2000}
}

@book{steidl2009automatic,
  title={Automatic classification of emotion related user states in spontaneous children's speech},
  author={Steidl, Stefan},
  year={2009},
  publisher={Logos-Verlag Berlin, Germany}
}

@inproceedings{bell2003child,
  author={Linda Bell and Joakim Gustafson},
  title={{Child and adult speaker adaptation during error resolution in a publicly available spoken dialogue system}},
  year=2003,
  booktitle={Proc. 8th European Conference on Speech Communication and Technology (Eurospeech 2003)},
  pages={613--616},
  doi={10.21437/Eurospeech.2003-259}
}

@article{PEREZESPINOSA202055,
title = {{IESC-Child: An Interactive Emotional Children’s Speech Corpus}},
journal = {Computer Speech \& Language},
volume = {59},
pages = {55-74},
year = {2020},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2019.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S0885230817301547},
author = {Humberto Pérez-Espinosa and Juan Martínez-Miranda and Ismael Espinosa-Curiel and Josefina Rodríguez-Jacobo and Luis Villaseñor-Pineda and Himer Avila-George},
keywords = {Interactive systems, Emotional analysis, Paralinguistic information},
abstract = {In this paper, we describe the process that we used to create a new corpus of children’s emotional speech. We used a Wizard of Oz (WoZ) setting to induce different emotional reactions in children during speech-based interactions with two robots. We recorded the speech spoken in Mexican Spanish by 174 children (both sexes) between 6 and 11 years of age. The recordings were manually segmented and transcribed. The segments were then labeled with two types of emotional-related paralinguistic information: emotion and attitude. The corpus contained 2093min of audio recordings (34.88h) divided into 19,793 speech segments. The Interactive Emotional Children’s Speech Corpus (IESC-Child) can be a valuable resource for researchers studying affective reactions in speech communication during child-computer interactions in Spanish and for creating models to recognize acoustic paralinguistic information. IESC-Child is available to the research community upon request.}
}

@inproceedings{hamalainen2013cng,
  title={{The CNG corpus of European Portuguese children’s speech}},
  author={H{\"a}m{\"a}l{\"a}inen, Annika and Rodrigues, Silvia and J{\'u}dice, Ana and Silva, Sandra Morgado and Calado, Ant{\'o}nio and Pinto, Fernando Miguel and Dias, Miguel Sales},
  booktitle={International Conference on Text, Speech and Dialogue},
  pages={544--551},
  year={2013},
  organization={Springer}
}

@article{big_review_childASR,
author = {Bhardwaj, Vivek and Kukreja, Vinay and Belkhier, Youcef and Bajaj, Mohit and .B, Srikanth Goud and Rehman, Ateeq and Hamam, Habib and Othman, Mohamed},
year = {2022},
month = {04},
pages = {},
title = {Automatic Speech Recognition ({ASR}) System for Children’s: A Systematic Literature Review},
journal = {Applied Sciences},
doi = {10.3390/app12094419}
}


@inproceedings{bdpublico,
  title={The design of a large vocabulary speech corpus for Portuguese},
  author={Neto, Joao P and Martins, Ciro A and Meinedo, Hugo and Almeida, Luis B},
  booktitle={Fifth European Conference on Speech Communication and Technology},
  year={1997}
}
@article{kunze2017transfer,
  title={Transfer learning for speech recognition on a budget},
  author={Kunze, Julius and Kirsch, Louis and Kurenkov, Ilia and Krug, Andreas and Johannsmeier, Jens and Stober, Sebastian},
  journal={arXiv preprint arXiv:1706.00290},
  year={2017}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{dong2018speech,
  title={Speech-transformer: a no-recurrence sequence-to-sequence model for speech recognition},
  author={Dong, Linhao and Xu, Shuang and Xu, Bo},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5884--5888},
  year={2018},
  organization={IEEE}
}

@inproceedings{
dosovitskiy2020image,
title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=YicbFdNTTy}
}

@article{hmm-end2end,
author = {Wang, Dong and Wang, Xiaodong and Lv, Shaohe},
year = {2019},
month = {08},
pages = {1018},
title = {An Overview of End-to-End Automatic Speech Recognition},
volume = {11},
journal = {Symmetry},
doi = {10.3390/sym11081018}
}

@inproceedings{VAE,
  author       = {Diederik P. Kingma and
                  Max Welling},
  editor       = {Yoshua Bengio and
                  Yann LeCun},
  title        = {Auto-Encoding Variational Bayes},
  booktitle    = {2nd International Conference on Learning Representations, {ICLR} 2014,
                  Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings},
  year         = {2014},
  url          = {http://arxiv.org/abs/1312.6114},
  timestamp    = {Thu, 04 Apr 2019 13:20:07 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/KingmaW13.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{houlsby,
  title={Parameter-efficient transfer learning for NLP},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={International Conference on Machine Learning},
  pages={2790--2799},
  year={2019},
  organization={PMLR}
}

@inproceedings{pfeiffer,
    title = "{MAD-X}: {A}n {A}dapter-{B}ased {F}ramework for {M}ulti-{T}ask {C}ross-{L}ingual {T}ransfer",
    author = "Pfeiffer, Jonas  and
      Vuli{\'c}, Ivan  and
      Gurevych, Iryna  and
      Ruder, Sebastian",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2020.emnlp-main.617",
    pages = "7654--7673",
}


@misc{speechbrain,
  title={{SpeechBrain}: A General-Purpose Speech Toolkit},
  author={Mirco Ravanelli and Titouan Parcollet and Peter Plantinga and Aku Rouhe and Samuele Cornell and Loren Lugosch and Cem Subakan and Nauman Dawalatabad and Abdelwahab Heba and Jianyuan Zhong and Ju-Chieh Chou and Sung-Lin Yeh and Szu-Wei Fu and Chien-Feng Liao and Elena Rastorgueva and François Grondin and William Aris and Hwidong Na and Yan Gao and Renato De Mori and Yoshua Bengio},
  year={2021},
  eprint={2106.04624},
  archivePrefix={arXiv},
  primaryClass={eess.AS},
  note={arXiv:2106.04624}
}

@article{vae_transformation,
  title={Modeling and transforming speech using variational autoencoders},
  author={Blaauw, Merlijn and Bonada, Jordi},
  journal={Morgan N, editor. Interspeech 2016; 2016 Sep 8-12; San Francisco, CA.[place unknown]: ISCA; 2016. p. 1770-4.},
  year={2016},
  publisher={International Speech Communication Association (ISCA)}
}

@article{vae_gen,
  title={Expressive speech synthesis via modeling expressions with variational autoencoder},
  author={Akuzawa, Kei and Iwasawa, Yusuke and Matsuo, Yutaka},
  journal={arXiv preprint arXiv:1804.02135},
  year={2018}
}

@inproceedings{vae_enh,
  title={A variance modeling framework based on variational autoencoders for speech enhancement},
  author={Leglaive, Simon and Girin, Laurent and Horaud, Radu},
  booktitle={2018 IEEE 28th International Workshop on Machine Learning for Signal Processing (MLSP)},
  pages={1--6},
  year={2018},
  organization={IEEE}
}

@inproceedings{philip2020monolingual,
  title={Monolingual adapters for zero-shot neural machine translation},
  author={Philip, Jerin and Berard, Alexandre and Gall{\'e}, Matthias and Besacier, Laurent},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={4465--4470},
  year={2020}
}

@inproceedings{kannan2019large,
  author={Anjuli Kannan and Arindrima Datta and Tara N. Sainath and Eugene Weinstein and Bhuvana Ramabhadran and Yonghui Wu and Ankur Bapna and Zhifeng Chen and Seungji Lee},
  title={{Large-Scale Multilingual Speech Recognition with a Streaming End-to-End Model}},
  year=2019,
  booktitle={Proc. Interspeech 2019},
  pages={2130--2134},
  doi={10.21437/Interspeech.2019-2858}
}

@inproceedings{tomanek2021residual,
    title = "Residual Adapters for Parameter-Efficient {ASR} Adaptation to Atypical and Accented Speech",
    author = "Tomanek, Katrin  and
      Zayats, Vicky  and
      Padfield, Dirk  and
      Vaillancourt, Kara  and
      Biadsy, Fadi",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.541",
    doi = "10.18653/v1/2021.emnlp-main.541",
    pages = "6751--6760",
    abstract = "Automatic Speech Recognition (ASR) systems are often optimized to work best for speakers with canonical speech patterns. Unfortunately, these systems perform poorly when tested on atypical speech and heavily accented speech. It has previously been shown that personalization through model fine-tuning substantially improves performance. However, maintaining such large models per speaker is costly and difficult to scale. We show that by adding a relatively small number of extra parameters to the encoder layers via so-called residual adapter, we can achieve similar adaptation gains compared to model fine-tuning, while only updating a tiny fraction (less than 0.5{\%}) of the model parameters. We demonstrate this on two speech adaptation tasks (atypical and accented speech) and for two state-of-the-art ASR architectures.",
}

@article{chen2020data,
  title={Data Augmentation For Children's Speech Recognition--The ``Ethiopian" System For The SLT 2021 Children Speech Recognition Challenge},
  author={Chen, Guoguo and Na, Xingyu and Wang, Yongqing and Yan, Zhiyong and Zhang, Junbo and Ma, Sifan and Wang, Yujun},
  journal={arXiv preprint arXiv:2011.04547},
  year={2020}
}

@article{ng2020cuhk,
  title={The {CUHK-TUDELFT} system for the {SLT} 2021 children speech recognition challenge},
  author={Ng, Si-Ioi and Liu, Wei and Peng, Zhiyuan and Feng, Siyuan and Huang, Hing-Pang and Scharenborg, Odette and Lee, Tan},
  journal={arXiv preprint arXiv:2011.06239},
  year={2020}
}


@inproceedings{luscher2019rwth,
  author={Christoph Lüscher and Eugen Beck and Kazuki Irie and Markus Kitza and Wilfried Michel and Albert Zeyer and Ralf Schlüter and Hermann Ney},
  title={{RWTH ASR Systems for LibriSpeech: Hybrid vs Attention}},
  year=2019,
  booktitle={Proc. Interspeech 2019},
  pages={231--235},
  doi={10.21437/Interspeech.2019-1780}
}

@inproceedings{battenberg2017exploring,
  title={Exploring neural transducers for end-to-end speech recognition},
  author={Battenberg, Eric and Chen, Jitong and Child, Rewon and Coates, Adam and Li, Yashesh Gaur Yi and Liu, Hairong and Satheesh, Sanjeev and Sriram, Anuroop and Zhu, Zhenyao},
  booktitle={2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={206--213},
  year={2017},
  organization={IEEE}
}


@inproceedings{soltau2016neural,
  author={Hagen Soltau and Hank Liao and Haşim Sak},
  title={{Neural Speech Recognizer: Acoustic-to-Word LSTM Model for Large Vocabulary Speech Recognition}},
  year=2017,
  booktitle={Proc. Interspeech 2017},
  pages={3707--3711},
  doi={10.21437/Interspeech.2017-1566}
}

@article{tribus,
  title={TRIBUS: An end-to-end automatic speech recognition system for European Portuguese},
  author={Carlos F. Carvalho and Alberto Abad},
  journal={IberSPEECH 2021},
  year={2021}
}

@INPROCEEDINGS{hmmvse2e,  author={Karita, Shigeki and Chen, Nanxin and Hayashi, Tomoki and Hori, Takaaki and Inaguma, Hirofumi and Jiang, Ziyan and Someki, Masao and Soplin, Nelson Enrique Yalta and Yamamoto, Ryuichi and Wang, Xiaofei and Watanabe, Shinji and Yoshimura, Takenori and Zhang, Wangyou},  booktitle={2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},   title={A Comparative Study on Transformer vs RNN in Speech Applications},   year={2019},  volume={},  number={},  pages={449-456},  doi={10.1109/ASRU46091.2019.9003750}}

@article{hannun2014deep,
  title={Deep speech: Scaling up end-to-end speech recognition},
  author={Hannun, Awni and Case, Carl and Casper, Jared and Catanzaro, Bryan and Diamos, Greg and Elsen, Erich and Prenger, Ryan and Satheesh, Sanjeev and Sengupta, Shubho and Coates, Adam and others},
  journal={arXiv preprint arXiv:1412.5567},
  year={2014}
}
@article{sutskever2014sequence,
  title={Sequence to sequence learning with neural networks},
  author={Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@conference{bahdanau2014neural,
title={Neural machine translation by jointly learning to align and translate},
author={Dzmitry Bahdanau and Cho, {Kyung Hyun} and Yoshua Bengio},
year = {2015},
booktitle={3rd International Conference on Learning Representations, ICLR 2015},
}

@INPROCEEDINGS{seq2seq_imagecaption,  author={Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},  booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},   title={Show and tell: A neural image caption generator},   year={2015},  volume={},  number={},  pages={3156-3164},  doi={10.1109/CVPR.2015.7298935}}

@article{vinyals2015neural,
  title={A neural conversational model},
  author={Vinyals, Oriol and Le, Quoc},
  journal={arXiv preprint arXiv:1506.05869},
  year={2015}
}



@inproceedings{nallapati2016abstractive,
    title = "Abstractive Text Summarization using Sequence-to-sequence {RNN}s and Beyond",
    author={Nallapati, Ramesh and Zhou, Bowen and Gulcehre, Caglar and Xiang, Bing and others},
    booktitle = {Proceedings of the 20th {SIGNLL} Conference on Computational Natural Language Learning},
    year = {2016},
    address ={Berlin, Germany},
    publisher = {Association for Computational Linguistics},
    url = {https://aclanthology.org/K16-1028},
    doi = {10.18653/v1/K16-1028},
    pages = {280--290},
}

@inproceedings{shen2018natural,
  title={Natural tts synthesis by conditioning wavenet on mel spectrogram predictions},
  author={Shen, Jonathan and Pang, Ruoming and Weiss, Ron J and Schuster, Mike and Jaitly, Navdeep and Yang, Zongheng and Chen, Zhifeng and Zhang, Yu and Wang, Yuxuan and Skerrv-Ryan, Rj and others},
  booktitle={2018 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={4779--4783},
  year={2018},
  organization={IEEE}
}

@inproceedings{wang2021towards,
  title={Towards data selection on {TTS} data for children’s speech recognition},
  author={Wang, Wei and Zhou, Zhikai and Lu, Yizhou and Wang, Hongji and Du, Chenpeng and Qian, Yanmin},
  booktitle={2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6888--6892},
  year={2021},
  organization={IEEE}
}

@inproceedings{kim2021conditional,
  title={Conditional variational autoencoder with adversarial learning for end-to-end text-to-speech},
  author={Kim, Jaehyeon and Kong, Jungil and Son, Juhee},
  booktitle={International Conference on Machine Learning},
  pages={5530--5540},
  year={2021},
  organization={PMLR}
}

@inproceedings{laptev2020you,
  title={You do not need more data: Improving end-to-end speech recognition by text-to-speech data augmentation},
  author={Laptev, Aleksandr and Korostik, Roman and Svischev, Aleksey and Andrusenko, Andrei and Medennikov, Ivan and Rybin, Sergey},
  booktitle={2020 13th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)},
  pages={439--444},
  year={2020},
  organization={IEEE}
}

@inproceedings{gelin2021simulating,
  title={Simulating reading mistakes for child speech Transformer-based phone recognition},
  author={Gelin, Lucile and Pellegrini, Thomas and Pinquier, Julien and Daniel, Morgane},
  booktitle={Annual Conference of the International Speech Communication Association (INTERSPEECH)},
  year={2021}
}

@inproceedings{gelin2020babble,
  title={Babble noise augmentation for phone recognition applied to children reading aloud in a classroom environment},
  author={Gelin, Lucile and Daniel, Morgane and Pellegrini, Thomas and Pinquier, Julien},
  booktitle={Speech in Noise Workshop (SPiN)},
  year={2020}
}
@inproceedings{couvreur2000use,
  title={On the use of artificial reverberation for ASR in highly reverberant environments},
  author={Couvreur, Laurent and Couvreur, Christophe},
  booktitle={Proc. 2nd IEEE Benelux Signal Processing Symposium (SPS-2000), Hilvarenbeek, The Netherlands},
  pages={S001--S004},
  year={2000},
  organization={Citeseer}
}
@article{whitenoise,
title = {Assessing local noise level estimation methods: Application to noise robust ASR},
journal = {Speech Communication},
volume = {34},
number = {1},
pages = {141-158},
year = {2001},
note = {Noise Robust ASR},
issn = {0167-6393},
doi = {https://doi.org/10.1016/S0167-6393(00)00051-0},
url = {https://www.sciencedirect.com/science/article/pii/S0167639300000510},
author = {Christophe Ris and Stéphane Dupont},
keywords = {Robust automatic speech recognition, Noise level estimation, Noise reduction, Spectral subtraction, Missing data},
abstract = {In this paper, we assess and compare four methods for the local estimation of noise spectra, namely the energy clustering, the Hirsch histograms, the weighted average method and the low-energy envelope tracking. Moreover we introduce, for these four approaches, the harmonic filtering strategy, a new pre-processing technique, expected to better track fast modulations of the noise energy. The speech periodicity property is used to update the noise level estimate during voiced parts of speech, without explicit detection of voiced portions. Our evaluation is performed with six different kinds of noises (both artificial and real noises) added to clean speech. The best noise level estimation method is then applied to noise robust speech recognition based on techniques requiring a dynamic estimation of the noise spectra, namely spectral subtraction and missing data compensation.
Zusammenfassung
Dans ce papier, nous nous proposons d'évaluer et de comparer différentes méthodes d'estimation locale du spectre de bruit: le clustering des énergies, les histogrammes de Hirsch, la méthode de la moyenne pondérée ainsi que le suivi de l'enveloppe de basse energie. Nous présentons également, en pré-traitement pour chacune de ces méthodes, le filtrage des harmoniques, une technique permettant de suivre plus efficacement des variations rapides de l'énergie du bruit. Le caractère harmonique de certaines portions de parole est exploité afin de réestimer le niveau de bruit pendant les périodes de sons voisés (sans détection explicite du caractère voisé ou non des segments de parole). Ces différentes approches ont été testées sur six types de bruit différents (artificiels et réels) ajoutés à de la parole claire. Les estimateurs de niveaux de bruit ainsi testés ont alors été appliqués à deux méthodes de reconnaissance de la parole robuste aux bruits basées sur la soustraction spectrale et la théorie des données manquantes.}
}

@inproceedings{malek2017robust,
  title={Robust Automatic Recognition of Speech with background music},
  author={Malek, Jiri and Zdansky, Jindrich and Cerva, Petr},
  booktitle={2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5210--5214},
  year={2017},
  organization={IEEE}
}
@inproceedings{VTLP,
  title={Vocal tract length perturbation (VTLP) improves speech recognition},
  author={Jaitly, Navdeep and Hinton, Geoffrey E},
  booktitle={Proc. ICML Workshop on Deep Learning for Audio, Speech and Language},
  volume={117},
  pages={21},
  year={2013}
}

@inproceedings{liu2003noise,
  title={Noise robustness in speech to speech translation},
  author={Liu, Fu-Hua and Gao, Yuqing and Gu, Liang and Picheny, Michael},
  booktitle={Eighth European Conference on Speech Communication and Technology},
  year={2003}
}

@article{pfeiffer2020adapterfusion,
  title={AdapterFusion: Non-destructive task composition for transfer learning},
  author={Pfeiffer, Jonas and Kamath, Aishwarya and R{\"u}ckl{\'e}, Andreas and Cho, Kyunghyun and Gurevych, Iryna},
  journal={arXiv preprint arXiv:2005.00247},
  year={2020}
}


@article{van2017neural,
  title={Neural discrete representation learning},
  author={Van Den Oord, Aaron and Vinyals, Oriol and others},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{cooper2020zero,
  title={Zero-shot multi-speaker text-to-speech with state-of-the-art neural speaker embeddings},
  author={Cooper, Erica and Lai, Cheng-I and Yasuda, Yusuke and Fang, Fuming and Wang, Xin and Chen, Nanxin and Yamagishi, Junichi},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6184--6188},
  year={2020},
  organization={IEEE}
}

@inproceedings{hu2022synt++,
  title={SYNT++: Utilizing Imperfect Synthetic Data to Improve Speech Recognition},
  author={Hu, Ting-Yao and Armandpour, Mohammadreza and Shrivastava, Ashish and Chang, Jen-Hao Rick and Koppula, Hema and Tuzel, Oncel},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7682--7686},
  year={2022},
  organization={IEEE}
}

@article{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{hsu2021hubert,
  title={Hubert: Self-supervised speech representation learning by masked prediction of hidden units},
  author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={29},
  pages={3451--3460},
  year={2021},
  publisher={IEEE}
}

@article{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={12449--12460},
  year={2020}
}

@inproceedings{caseiro2002using,
  title={Using dynamic {WFST} composition for recognizing broadcast news},
  author={Caseiro, Diamantino and Trancoso, Isabel},
  booktitle={Seventh International Conference on Spoken Language Processing},
  year={2002}
}

@article{mohri1997finite,
  title={Finite-state transducers in language and speech processing},
  author={Mohri, Mehryar},
  journal={Computational linguistics},
  volume={23},
  number={2},
  pages={269--311},
  year={1997}
}

@article{botelho2020pathological,
  title={Pathological speech detection using x-vector embeddings},
  author={Botelho, Catarina and Teixeira, Francisco and Rolland, Thomas and Abad, Alberto and Trancoso, Isabel},
  journal={arXiv preprint arXiv:2003.00864},
  year={2020}
}

@inproceedings{snyder2018x,
  title={X-vectors: Robust dnn embeddings for speaker recognition},
  author={Snyder, David and Garcia-Romero, Daniel and Sell, Gregory and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2018 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={5329--5333},
  year={2018},
  organization={IEEE}
}

@inproceedings{hauptman2019identifying,
  title={Identifying Distinctive Acoustic and Spectral Features in Parkinson's Disease.},
  author={Hauptman, Yermiyahu and Aloni-Lavi, Ruth and Lapidot, Itshak and Gurevich, Tanya and Manor, Yael and Naor, Stav and Diamant, Noa and Opher, Irit},
  booktitle={Interspeech},
  pages={2498--2502},
  year={2019}
}

@inproceedings{botelho2019speech,
  title={Speech as a biomarker for obstructive sleep apnea detection},
  author={Botelho, M Catarina and Trancoso, Isabel and Abad, Alberto and Paiva, Teresa},
  booktitle={ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5851--5855},
  year={2019},
  organization={IEEE}
}


@inproceedings{pompili2020inesc,
  author={Anna Pompili and Thomas Rolland and Alberto Abad},
  title={{The INESC-ID Multi-Modal System for the ADReSS 2020 Challenge}},
  year=2020,
  booktitle={Proc. Interspeech 2020},
  pages={2202--2206},
  doi={10.21437/Interspeech.2020-2833}
}

@article{bizzocchi2017many,
  title={How many phonemes does the English language have?},
  author={Bizzocchi, Aldo Luiz},
  journal={International Journal on Studies in English Language and Literature (IJSELL)},
  volume={5},
  number={10},
  pages={36--46},
  year={2017}
}

@article{benzeghiba2007automatic,
  title={Automatic speech recognition and speech variability: A review},
  author={Benzeghiba, Mohamed and De Mori, Renato and Deroo, Olivier and Dupont, Stephane and Erbes, Teodora and Jouvet, Denis and Fissore, Luciano and Laface, Pietro and Mertins, Alfred and Ris, Christophe and others},
  journal={Speech communication},
  volume={49},
  number={10-11},
  pages={763--786},
  year={2007},
  publisher={Elsevier}
}

@article{arora2012automatic,
  title={Automatic speech recognition: a review},
  author={Arora, Shipra J and Singh, Rishi Pal},
  journal={International Journal of Computer Applications},
  volume={60},
  number={9},
  year={2012},
  publisher={Foundation of Computer Science}
}

@article{karpagavalli2016review,
  title={A review on automatic speech recognition architecture and approaches},
  author={Karpagavalli, S and Chandra, Edy},
  journal={International Journal of Signal Processing, Image Processing and Pattern Recognition},
  volume={9},
  number={4},
  pages={393--404},
  year={2016}
}

@book{bourlard2012connectionist,
  title={Connectionist speech recognition: a hybrid approach},
  author={Bourlard, Herve A and Morgan, Nelson},
  volume={247},
  year={2012},
  publisher={Springer Science \& Business Media}
}
@inproceedings{meinedo2003audimus,
  title={AUDIMUS. media: a Broadcast News speech recognition system for the European Portuguese language},
  author={Meinedo, Hugo and Caseiro, Diamantino and Neto, Joao and Trancoso, Isabel},
  booktitle={International Workshop on Computational Processing of the Portuguese Language},
  pages={9--17},
  year={2003},
  organization={Springer}
}


@inproceedings{fan2022draft,
  author={Ruchao Fan and Abeer Alwan},
  title={{DRAFT: A Novel Framework to Reduce Domain Shifting in Self-supervised Learning and Its Application to Children’s ASR}},
  year=2022,
  booktitle={Proc. Interspeech 2022},
  pages={4900--4904},
  doi={10.21437/Interspeech.2022-11128}
}

@article{shivakumar2020transfer,
  title={Transfer learning from adult to children for speech recognition: Evaluation, analysis and recommendations},
  author={Shivakumar, Prashanth Gurunath and Georgiou, Panayiotis},
  journal={Computer speech \& language},
  volume={63},
  pages={101077},
  year={2020},
  publisher={Elsevier}
}

@article{langbecker2020long,
  title={Long-term effects of childhood speech and language disorders: A scoping review},
  author={Langbecker, Danette and Snoswell, Centaine L and Smith, Anthony C and Verboom, Jedidja and Caffery, Liam J},
  journal={South African Journal of Childhood Education},
  volume={10},
  number={1},
  pages={1--13},
  year={2020},
  publisher={AOSIS Publishing}
}
@article{black2015communication,
  title={Communication Disorders and Use of Intervention Services among Children Aged 3--17 Years: United States, 2012; US Department of Health and Human Services, Centers for Disease Control and Prevention},
  author={Black, LI and Vahratian, A and Hoffman, HJ},
  journal={National Center for Health Statistics: Atlanta, GA, USA},
  year={2015}
}

@book{levelt1993speaking,
    author = {Levelt, Willem J. M.},
    title = "{Speaking: From Intention to Articulation}",
    publisher = {The MIT Press},
    year = {1993},
    month = {08},
    abstract = "{In Speaking, Willem "Pim" Levelt, Director of the Max-Planck-Institut für Psycholinguistik, accomplishes the formidable task of covering the entire process of speech production, from constraints on conversational appropriateness to articulation and self-monitoring of speech. Speaking is unique in its balanced coverage of all major aspects of the production of speech, in the completeness of its treatment of the entire speech process, and in its strategy of exemplifying rather than formalizing theoretical issues.}",
    isbn = {9780262278225},
    doi = {10.7551/mitpress/6393.001.0001},
    url = {https://doi.org/10.7551/mitpress/6393.001.0001},
}

@article{hughes2019increasing,
  title={Increasing access to rural mental health care using hybrid care that includes telepsychiatry.},
  author={Hughes, M Courtney and Gorman, Jack M and Ren, Yingqian and Khalid, Sana and Clayton, Carol},
  journal={Journal of Rural Mental Health},
  volume={43},
  number={1},
  pages={30},
  year={2019},
  publisher={Educational Publishing Foundation}
}

@article{barnett2011utilizing,
  title={Utilizing technological innovations to enhance psychotherapy supervision, training, and outcomes.},
  author={Barnett, Jeffrey E},
  journal={Psychotherapy},
  volume={48},
  number={2},
  pages={103},
  year={2011},
  publisher={Educational Publishing Foundation}
}
@article{hilty2015new,
  title={New frontiers in healthcare and technology: Internet-and web-based mental options emerge to complement in-person and telepsychiatric care options},
  author={Hilty, DM and Chan, S and Torous, J and Mahautmr, J and Mucic, DM},
  journal={J Health Med Informatics},
  volume={6},
  number={4},
  pages={1--14},
  year={2015}
}

@phdthesis{mendoza2022added,
  title={The added value of speech technology in clinical care of patients with dysarthria},
  author={Mendoza Ramos, Viviana},
  year={2022},
  school={University of Antwerp}
}

@inproceedings{brewer2013using,
  title={Using gamification to motivate children to complete empirical studies in lab environments},
  author={Brewer, Robin and Anthony, Lisa and Brown, Quincy and Irwin, Germaine and Nias, Jaye and Tate, Berthel},
  booktitle={Proceedings of the 12th international conference on interaction design and children},
  pages={388--391},
  year={2013}
}

@inproceedings{li2023asr,
  author={Yuanchao Li and Zeyu Zhao and Ondřej Klejch and Peter Bell and Catherine Lai},
  title={{ASR and Emotional Speech: A Word-Level Investigation of the Mutual Impact of Speech and Emotion Recognition}},
  year=2023,
  booktitle={Proc. INTERSPEECH 2023},
  pages={1449--1453},
  doi={10.21437/Interspeech.2023-2078}
}

@article{li2014overview,
  title={An overview of noise-robust automatic speech recognition},
  author={Li, Jinyu and Deng, Li and Gong, Yifan and Haeb-Umbach, Reinhold},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={22},
  number={4},
  pages={745--777},
  year={2014},
  publisher={IEEE}
}

@inproceedings{king2017robust,
  author={Brian King and I-Fan Chen and Yonatan Vaizman and Yuzong Liu and Roland Maas and Sree Hari Krishnan Parthasarathi and Björn Hoffmeister},
  title={{Robust Speech Recognition via Anchor Word Representations}},
  year=2017,
  booktitle={Proc. Interspeech 2017},
  pages={2471--2475},
  doi={10.21437/Interspeech.2017-1570}
}

@book{moats2000speech,
  title={Speech to print: Language essentials for teachers},
  author={Moats, Louisa Cook and Brady, Susan},
  year={2000},
  publisher={Paul H. Brookes Pub.}
}
@article{clark1977psychology,
  title={Psychology and language},
  author={Clark, Herbert H and Clark, Eve V},
  journal={Journal of Child Language},
  year={1977},
  volume={4},
  pages={b1–b3},
  publisher={Harcourt Brace Jovanovich New York}
}

@inproceedings{radford2023robust,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={28492--28518},
  year={2023},
  organization={PMLR}
}

@inproceedings{chen2021gigaspeech,
  author={Guoguo Chen and Shuzhou Chai and Guan-Bo Wang and Jiayu Du and Wei-Qiang Zhang and Chao Weng and Dan Su and Daniel Povey and Jan Trmal and Junbo Zhang and Mingjie Jin and Sanjeev Khudanpur and Shinji Watanabe and Shuaijiang Zhao and Wei Zou and Xiangang Li and Xuchen Yao and Yongqing Wang and Zhao You and Zhiyong Yan},
  title={{GigaSpeech: An Evolving, Multi-Domain ASR Corpus with 10,000 Hours of Transcribed Audio}},
  year=2021,
  booktitle={Proc. Interspeech 2021},
  pages={3670--3674},
  doi={10.21437/Interspeech.2021-1965}
}

@article{khanzadi2022persian,
  title={Persian phoneme and syllable recognition using recurrent neural networks for phonological awareness assessment},
  author={Khanzadi, Maryam and Veisi, Hadi and Alinaghizade, Roghaye and Soleymani, Zahra},
  journal={Journal of AI and Data Mining},
  volume={10},
  number={1},
  pages={117--126},
  year={2022},
  publisher={Shahrood University of Technology}
}
@article{klatt1977review,
  title={Review of the {ARPA} speech understanding project},
  author={Klatt, Dennis H},
  journal={The Journal of the Acoustical Society of America},
  volume={62},
  number={6},
  pages={1345--1366},
  year={1977},
  publisher={Acoustical Society of America}
}

@inproceedings{kiktova2013comparison,
  title={Comparison of different feature types for acoustic event detection system},
  author={Kiktova, Eva and Lojka, Martin and Pleva, Matus and Juhar, Jozef and Cizmar, Anton},
  booktitle={Multimedia Communications, Services and Security: 6th International Conference, MCSS 2013, Krakow, Poland, June 6-7, 2013. Proceedings 6},
  pages={288--297},
  year={2013},
  organization={Springer}
}
@article{weide1998carnegie,
  title={The carnegie mellon pronouncing dictionary},
  author={Weide, Robert and others},
  journal={release 0.6, www. cs. cmu. edu},
  year={1998}
}

@inproceedings{schwartz1985context,
  title={Context-dependent modeling for acoustic-phonetic recognition of continuous speech},
  author={Schwartz, Richard and Chow, YL and Kimball, Owen and Roucos, S and Krasner, M and Makhoul, John},
  booktitle={ICASSP'85. IEEE International Conference on Acoustics, Speech, and Signal Processing},
  volume={10},
  pages={1205--1208},
  year={1985},
  organization={IEEE}
}

@inproceedings{bahl1991context,
  title={Context dependent modeling of phones in continuous speech using decision trees},
  author={Bahl, Lalit R and deSouza, Peter V and Gopalakrishnan, PS and Nahamoo, David and Picheny, MA},
  booktitle={Speech and Natural Language: Proceedings of a Workshop Held at Pacific Grove, California, February 19-22, 1991},
  year={1991}
}

@inproceedings{sak2014long,
  author={Hasim Sak and Andrew Senior and Fran{\c{c}}oise Beaufays},
  title={{Long short-term memory recurrent neural network architectures for large scale acoustic modeling}},
  year=2014,
  booktitle={Proc. Interspeech 2014},
  pages={338--342},
  doi={10.21437/Interspeech.2014-80}
}

@article{lang1990time,
  title={A time-delay neural network architecture for isolated word recognition},
  author={Lang, Kevin J and Waibel, Alex H and Hinton, Geoffrey E},
  journal={Neural networks},
  volume={3},
  number={1},
  pages={23--43},
  year={1990},
  publisher={Elsevier}
}
@incollection{waibel2013phoneme,
  title={Phoneme recognition using time-delay neural networks},
  author={Waibel, Alexander and Hanazawa, Toshiyuki and Hinton, Geoffrey and Shikano, Kiyohiro and Lang, Kevin J},
  booktitle={Backpropagation},
  pages={35--61},
  year={2013},
  publisher={Psychology Press}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@inproceedings{richardson1995lattice,
  title={Lattice-based search strategies for large vocabulary speech recognition},
  author={Richardson, Frederick and Ostendorf, Mari and Rohlicek, Jan Robin},
  booktitle={1995 International Conference on Acoustics, Speech, and Signal Processing},
  volume={1},
  pages={576--579},
  year={1995},
  organization={IEEE}
}

@inproceedings{tuske2021limit,
  author={Zoltán Tüske and George Saon and Brian Kingsbury},
  title={{On the Limit of English Conversational Speech Recognition}},
  year=2021,
  booktitle={Proc. Interspeech 2021},
  pages={2062--2066},
  doi={10.21437/Interspeech.2021-211}
}

@article{bermuth2021scribosermo,
  title={Scribosermo: fast speech-to-text models for German and other languages},
  author={Bermuth, Daniel and Poeppel, Alexander and Reif, Wolfgang},
  journal={arXiv preprint arXiv:2110.07982},
  year={2021}
}

@article{chan2021speechstew,
  title={Speechstew: Simply mix all available speech recognition data to train one large neural network},
  author={Chan, William and Park, Daniel and Lee, Chris and Zhang, Yu and Le, Quoc and Norouzi, Mohammad},
  journal={arXiv preprint arXiv:2104.02133},
  year={2021}
}
@inproceedings{ghai2009exploring,
  title={Exploring the role of spectral smoothing in context of children's speech recognition},
  author={Ghai, Shweta and Sinha, Rohit},
  booktitle={Tenth Annual Conference of the International Speech Communication Association},
  year={2009}
}

@phdthesis{ghai2011addressing,
  title={Addressing pitch mismatch for children's automatic speech recognition},
  author={Ghai, Shweta},
  school={Indian Institute of technology Guwahati},
  year={2011}
}

@inproceedings{claus2013survey,
  title={A Survey about ASR for Children},
  author={Claus, Felix and Gamboa Rosales, Hamurabi and Petrick, Rico and Hain, Horst-Udo and Hoffmann, R{\"u}diger},
  booktitle={Speech and Language Technology in Education},
  year={2013}
}

@inproceedings{potamianos1997automatic,
  title={Automatic speech recognition for children},
  author={Potamianos, Alexandros and Narayanan, Shrikanth and Lee, Sungbok},
  booktitle={Fifth European Conference on Speech Communication and Technology},
  year={1997}
}
@inproceedings{potamianos1997combining,
  title={On combining frequency warping and spectral shaping in HMM based speech recognition},
  author={Potamianos, Alexandros and Rose, Richard C},
  booktitle={1997 IEEE International Conference on Acoustics, Speech, and Signal Processing},
  volume={2},
  pages={1275--1278},
  year={1997},
  organization={IEEE}
}

@inproceedings{shahnawazuddin2023gammatone,
  title={Gammatone-Filterbank Based Pitch-Normalized Cepstral Coefficients for Zero-Resource Children’s ASR},
  author={Shahnawazuddin, Syed and Ankita and Kumar, Avinash and Kathania, Hemant Kumar},
  booktitle={International Conference on Speech and Computer},
  pages={494--505},
  year={2023},
  organization={Springer}
}

@inproceedings{kumar2023effect,
  title={Effect of Linear Prediction Order to Modify Formant Locations for Children Speech Recognition},
  author={Kumar, Udara Laxman and Kurimo, Mikko and Kathania, Hemant Kumar},
  booktitle={International Conference on Speech and Computer},
  pages={483--493},
  year={2023},
  organization={Springer}
}

@article{kadyan2023prosody,
  title={Prosody features based low resource Punjabi children ASR and T-NT classifier using data augmentation},
  author={Kadyan, Virender and Hasija, Taniya and Singh, Amitoj},
  journal={Multimedia Tools and Applications},
  volume={82},
  number={3},
  pages={3973--3994},
  year={2023},
  publisher={Springer}
}

@inproceedings{gale2019improving,
  title={Improving asr systems for children with autism and language impairment using domain-focused dnn transfer techniques},
  author={Gale, Robert and Chen, Liu and Dolata, Jill and Van Santen, Jan and Asgari, Meysam},
  booktitle={Interspeech},
  volume={2019},
  pages={11},
  year={2019},
  organization={NIH Public Access}
}

@article{bhardwaj2022automatic,
  title={Automatic speech recognition (asr) systems for children: A systematic literature review},
  author={Bhardwaj, Vivek and Ben Othman, Mohamed Tahar and Kukreja, Vinay and Belkhier, Youcef and Bajaj, Mohit and Goud, B Srikanth and Rehman, Ateeq Ur and Shafiq, Muhammad and Hamam, Habib},
  journal={Applied Sciences},
  volume={12},
  number={9},
  pages={4419},
  year={2022},
  publisher={MDPI}
}

@article{kumar2020leveraging,
  title={Leveraging linguistic context in dyadic interactions to improve automatic speech recognition for children},
  author={Kumar, Manoj and Kim, So Hyun and Lord, Catherine and Lyon, Thomas D and Narayanan, Shrikanth},
  journal={Computer speech \& language},
  volume={63},
  pages={101101},
  year={2020},
  publisher={Elsevier}
}



@INPROCEEDINGS{chan2015listen,
  author={Chan, William and Jaitly, Navdeep and Le, Quoc and Vinyals, Oriol},
  booktitle={2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Listen, attend and spell: A neural network for large vocabulary conversational speech recognition}, 
  year={2016},
  volume={},
  number={},
  pages={4960-4964},
  keywords={Hidden Markov models;Speech recognition;Acoustics;Speech;Decoding;Training;Context;Recurrent neural network;neural attention;end-to-end speech recognition},
  doi={10.1109/ICASSP.2016.7472621}}


@article{targ2016resnet,
  title={Resnet in resnet: Generalizing residual architectures},
  author={Targ, Sasha and Almeida, Diogo and Lyman, Kevin},
  journal={arXiv preprint arXiv:1603.08029},
  year={2016}
}

@inproceedings{shuyangdata,
  author={Shuyang Zhao and Mittul Singh and Abraham Woubie and Reima Karhila},
  title={{Data augmentation for children ASR and child-adult speaker classification using voice conversion methods}},
  year=2023,
  booktitle={Proc. INTERSPEECH 2023},
  pages={4593--4597},
  doi={10.21437/Interspeech.2023-702}
}

@article{dua2022spectral,
  title={Spectral warping and data augmentation for low resource language ASR system under mismatched conditions},
  author={Dua, Mohit and Kadyan, Virender and Banthia, Neha and Bansal, Akshit and Agarwal, Tanya},
  journal={Applied Acoustics},
  volume={190},
  pages={108643},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{nagano2019data,
  title={Data augmentation based on vowel stretch for improving children's speech recognition},
  author={Nagano, Tohru and Fukuda, Takashi and Suzuki, Masayuki and Kurata, Gakuto},
  booktitle={2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={502--508},
  year={2019},
  organization={IEEE}
}

@inproceedings{yeung2021fundamental,
  title={Fundamental frequency feature normalization and data augmentation for child speech recognition},
  author={Yeung, Gary and Fan, Ruchao and Alwan, Abeer},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6993--6997},
  year={2021},
  organization={IEEE}
}

@inproceedings{singh2022spectral,
  author={Vishwanath Pratap Singh and Hardik Sailor and Supratik Bhattacharya and Abhishek Pandey},
  title={{Spectral Modification Based Data Augmentation For Improving End-to-End ASR For Children’s Speech}},
  year=2022,
  booktitle={Proc. Interspeech 2022},
  pages={3213--3217},
  doi={10.21437/Interspeech.2022-11343}
}

@inproceedings{lo2020ntnu,
  author={Tien-Hong Lo and Fu-An Chao and Shi-Yan Weng and Berlin Chen},
  title={{The NTNU System at the Interspeech 2020 Non-Native Children’s Speech ASR Challenge}},
  year=2020,
  booktitle={Proc. Interspeech 2020},
  pages={250--254},
  doi={10.21437/Interspeech.2020-1990}
}

@inproceedings{ma2006unsupervised,
  title={Unsupervised training on large amounts of broadcast news data},
  author={Ma, Jeff and Matsoukas, Spyros and Kimball, Owen and Schwartz, Richard},
  booktitle={2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings},
  volume={3},
  pages={III--III},
  year={2006},
  organization={IEEE}
}

@inproceedings{zavaliagkos1998utilizing,
  author={George Zavaliagkos and Man-Hung Siu and Thomas Colthurst and Jayadev Billa},
  title={{Using untranscribed training data to improve performance}},
  year=1998,
  booktitle={Proc. 5th International Conference on Spoken Language Processing (ICSLP 1998)},
  pages={paper 1007},
  doi={10.21437/ICSLP.1998-679}
}

@inproceedings{henaff2020data,
  title={Data-efficient image recognition with contrastive predictive coding},
  author={Henaff, Olivier},
  booktitle={International conference on machine learning},
  pages={4182--4192},
  year={2020},
  organization={PMLR}
}

@article{sarzynska2021detecting,
  title={Detecting formal thought disorder by deep contextualized word representations},
  author={Sarzynska-Wawer, Justyna and Wawer, Aleksander and Pawlak, Aleksandra and Szymanowska, Julia and Stefaniak, Izabela and Jarkiewicz, Michal and Okruszek, Lukasz},
  journal={Psychiatry Research},
  volume={304},
  pages={114135},
  year={2021},
  publisher={Elsevier}
}
@inproceedings{riviere2020unsupervised,
  title={Unsupervised pretraining transfers well across languages},
  author={Riviere, Morgane and Joulin, Armand and Mazar{\'e}, Pierre-Emmanuel and Dupoux, Emmanuel},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7414--7418},
  year={2020},
  organization={IEEE}
}

@inproceedings{wang2022wav2vec,
  title={Wav2vec-switch: Contrastive learning from original-noisy speech pairs for robust speech recognition},
  author={Wang, Yiming and Li, Jinyu and Wang, Heming and Qian, Yao and Wang, Chengyi and Wu, Yu},
  booktitle={2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7097--7101},
  year={2022},
  organization={IEEE}
}

@article{li2021accent,
  title={Accent-robust automatic speech recognition using supervised and unsupervised wav2vec embeddings},
  author={Li, Jialu and Manohar, Vimal and Chitkara, Pooja and Tjandra, Andros and Picheny, Michael and Zhang, Frank and Zhang, Xiaohui and Saraf, Yatharth},
  journal={arXiv preprint arXiv:2110.03520},
  year={2021}
}

@inproceedings{xu2021tal,
  title={{The TAL System for the INTERSPEECH2021 Shared Task on Automatic Speech Recognition for Non-Native Childrens Speech.}},
  author={Xu, Gaopeng and Yang, Song and Ma, Lu and Li, Chengfei and Wu, Zhongqin},
  booktitle={Interspeech},
  pages={1294--1298},
  year={2021}
}

@ARTICLE{jain2023wav2vec2,
  author={Jain, Rishabh and Barcovschi, Andrei and Yiwere, Mariam Yahayah and Bigioi, Dan and Corcoran, Peter and Cucu, Horia},
  journal={IEEE Access}, 
  title={{A WAV2VEC2-Based Experimental Study on Self-Supervised Learning Methods to Improve Child Speech Recognition}}, 
  year={2023},
  volume={11},
  number={},
  pages={46938-46948},
  keywords={Speech recognition;Data models;Pediatrics;Automatic speech recognition;Transformers;Perturbation methods;Self-supervised learning;Child speech recognition;self-supervised learning;wav2vec2;automatic speech recognition;MyST dataset;PFSTAR dataset;CMU_kids dataset},
  doi={10.1109/ACCESS.2023.3275106}}


@inproceedings{jain2023adaptation,
  author={Rishabh Jain and Andrei Barcovschi and Mariam Yiwere and Peter Corcoran and Horia Cucu},
  title={{Adaptation of Whisper models to child speech recognition}},
  year=2023,
  booktitle={Proc. INTERSPEECH 2023},
  pages={5242--5246},
  doi={10.21437/Interspeech.2023-935}
}

@inproceedings{yeung2019robotic,
  title={A robotic interface for the administration of language, literacy, and speech pathology assessments for children.},
  author={Yeung, Gary and Bailey, Alison L and Afshan, Amber and Tinkler, Morgan and P{\'e}rez, Marlen Q and Martin, Alejandra and Pogossian, Anahit A and Spaulding, Samuel and Park, Hae Won and Muco, Manushaqe and others},
  booktitle={SLaTE},
  pages={41--42},
  year={2019}
}

@inproceedings{yu2021slt,
  title={{The SLT 2021 children speech recognition challenge: Open datasets, rules and baselines}},
  author={Yu, Fan and Yao, Zhuoyuan and Wang, Xiong and An, Keyu and Xie, Lei and Ou, Zhijian and Liu, Bo and Li, Xiulin and Miao, Guanqiong},
  booktitle={2021 IEEE Spoken Language Technology Workshop (SLT)},
  pages={1117--1123},
  year={2021},
  organization={IEEE}
}

@inproceedings{bahrini2023chatgpt,
  title={ChatGPT: Applications, opportunities, and threats},
  author={Bahrini, Aram and Khamoshifar, Mohammadsadra and Abbasimehr, Hossein and Riggs, Robert J and Esmaeili, Maryam and Majdabadkohne, Rastin Mastali and Pasehvar, Morteza},
  booktitle={2023 Systems and Information Engineering Design Symposium (SIEDS)},
  pages={274--279},
  year={2023},
  organization={IEEE}
}

@inproceedings{ramesh2021zero,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={8821--8831},
  year={2021},
  organization={PMLR}
}

@inproceedings{wu2020lite,
  author       = {Zhanghao Wu and
                  Zhijian Liu and
                  Ji Lin and
                  Yujun Lin and
                  Song Han},
  title        = {Lite Transformer with Long-Short Range Attention},
  booktitle    = {8th International Conference on Learning Representations, {ICLR} 2020,
                  Addis Ababa, Ethiopia, April 26-30, 2020},
  publisher    = {OpenReview.net},
  year         = {2020},
  url          = {https://openreview.net/forum?id=ByeMPlHKPH},
  timestamp    = {Thu, 11 Feb 2021 23:39:38 +0100},
  biburl       = {https://dblp.org/rec/conf/iclr/WuLLLH20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{dauphin2017language,
  title={Language modeling with gated convolutional networks},
  author={Dauphin, Yann N and Fan, Angela and Auli, Michael and Grangier, David},
  booktitle={International conference on machine learning},
  pages={933--941},
  year={2017},
  organization={PMLR}
}


@inproceedings{gulati2020conformer,
  author={Anmol Gulati and James Qin and Chung-Cheng Chiu and Niki Parmar and Yu Zhang and Jiahui Yu and Wei Han and Shibo Wang and Zhengdong Zhang and Yonghui Wu and Ruoming Pang},
  title={{Conformer: Convolution-augmented Transformer for Speech Recognition}},
  year=2020,
  booktitle={Proc. Interspeech 2020},
  pages={5036--5040},
  doi={10.21437/Interspeech.2020-3015}
}

@inproceedings{bello2019attention,
  title={Attention augmented convolutional networks},
  author={Bello, Irwan and Zoph, Barret and Vaswani, Ashish and Shlens, Jonathon and Le, Quoc V},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={3286--3295},
  year={2019}
}

@inproceedings{yang2019convolutional,
    title = "Convolutional Self-Attention Networks",
    author = "Yang, Baosong  and
      Wang, Longyue  and
      Wong, Derek F.  and
      Chao, Lidia S.  and
      Tu, Zhaopeng",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1407",
    doi = "10.18653/v1/N19-1407",
    pages = "4040--4045",
    abstract = "Self-attention networks (SANs) have drawn increasing interest due to their high parallelization in computation and flexibility in modeling dependencies. SANs can be further enhanced with multi-head attention by allowing the model to attend to information from different representation subspaces. In this work, we propose novel convolutional self-attention networks, which offer SANs the abilities to 1) strengthen dependencies among neighboring elements, and 2) model the interaction between features extracted by multiple attention heads. Experimental results of machine translation on different language pairs and model settings show that our approach outperforms both the strong Transformer baseline and other existing models on enhancing the locality of SANs. Comparing with prior studies, the proposed model is parameter free in terms of introducing no more parameters.",
}


@article{lu2019understanding,
  title={Understanding and improving transformer from a multi-particle dynamic system point of view},
  author={Lu, Yiping and Li, Zhuohan and He, Di and Sun, Zhiqing and Dong, Bin and Qin, Tao and Wang, Liwei and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:1906.02762},
  year={2019}
}


@inproceedings{
frankle2018lottery,
title={The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks},
author={Jonathan Frankle and Michael Carbin},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=rJl-b3RcF7},
}

@INPROCEEDINGS{10095837,
  author={Eeckt, Steven Vander and Van Hamme, Hugo},
  booktitle={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Using Adapters to Overcome Catastrophic Forgetting in End-to-End Automatic Speech Recognition}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  doi={10.1109/ICASSP49357.2023.10095837}}

@inproceedings{rolland2022multilingual,
    title = "Multilingual Transfer Learning for Children Automatic Speech Recognition",
    author = "Rolland, Thomas  and
      Abad, Alberto  and
      Cucchiarini, Catia  and
      Strik, Helmer", 
    booktitle = "LREC 2022",
    month = jun,
    year = "2022",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "",
    pages = "7314--7320",
    abstract = "Despite recent advances in automatic speech recognition (ASR), the recognition of children{'}s speech still remains a significant challenge. This is mainly due to the high acoustic variability and the limited amount of available training data. The latter problem is particularly evident in languages other than English, which are usually less-resourced. In the current paper, we address children ASR in a number of less-resourced languages by combining several small-sized children speech corpora from these languages. In particular, we address the following research question: Does a novel two-step training strategy in which multilingual learning is followed by language-specific transfer learning outperform conventional single language/task training for children speech, as well as multilingual and transfer learning alone? Based on previous experimental results with English, we hypothesize that multilingual learning provides a better generalization of the underlying characteristics of children{'}s speech. Our results provide a positive answer to our research question, by showing that using transfer learning on top of a multilingual model for an unseen language outperforms conventional single language-specific learning.",
}

@INPROCEEDINGS{9847929,
  author={Shraddha, S and G, Jyothish Lal and S, Sachin Kumar},
  booktitle={2022 2nd International Conference on Intelligent Technologies (CONIT)}, 
  title={Child Speech Recognition on End-to-End Neural ASR Models}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/CONIT55038.2022.9847929}}

@inproceedings{hwang2022large,
  title={Large-scale asr domain adaptation using self-and semi-supervised learning},
  author={Hwang, Dongseong and Misra, Ananya and Huo, Zhouyuan and Siddhartha, Nikhil and Garg, Shefali and Qiu, David and Sim, Khe Chai and Strohman, Trevor and Beaufays, Fran{\c{c}}oise and He, Yanzhang},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6627--6631},
  year={2022},
  organization={IEEE}
}

@inproceedings{ruckle2020adapterdrop,
    title = "{AdapterDrop}: {O}n the Efficiency of Adapters in Transformers",
    author = {R{\"u}ckl{\'e}, Andreas  and
      Geigle, Gregor  and
      Glockner, Max  and
      Beck, Tilman  and
      Pfeiffer, Jonas  and
      Reimers, Nils  and
      Gurevych, Iryna},
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.626",
    doi = "10.18653/v1/2021.emnlp-main.626",
    pages = "7930--7946",
    abstract = "Transformer models are expensive to fine-tune, slow for inference, and have large storage requirements. Recent approaches tackle these shortcomings by training smaller models, dynamically reducing the model size, and by training light-weight adapters. In this paper, we propose AdapterDrop, removing adapters from lower transformer layers during training and inference, which incorporates concepts from all three directions. We show that AdapterDrop can dynamically reduce the computational overhead when performing inference over multiple tasks simultaneously, with minimal decrease in task performances. We further prune adapters from AdapterFusion, which improves the inference efficiency while maintaining the task performances entirely.",
}

@article{chen2023efficient,
  title={Efficient Adapters for Giant Speech Models},
  author={Chen, Nanxin and Shafran, Izhak and Zhang, Yu and Chiu, Chung-Cheng and Soltau, Hagen and Qin, James and Wu, Yonghui},
  journal={arXiv preprint arXiv:2306.08131},
  year={2023}
}


@article{kulkarni2023adapting,
  title={Adapting the adapters for code-switching in multilingual ASR},
  author={Kulkarni, Atharva and Kulkarni, Ajinkya and Couceiro, Miguel and Aldarmaki, Hanan},
  journal={arXiv preprint arXiv:2310.07423},
  year={2023}
}

@article{hou2021exploiting,
  title={Exploiting adapters for cross-lingual low-resource speech recognition},
  author={Hou, Wenxin and Zhu, Han and Wang, Yidong and Wang, Jindong and Qin, Tao and Xu, Renjun and Shinozaki, Takahiro},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={30},
  pages={317--329},
  year={2021},
  publisher={IEEE}
}

@inproceedings{thomas2022efficient,
  title={Efficient adapter transfer of self-supervised speech models for automatic speech recognition},
  author={Thomas, Bethan and Kessler, Samuel and Karout, Salah},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7102--7106},
  year={2022},
  organization={IEEE}
}
@article{cappellazzo2023parameter,
  title={Parameter-Efficient Transfer Learning of Audio Spectrogram Transformers},
  author={Cappellazzo, Umberto and Falavigna, Daniele and Brutti, Alessio and Ravanelli, Mirco},
  journal={arXiv preprint arXiv:2312.03694},
  year={2023}
}

@inproceedings{kovaleva-etal-2019-revealing,
    title = "Revealing the Dark Secrets of {BERT}",
    author = "Kovaleva, Olga  and
      Romanov, Alexey  and
      Rogers, Anna  and
      Rumshisky, Anna",
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1445",
    doi = "10.18653/v1/D19-1445",
    pages = "4365--4374",
    abstract = "BERT-based architectures currently give state-of-the-art performance on many NLP tasks, but little is known about the exact mechanisms that contribute to its success. In the current work, we focus on the interpretation of self-attention, which is one of the fundamental underlying components of BERT. Using a subset of GLUE tasks and a set of handcrafted features-of-interest, we propose the methodology and carry out a qualitative and quantitative analysis of the information encoded by the individual BERT{'}s heads. Our findings suggest that there is a limited set of attention patterns that are repeated across different heads, indicating the overall model overparametrization. While different heads consistently use the same attention patterns, they have varying impact on performance across different tasks. We show that manually disabling attention in certain heads leads to a performance improvement over the regular fine-tuned BERT models.",
}

@article{michel2019sixteen,
  title={Are sixteen heads really better than one?},
  author={Michel, Paul and Levy, Omer and Neubig, Graham},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{zheng22d_interspeech,
  author={Weiyi Zheng and Alex Xiao and Gil Keren and Duc Le and Frank Zhang and Christian Fuegen and Ozlem Kalinli and Yatharth Saraf and Abdelrahman Mohamed},
  title={{Scaling ASR Improves Zero and Few Shot Learning}},
  year=2022,
  booktitle={Proc. Interspeech 2022},
  pages={5135--5139},
  doi={10.21437/Interspeech.2022-11023}
}

@article{Kaplan2020ScalingLF,
  title={Scaling Laws for Neural Language Models},
  author={Jared Kaplan and Sam McCandlish and T. J. Henighan and Tom B. Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeff Wu and Dario Amodei},
  journal={ArXiv},
  year={2020},
  volume={abs/2001.08361},
  url={https://api.semanticscholar.org/CorpusID:210861095}
}

@article{wang2021fine,
  title={A fine-tuned wav2vec 2.0/hubert benchmark for speech emotion recognition, speaker verification and spoken language understanding},
  author={Wang, Yingzhi and Boumadane, Abdelmoumene and Heba, Abdelwahab},
  journal={arXiv preprint arXiv:2111.02735},
  year={2021}
}

@article{ye2023partial,
  title={Partial Fine-Tuning: A Successor to Full Fine-Tuning for Vision Transformers},
  author={Ye, Peng and Huang, Yongqi and Tu, Chongjun and Li, Minglei and Chen, Tao and He, Tong and Ouyang, Wanli},
  journal={arXiv preprint arXiv:2312.15681},
  year={2023}
}

@inproceedings{shen2021partial,
  title={Partial is better than all: revisiting fine-tuning strategy for few-shot learning},
  author={Shen, Zhiqiang and Liu, Zechun and Qin, Jie and Savvides, Marios and Cheng, Kwang-Ting},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={11},
  pages={9594--9602},
  year={2021}
}

@article{Sanh2019DistilBERTAD,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Victor Sanh and Lysandre Debut and Julien Chaumond and Thomas Wolf},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.01108},
  url={https://api.semanticscholar.org/CorpusID:203626972}
}

@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}

@article{mccarley2019structured,
  title={Structured pruning of a bert-based question answering model},
  author={McCarley, JS and Chakravarti, Rishav and Sil, Avirup},
  journal={arXiv preprint arXiv:1910.06360},
  year={2019}
}


@article{gandhi2023distilwhisper,
  title={Distil-Whisper: Robust Knowledge Distillation via Large-Scale Pseudo Labelling},
  author={Gandhi, Sanchit and von Platen, Patrick and Rush, Alexander M},
  journal={arXiv preprint arXiv:2311.00430},
  year={2023}
}

@inproceedings{peng23c_interspeech,
  author={Yifan Peng and Yui Sudo and Shakeel Muhammad and Shinji Watanabe},
  title={{DPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models}},
  year=2023,
  booktitle={Proc. INTERSPEECH 2023},
  pages={62--66},
  doi={10.21437/Interspeech.2023-1213}
}

@inproceedings{glorot2010understanding,
  title={Understanding the difficulty of training deep feedforward neural networks},
  author={Glorot, Xavier and Bengio, Yoshua},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={249--256},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{lian2022scaling,
  title={Scaling \& shifting your features: A new baseline for efficient model tuning},
  author={Lian, Dongze and Zhou, Daquan and Feng, Jiashi and Wang, Xinchao},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={109--123},
  year={2022}
}

@inproceedings{wu2018group,
  title={Group normalization},
  author={Wu, Yuxin and He, Kaiming},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={3--19},
  year={2018}
}

@inproceedings{huang2017arbitrary,
  title={Arbitrary style transfer in real-time with adaptive instance normalization},
  author={Huang, Xun and Belongie, Serge},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1501--1510},
  year={2017}
}

@inproceedings{sun2016return,
  title={Return of frustratingly easy domain adaptation},
  author={Sun, Baochen and Feng, Jiashi and Saenko, Kate},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={30},
  number={1},
  year={2016}
}


@inproceedings{ben-zaken-etal-2022-bitfit,
    title = "{B}it{F}it: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models",
    author = "Ben Zaken, Elad  and
      Goldberg, Yoav  and
      Ravfogel, Shauli",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-short.1",
    doi = "10.18653/v1/2022.acl-short.1",
    pages = "1--9",
    abstract = "We introduce BitFit, a sparse-finetuning method where only the bias-terms of the model (or a subset of them) are being modified. We show that with small-to-medium training data, applying BitFit on pre-trained BERT models is competitive with (and sometimes better than) fine-tuning the entire model. For larger data, the method is competitive with other sparse fine-tuning methods. Besides their practical utility, these findings are relevant for the question of understanding the commonly-used process of finetuning: they support the hypothesis that finetuning is mainly about exposing knowledge induced by language-modeling training, rather than learning new task-specific linguistic knowledge.",
}

@inproceedings{fu-etal-2022-adapterbias,
    title = "{A}dapter{B}ias: Parameter-efficient Token-dependent Representation Shift for Adapters in {NLP} Tasks",
    author = "Fu, Chin-Lun  and
      Chen, Zih-Ching  and
      Lee, Yun-Ru  and
      Lee, Hung-yi",
    editor = "Carpuat, Marine  and
      de Marneffe, Marie-Catherine  and
      Meza Ruiz, Ivan Vladimir",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2022",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-naacl.199",
    doi = "10.18653/v1/2022.findings-naacl.199",
    pages = "2608--2621",
    abstract = "Transformer-based pre-trained models with millions of parameters require large storage. Recent approaches tackle this shortcoming by training adapters, but these approaches still require a relatively large number of parameters. In this study, AdapterBias, a surprisingly simple yet effective adapter architecture, is proposed. AdapterBias adds a token-dependent shift to the hidden output of transformer layers to adapt to downstream tasks with only a vector and a linear layer. Extensive experiments are conducted to demonstrate the effectiveness of AdapterBias. The experiments show that our proposed method can dramatically reduce the trainable parameters compared to the previous works with a minimal decrease in task performances compared with fine-tuned pre-trained models. We further find that AdapterBias automatically learns to assign more significant representation shifts to the tokens related to the task in consideration.",
}

@inproceedings{he2022towards,
title={Towards a Unified View of Parameter-Efficient Transfer Learning},
author={Junxian He and Chunting Zhou and Xuezhe Ma and Taylor Berg-Kirkpatrick and Graham Neubig},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=0RDcd5Axok}
}

@inproceedings{mao-etal-2022-unipelt,
    title = "{U}ni{PELT}: A Unified Framework for Parameter-Efficient Language Model Tuning",
    author = "Mao, Yuning  and
      Mathias, Lambert  and
      Hou, Rui  and
      Almahairi, Amjad  and
      Ma, Hao  and
      Han, Jiawei  and
      Yih, Scott  and
      Khabsa, Madian",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.433",
    doi = "10.18653/v1/2022.acl-long.433",
    pages = "6253--6264",
    abstract = "Recent parameter-efficient language model tuning (PELT) methods manage to match the performance of fine-tuning with much fewer trainable parameters and perform especially well when training data is limited. However, different PELT methods may perform rather differently on the same task, making it nontrivial to select the most appropriate method for a specific task, especially considering the fast-growing number of new PELT methods and tasks. In light of model diversity and the difficulty of model selection, we propose a unified framework, UniPELT, which incorporates different PELT methods as submodules and learns to activate the ones that best suit the current data or task setup via gating mechanism. On the GLUE benchmark, UniPELT consistently achieves 1 4{\%} gains compared to the best individual PELT method that it incorporates and even outperforms fine-tuning under different setups. Moreover, UniPELT generally surpasses the upper bound that takes the best performance of all its submodules used individually on each task, indicating that a mixture of multiple PELT methods may be inherently more effective than single methods.",
}

@inproceedings{muthuchamyselvaraj23_interspeech,
  author={Nithish {Muthuchamy Selvaraj} and Xiaobao Guo and Adams Kong and Bingquan Shen and Alex Kot},
  title={{Adapter Incremental Continual Learning of Efficient Audio Spectrogram Transformers}},
  year=2023,
  booktitle={Proc. INTERSPEECH 2023},
  pages={909--913},
  doi={10.21437/Interspeech.2023-1189}
}

@inproceedings{yang23p_interspeech,
  author={Li-Jen Yang and Chao-Han Huck Yang and Jen-Tzung Chien},
  title={{Parameter-Efficient Learning for Text-to-Speech Accent Adaptation}},
  year=2023,
  booktitle={Proc. INTERSPEECH 2023},
  pages={4354--4358},
  doi={10.21437/Interspeech.2023-1212}
}

@inproceedings{li2023evaluating,
  title={Evaluating Parameter-Efficient Transfer Learning Approaches on SURE Benchmark for Speech Understanding},
  author={Li, Yingting and Mehrish, Ambuj and Zhao, Shuai and Bhardwaj, Rishabh and Zadeh, Amir and Majumder, Navonil and Mihalcea, Rada and Poria, Soujanya},
  booktitle={ICASSP},
  year={2023}
}
@article{jie2022convolutional,
  title={Convolutional bypasses are better vision transformer adapters},
  author={Jie, Shibo and Deng, Zhi-Hong},
  journal={arXiv preprint arXiv:2207.07039},
  year={2022}
}

@inproceedings{hu2018squeeze,
  title={Squeeze-and-excitation networks},
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7132--7141},
  year={2018}
}

@inproceedings{pires2023one,
title = {One Wide Feedforward is All You Need},
booktitle = {EMNLP Workshop},
author = {Telmo Pessoa Pires and António V. Lopes and Yannick Assogba and Hendra Setiawan},
year = {2024},
URL = {https://arxiv.org/abs/2309.01826}
}

@inproceedings{geva2020transformer,
    title={Transformer Feed-Forward Layers Are Key-Value Memories},
    author={Geva, Mor and Schuster, Roei and Berant, Jonathan and Levy, Omer},
    booktitle = {Empirical Methods in Natural Language Processing (EMNLP)},
    year={2021},
}
@inproceedings{yang21c_interspeech,
  author={Shu-wen Yang and Po-Han Chi and Yung-Sung Chuang and Cheng-I Jeff Lai and Kushal Lakhotia and Yist Y. Lin and Andy T. Liu and Jiatong Shi and Xuankai Chang and Guan-Ting Lin and Tzu-Hsien Huang and Wei-Cheng Tseng and Ko-tik Lee and Da-Rong Liu and Zili Huang and Shuyan Dong and Shang-Wen Li and Shinji Watanabe and Abdelrahman Mohamed and Hung-yi Lee},
  title={{SUPERB: Speech Processing Universal PERformance Benchmark}},
  year=2021,
  booktitle={Proc. Interspeech 2021},
  pages={1194--1198},
  doi={10.21437/Interspeech.2021-1775}
}
@inproceedings{chang2021exploration,
  title={An exploration of self-supervised pretrained representations for end-to-end speech recognition},
  author={Chang, Xuankai and Maekaku, Takashi and Guo, Pengcheng and Shi, Jing and Lu, Yen-Ju and Subramanian, Aswin Shanmugam and Wang, Tianzi and Yang, Shu-wen and Tsao, Yu and Lee, Hung-yi and others},
  booktitle={2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={228--235},
  year={2021},
  organization={IEEE}
}

@INPROCEEDINGS{librilight,
  author={J. {Kahn} and M. {Rivière} and W. {Zheng} and E. {Kharitonov} and Q. {Xu} and P. E. {Mazaré} and J. {Karadayi} and V. {Liptchinsky} and R. {Collobert} and C. {Fuegen} and T. {Likhomanenko} and G. {Synnaeve} and A. {Joulin} and A. {Mohamed} and E. {Dupoux}},
  booktitle={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Libri-Light: A Benchmark for ASR with Limited or No Supervision}, 
  year={2020},
  pages={7669-7673},
  note = {\url{https://github.com/facebookresearch/libri-light}},
}

@inproceedings{babu2021xlsr,
  author={Arun Babu and Changhan Wang and Andros Tjandra and Kushal Lakhotia and Qiantong Xu and Naman Goyal and Kritika Singh and Patrick {von Platen} and Yatharth Saraf and Juan Pino and Alexei Baevski and Alexis Conneau and Michael Auli},
  title={{XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale}},
  year=2022,
  booktitle={Proc. Interspeech 2022},
  pages={2278--2282},
  doi={10.21437/Interspeech.2022-143}
}

@phdthesis{phdthesis,
author = {Gelin, Lucile},
year = {2022},
month = {02},
pages = {},
school={Toulouse III - Paul Sabatier University},

title = {Reconnaissance automatique de la parole d'enfants apprenant·e·s lecteur·ice·s en salle de classe : modélisation acoustique de phonèmes}
}

@inproceedings{mcauliffe2017montreal,
  title={Montreal forced aligner: Trainable text-speech alignment using kaldi.},
  author={McAuliffe, Michael and Socolof, Michaela and Mihuc, Sarah and Wagner, Michael and Sonderegger, Morgan},
  booktitle={Interspeech},
  volume={2017},
  pages={498--502},
  year={2017}
}

@inproceedings{laaridh17_interspeech,
  author={Imed Laaridh and Waad Ben Kheder and Corinne Fredouille and Christine Meunier},
  title={{Automatic Prediction of Speech Evaluation Metrics for Dysarthric Speech}},
  year=2017,
  booktitle={Proc. Interspeech 2017},
  pages={1834--1838},
  doi={10.21437/Interspeech.2017-1363}
}

@inproceedings{pappagari2020x,
  title={x-vectors meet emotions: A study on dependencies between emotion and speaker recognition},
  author={Pappagari, Raghavendra and Wang, Tianzi and Villalba, Jesus and Chen, Nanxin and Dehak, Najim},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7169--7173},
  year={2020},
  organization={IEEE}
}

@article{perero2019modeling,
  title={Modeling obstructive sleep apnea voices using deep neural network embeddings and domain-adversarial training},
  author={Perero-Codosero, Juan M and Espinoza-Cuadros, Fernando and Ant{\'o}n-Mart{\'\i}n, Javier and Barbero-Alvarez, Miguel A and Hern{\'a}ndez-G{\'o}mez, Luis A},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  volume={14},
  number={2},
  pages={240--250},
  year={2019},
  publisher={IEEE}
}

@article{zargarbashi2019multi,
  title={A multi-modal feature embedding approach to diagnose Alzheimer disease from spoken language},
  author={Zargarbashi, S and Babaali, Bagher},
  journal={arXiv preprint arXiv:1910.00330},
  year={2019}
}

@inproceedings{snyder2017deep,
  title={Deep neural network embeddings for text-independent speaker verification.},
  author={Snyder, David and Garcia-Romero, Daniel and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={Interspeech},
  volume={2017},
  pages={999--1003},
  year={2017}
}

@article{kenny2007joint,
  title={Joint factor analysis versus eigenchannels in speaker recognition},
  author={Kenny, Patrick and Boulianne, Gilles and Ouellet, Pierre and Dumouchel, Pierre},
  journal={IEEE Transactions on Audio, Speech, and Language Processing},
  volume={15},
  number={4},
  pages={1435--1447},
  year={2007},
  publisher={IEEE}
}
@article{reynolds2000speaker,
  title={Speaker verification using adapted Gaussian mixture models},
  author={Reynolds, Douglas A and Quatieri, Thomas F and Dunn, Robert B},
  journal={Digital signal processing},
  volume={10},
  number={1-3},
  pages={19--41},
  year={2000},
  publisher={Elsevier}
}

@article{dehak2010front,
  title={Front-end factor analysis for speaker verification},
  author={Dehak, Najim and Kenny, Patrick J and Dehak, R{\'e}da and Dumouchel, Pierre and Ouellet, Pierre},
  journal={IEEE Transactions on Audio, Speech, and Language Processing},
  volume={19},
  number={4},
  pages={788--798},
  year={2010},
  publisher={IEEE}
}

@article{hamalainen2014easr,
  title={{The EASR Corpora of European Portuguese, French, Hungarian and Polish Elderly Speech}},
  author={H{\"a}m{\"a}l{\"a}inen, Annika and Avelar, Jairo and Rodrigues, Silvia and Dias, J and Kolesinski, Artur and Fegy{\'o}, Tibor and N{\'e}meth, G{\'e}za and Csob{\'a}nka, Petra and Ting, K and Hewson, David},
  journal={The EASR Corpora of European Portuguese, French, Hungarian and Polish elderly speech},
  pages={1458--1464},
  year={2014},
  publisher={ELRA}
}

@article{pinto2016dysarthria,
  title={Dysarthria in individuals with Parkinson's disease: a protocol for a binational, cross-sectional, case-controlled study in French and European Portuguese (FraLusoPark)},
  author={Pinto, Serge and Cardoso, Rita and Sadat, Jasmin and Guimar{\~a}es, Isabel and Mercier, C{\'e}line and Santos, Helena and Atkinson-Clement, Cyril and Carvalho, Joana and Welby, Pauline and Oliveira, Pedro and others},
  journal={BMJ open},
  volume={6},
  number={11},
  pages={e012885},
  year={2016},
  publisher={British Medical Journal Publishing Group}
}

@inproceedings{orozco2014new,
  title={New Spanish speech corpus database for the analysis of people suffering from Parkinson's disease.},
  author={Orozco-Arroyave, Juan Rafael and Arias-Londo{\~n}o, Juli{\'a}n David and Vargas-Bonilla, Jes{\'u}s Francisco and Gonzalez-R{\'a}tiva, Mar{\'\i}a Claudia and N{\"o}th, Elmar},
  booktitle={LREC},
  pages={342--347},
  year={2014}
}
@inproceedings{pompili2017automatic,
  title={Automatic detection of parkinson’s disease: an experimental analysis of common speech production tasks used for diagnosis},
  author={Pompili, Anna and Abad, Alberto and Romano, Paolo and Martins, Isabel P and Cardoso, Rita and Santos, Helena and Carvalho, Joana and Guimaraes, Isabel and Ferreira, Joaquim J},
  booktitle={International Conference on Text, Speech, and Dialogue},
  pages={411--419},
  year={2017},
  organization={Springer}
}
@article{eyben2015geneva,
  title={The Geneva minimalistic acoustic parameter set (GeMAPS) for voice research and affective computing},
  author={Eyben, Florian and Scherer, Klaus R and Schuller, Bj{\"o}rn W and Sundberg, Johan and Andr{\'e}, Elisabeth and Busso, Carlos and Devillers, Laurence Y and Epps, Julien and Laukka, Petri and Narayanan, Shrikanth S and others},
  journal={IEEE transactions on affective computing},
  volume={7},
  number={2},
  pages={190--202},
  year={2015},
  publisher={IEEE}
}

@inproceedings{eyben2013recent,
  title={Recent developments in opensmile, the munich open-source multimedia feature extractor},
  author={Eyben, Florian and Weninger, Felix and Gross, Florian and Schuller, Bj{\"o}rn},
  booktitle={Proceedings of the 21st ACM international conference on Multimedia},
  pages={835--838},
  year={2013}
}

@article{konig2015automatic,
  title={Automatic speech analysis for the assessment of patients with predementia and Alzheimer's disease},
  author={K{\"o}nig, Alexandra and Satt, Aharon and Sorin, Alexander and Hoory, Ron and Toledo-Ronen, Orith and Derreumaux, Alexandre and Manera, Valeria and Verhey, Frans and Aalten, Pauline and Robert, Phillipe H and others},
  journal={Alzheimer's \& Dementia: Diagnosis, Assessment \& Disease Monitoring},
  volume={1},
  number={1},
  pages={112--124},
  year={2015},
  publisher={Elsevier}
}

@article{fraser2016linguistic,
  title={Linguistic features identify Alzheimer’s disease in narrative speech},
  author={Fraser, Kathleen C and Meltzer, Jed A and Rudzicz, Frank},
  journal={Journal of Alzheimer's Disease},
  volume={49},
  number={2},
  pages={407--422},
  year={2016},
  publisher={IOS Press}
}

@article{gosztolya2019identifying,
  title={Identifying mild cognitive impairment and mild Alzheimer’s disease based on spontaneous speech using ASR and linguistic features},
  author={Gosztolya, G{\'a}bor and Vincze, Veronika and T{\'o}th, L{\'a}szl{\'o} and P{\'a}k{\'a}ski, Magdolna and K{\'a}lm{\'a}n, J{\'a}nos and Hoffmann, Ildik{\'o}},
  journal={Computer Speech \& Language},
  volume={53},
  pages={181--197},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{warnita18_interspeech,
  author={Tifani Warnita and Nakamasa Inoue and Koichi Shinoda},
  title={{Detecting Alzheimer’s Disease Using Gated Convolutional Neural Network from Audio Data}},
  year=2018,
  booktitle={Proc. Interspeech 2018},
  pages={1706--1710},
  doi={10.21437/Interspeech.2018-1713}
}
@inproceedings{karlekar-etal-2018-detecting,
    title = "Detecting Linguistic Characteristics of {A}lzheimer{'}s Dementia by Interpreting Neural Models",
    author = "Karlekar, Sweta  and
      Niu, Tong  and
      Bansal, Mohit",
    editor = "Walker, Marilyn  and
      Ji, Heng  and
      Stent, Amanda",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-2110",
    doi = "10.18653/v1/N18-2110",
    pages = "701--707",
    abstract = "Alzheimer{'}s disease (AD) is an irreversible and progressive brain disease that can be stopped or slowed down with medical treatment. Language changes serve as a sign that a patient{'}s cognitive functions have been impacted, potentially leading to early diagnosis. In this work, we use NLP techniques to classify and analyze the linguistic characteristics of AD patients using the DementiaBank dataset. We apply three neural models based on CNNs, LSTM-RNNs, and their combination, to distinguish between language samples from AD and control patients. We achieve a new independent benchmark accuracy for the AD classification task. More importantly, we next interpret what these neural models have learned about the linguistic characteristics of AD patients, via analysis based on activation clustering and first-derivative saliency techniques. We then perform novel automatic pattern discovery inside activation clusters, and consolidate AD patients{'} distinctive grammar patterns. Additionally, we show that first derivative saliency can not only rediscover previous language patterns of AD patients, but also shed light on the limitations of neural models. Lastly, we also include analysis of gender-separated AD data.",
}
@book{goodglass2001bdae,
  title={BDAE: The Boston diagnostic aphasia examination},
  author={Goodglass, Harold and Kaplan, Edith and Weintraub, Sandra},
  year={2001},
  publisher={Lippincott Williams \& Wilkins Philadelphia, PA}
}


@inproceedings{luz2020alzheimer,
  title =        {{Alzheimer's} Dementia Recognition through Spontaneous
                  Speech: The {ADReSS Challenge}},
  author =       {Luz, Saturnino and Haider, Fasih and de la Fuente,
                  Sofia and Fromm, Davida and MacWhinney, Brian},
  booktitle =    {Proceedings of INTERSPEECH 2020},
  address =      {Shanghai, China},
  url={https://arxiv.org/abs/2004.06833},
  year =         {2020}
}

@inproceedings{nagrani17_interspeech,
  author={Arsha Nagrani and Joon Son Chung and Andrew Zisserman},
  title={{VoxCeleb: A Large-Scale Speaker Identification Dataset}},
  year=2017,
  booktitle={Proc. Interspeech 2017},
  pages={2616--2620},
  doi={10.21437/Interspeech.2017-950}
}

@article{schuller2020interspeech,
  title={{The INTERSPEECH 2020 Computational Paralinguistics Challenge: Elderly Emotion, Breathing \& Masks}},
  author={Schuller, Bj{\"o}rn W and Batliner, Anton and Bergler, Christian and Messner, Eva-Maria and Hamilton, Antonia and Amiriparian, Shahin and Baird, Alice and Rizos, Georgios and Schmitt, Maximilian and Stappen, Lukas and others},
  journal={Proceedings INTERSPEECH. Shanghai, China: ISCA},
  year={2020}
}

@inproceedings{schuller21_interspeech,
  author={Björn W. Schuller and Anton Batliner and Christian Bergler and Cecilia Mascolo and Jing Han and Iulia Lefter and Heysem Kaya and Shahin Amiriparian and Alice Baird and Lukas Stappen and Sandra Ottl and Maurice Gerczuk and Panagiotis Tzirakis and Chloë Brown and Jagmohan Chauhan and Andreas Grammenos and Apinan Hasthanasombat and Dimitris Spathis and Tong Xia and Pietro Cicuta and Leon J.M. Rothkrantz and Joeri A. Zwerts and Jelle Treep and Casper S. Kaandorp},
  title={{The INTERSPEECH 2021 Computational Paralinguistics Challenge: COVID-19 Cough, COVID-19 Speech, Escalation and Primates}},
  year=2021,
  booktitle={Proc. Interspeech 2021},
  pages={431--435},
  doi={10.21437/Interspeech.2021-19}
}

@article{pramono2016cough,
  title={A cough-based algorithm for automatic diagnosis of pertussis},
  author={Pramono, Renard Xaviero Adhi and Imtiaz, Syed Anas and Rodriguez-Villegas, Esther},
  journal={PloS one},
  volume={11},
  number={9},
  pages={e0162128},
  year={2016},
  publisher={Public Library of Science San Francisco, CA USA}
}
@inproceedings{Hershey2017,
author={S. {Hershey} and S. {Chaudhuri} and D. P. W. {Ellis} and J. F. {Gemmeke} and A. {Jansen} and R. C. {Moore} and M. {Plakal} and D. {Platt} and R. A. {Saurous} and B. {Seybold} and M. {Slaney} and R. J. {Weiss} and K. {Wilson}},
booktitle={{2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}},
title={{CNN architectures for large-scale audio classification}},
year={2017},
volume={},
number={},
pages={131-135},
}
@inproceedings{Chloe2020,
author = {Brown, Chlo\"{e} and Chauhan, Jagmohan and Grammenos, Andreas and Han, Jing and Hasthanasombat, Apinan and Spathis, Dimitris and Xia, Tong and Cicuta, Pietro and Mascolo, Cecilia},
title = {{Exploring Automatic Diagnosis of COVID-19 from Crowdsourced Respiratory Sound Data}},
year = {2020},
isbn = {9781450379984},
doi = {10.1145/3394486.3412865},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
pages = {3474–3484},
numpages = {11},
keywords = {covid-19, coughing, crowdsourcing platform, audio analysis, breathing},
address = {Virtual Event, CA, USA},
}

@article{Bagad2020,
title={{Cough Against COVID: Evidence of COVID-19 Signature in Cough Sounds}},
author={Piyush Bagad and Aman Dalmia and Jigar Doshi and Arsha Nagrani and Parag Bhamare and Amrita Mahale and Saurabh Rane and Neeraj Agarwal and Rahul Panicker},
year={2020},
journal = {preprint arXiv:2009.08790},
eprint={2009.08790},
archivePrefix={arXiv},
primaryClass={cs.SD},
}

@article{Imran2020,
title = {{AI4COVID-19: AI enabled preliminary diagnosis for COVID-19 from cough samples via an app}},
journal = {Informatics in Medicine Unlocked},
volume = {20},
pages = {100378},
year = {2020},
issn = {2352-9148},
author = {Ali Imran and Iryna Posokhova and Haneya N. Qureshi and Usama Masood and Muhammad Sajid Riaz and Kamran Ali and Charles N. John and MD Iftikhar Hussain and Muhammad Nabeel},
}

@article{Chaudhari2021,
title={{Virufy: Global Applicability of Crowdsourced and Clinical Datasets for AI Detection of COVID-19 from Cough}}, 
author={Gunvant Chaudhari and Xinyi Jiang and Ahmed Fakhry and Asriel Han and Jaclyn Xiao and Sabrina Shen and Amil Khanzada},
year={2021},
eprint={2011.13320},
archivePrefix={arXiv},
primaryClass={cs.SD},
journal = {preprint arXiv:2011.13320},
}

@inproceedings{Han2021,
  author={Han, Jing and Brown, Chloë and Chauhan, Jagmohan and Grammenos, Andreas and Hasthanasombat, Apinan and Spathis, Dimitris and Xia, Tong and Cicuta, Pietro and Mascolo, Cecilia},
  booktitle={2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={{Exploring Automatic COVID-19 Diagnosis via Voice and Symptoms from Crowdsourced Data}}, 
  year={2021},
  volume={},
  number={},
  pages={8328-8332},
  doi={10.1109/ICASSP39728.2021.9414576}
}

@article{Orlandic2020,
  title={The COUGHVID crowdsourcing dataset, a corpus for the study of large-scale cough analysis algorithms},
  author={Orlandic, Lara and Teijeiro, Tomas and Atienza, David},
  journal={Scientific Data},
  volume={8},
  number={1},
  pages={156},
  year={2021},
  publisher={Nature Publishing Group UK London}
}

@article{villalbaSRE182020,
author = {Jesús Villalba and Nanxin Chen and David Snyder and Daniel Garcia-Romero and Alan McCree and Gregory Sell and Jonas Borgstrom and Leibny Paola García-Perera and Fred Richardson and Réda Dehak and Pedro A. Torres-Carrasquillo and Najim Dehak},
title = {{State-of-the-art speaker recognition with neural network embeddings in NIST SRE18 and Speakers in the Wild evaluations}},
journal = {{Computer Speech \& Language}},
volume = {60},
pages = {101026},
year = {2020},
issn = {0885-2308},
}

@inproceedings{Simonyan2015,
author = {Karen Simonyan and Andrew Zisserman},
title = {{Very Deep Convolutional Networks for Large-Scale Image Recognition}},
booktitle = {{3rd International Conference on Learning Representations, ICLR 2015}},
address = {San Diego, CA, USA},
year = {2015},
}

@inproceedings{Pascual2019,
  author={Santiago Pascual and Mirco Ravanelli and Joan Serrà and Antonio Bonafonte and Yoshua Bengio},
  title={{Learning Problem-Agnostic Speech Representations from Multiple Self-Supervised Tasks}},
  year=2019,
  booktitle={Proceedings of Interspeech 2019},
  pages={161--165},
  address = {Graz, Austria}
}  %url={http://dx.doi.org/10.21437/Interspeech.2019-2605}

@inproceedings{Ravanelli2020,
  author={Ravanelli, Mirco and Zhong, Jianyuan and Pascual, Santiago and Swietojanski, Pawel and Monteiro, Joao and Trmal, Jan and Bengio, Yoshua},
  booktitle={{2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}}, 
  title={{Multi-Task Self-Supervised Learning for Robust Speech Recognition}}, 
  year={2020},
  volume={},
  number={},
  pages={6989-6993},
  doi={10.1109/ICASSP40776.2020.9053569}
}
@inproceedings{SoleraUrea2021TransferLC,
  title={Transfer Learning-Based Cough Representations for Automatic Detection of COVID-19},
  author={Rub{\'e}n Solera-Ure{\~n}a and Catarina Botelho and Francisco Teixeira and Thomas Rolland and Alberto Abad and Isabel Trancoso},
  booktitle={Interspeech},
  year={2021},
  url={https://api.semanticscholar.org/CorpusID:237489901}
}

@inproceedings{casanova2022asr,
  author={Edresson Casanova and Christopher Shulby and Alexander Korolev and Arnaldo Candido Junior and Anderson da Silva Soares and Sandra Aluísio and Moacir Antonelli Ponti},
  title={{ASR data augmentation in low-resource settings using cross-lingual multi-speaker TTS and cross-lingual voice conversion}},
  year=2023,
  booktitle={Proc. INTERSPEECH 2023},
  pages={1244--1248},
  doi={10.21437/Interspeech.2023-496}
}
@INPROCEEDINGS{9688218,
  author={Ueno, Sei and Mimura, Masato and Sakai, Shinsuke and Kawahara, Tatsuya},
  booktitle={2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)}, 
  title={Data Augmentation for ASR Using TTS Via a Discrete Representation}, 
  year={2021},
  volume={},
  number={},
  pages={68-75},
  doi={10.1109/ASRU51503.2021.9688218}}


@inproceedings{fazel21_interspeech,
  author={Amin Fazel and Wei Yang and Yulan Liu and Roberto Barra-Chicote and Yixiong Meng and Roland Maas and Jasha Droppo},
  title={{SynthASR: Unlocking Synthetic Data for Speech Recognition}},
  year=2021,
  booktitle={Proc. Interspeech 2021},
  pages={896--900},
  doi={10.21437/Interspeech.2021-1882}
}


@InProceedings{casanova2022yourtts,
  title = 	 {{Y}our{TTS}: Towards Zero-Shot Multi-Speaker {TTS} and Zero-Shot Voice Conversion for Everyone},
  author =       {Casanova, Edresson and Weber, Julian and Shulby, Christopher D and Junior, Arnaldo Candido and G{\"o}lge, Eren and Ponti, Moacir A},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {2709--2720},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/casanova22a/casanova22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/casanova22a.html},
  abstract = 	 {YourTTS brings the power of a multilingual approach to the task of zero-shot multi-speaker TTS. Our method builds upon the VITS model and adds several novel modifications for zero-shot multi-speaker and multilingual training. We achieved state-of-the-art (SOTA) results in zero-shot multi-speaker TTS and results comparable to SOTA in zero-shot voice conversion on the VCTK dataset. Additionally, our approach achieves promising results in a target language with a single-speaker dataset, opening possibilities for zero-shot multi-speaker TTS and zero-shot voice conversion systems in low-resource languages. Finally, it is possible to fine-tune the YourTTS model with less than 1 minute of speech and achieve state-of-the-art results in voice similarity and with reasonable quality. This is important to allow synthesis for speakers with a very different voice or recording characteristics from those seen during training.}
}

@inproceedings{45819,
  author       = {Laurent Dinh and
                  Jascha Sohl{-}Dickstein and
                  Samy Bengio},
  title        = {Density estimation using Real {NVP}},
  booktitle    = {5th International Conference on Learning Representations, {ICLR} 2017,
                  Toulon, France, April 24-26, 2017, Conference Track Proceedings},
  publisher    = {OpenReview.net},
  year         = {2017},
  url          = {https://openreview.net/forum?id=HkpbnH9lx},
  timestamp    = {Thu, 25 Jul 2019 14:25:58 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/DinhSB17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{45774,
  author={Aäron {van den Oord} and Sander Dieleman and Heiga Zen and Karen Simonyan and Oriol Vinyals and Alex Graves and Nal Kalchbrenner and Andrew Senior and Koray Kavukcuoglu},
  title={{WaveNet: A Generative Model for Raw Audio}},
  year=2016,
  booktitle={Proc. 9th ISCA Workshop on Speech Synthesis Workshop (SSW 9)},
  pages={125}
}

@article{heo2020clova,
  title={{Clova baseline system for the voxceleb speaker recognition challenge 2020}},
  author={Heo, Hee Soo and Lee, Bong-Jin and Huh, Jaesung and Chung, Joon Son},
  journal={arXiv preprint arXiv:2009.14153},
  year={2020}
}

@article{kong2020hifi,
  title={Hifi-gan: Generative adversarial networks for efficient and high fidelity speech synthesis},
  author={Kong, Jungil and Kim, Jaehyeon and Bae, Jaekyoung},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={17022--17033},
  year={2020}
}


@misc{veaux2016superseded,
  author = {{Christophe Veaux and Junichi Yamagishi and Kirsten MacDonald }},
  year = {2016},
  title = {{SUPERSEDED - CSTR VCTK Corpus: English Multi-speaker Corpus for CSTR Voice Cloning Toolkit}},
  note = {Accessed Febuary 08, 2024.  \url{https://datashare.ed.ac.uk/handle/10283/2119}}
}


@article{casanova2022tts,
  title={TTS-Portuguese Corpus: a corpus for speech synthesis in Brazilian Portuguese},
  author={Casanova, Edresson and Junior, Arnaldo Candido and Shulby, Christopher and Oliveira, Frederico Santos de and Teixeira, Jo{\~a}o Paulo and Ponti, Moacir Antonelli and Alu{\'\i}sio, Sandra},
  journal={Language Resources and Evaluation},
  volume={56},
  number={3},
  pages={1043--1055},
  year={2022},
  publisher={Springer}
}

@misc{mailabs,
  author = {{Munich Artificial Intelligence Laboratories GmbH}},
  year = {2017},
  title = {The mailabs speech dataset – caito},
  note = {Accessed January 15, 2024.  \url{https://www.caito.de/2019/01/03/the-m-ailabs-speech-dataset/}}
}

@inproceedings{zeyer2019comparison,
  title={A comparison of transformer and lstm encoder decoder models for asr},
  author={Zeyer, Albert and Bahar, Parnia and Irie, Kazuki and Schl{\"u}ter, Ralf and Ney, Hermann},
  booktitle={2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={8--15},
  year={2019},
  organization={IEEE}
}

@inproceedings{zeineldeen2022conformer,
  title={Conformer-based hybrid ASR system for switchboard dataset},
  author={Zeineldeen, Mohammad and Xu, Jingjing and L{\"u}scher, Christoph and Michel, Wilfried and Gerstenberger, Alexander and Schl{\"u}ter, Ralf and Ney, Hermann},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7437--7441},
  year={2022},
  organization={IEEE}
}

@inproceedings{chang2022distilhubert,
  title={Distilhubert: Speech representation learning by layer-wise distillation of hidden-unit bert},
  author={Chang, Heng-Jui and Yang, Shu-wen and Lee, Hung-yi},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7087--7091},
  year={2022},
  organization={IEEE}
}

@article{liu2021tera,
  title={Tera: Self-supervised learning of transformer encoder representation for speech},
  author={Liu, Andy T and Li, Shang-Wen and Lee, Hung-yi},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={29},
  pages={2351--2366},
  year={2021},
  publisher={IEEE}
}

@article{mockingjay,
   title={Mockingjay: Unsupervised Speech Representation Learning with Deep Bidirectional Transformer Encoders},
   ISBN={9781509066315},
   url={http://dx.doi.org/10.1109/ICASSP40776.2020.9054458},
   DOI={10.1109/icassp40776.2020.9054458},
   journal={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
   publisher={IEEE},
   author={Liu, Andy T. and Yang, Shu-wen and Chi, Po-Han and Hsu, Po-chun and Lee, Hung-yi},
   year={2020},
   month={May}
}

@inproceedings{chung19_interspeech,
  author={Yu-An Chung and Wei-Ning Hsu and Hao Tang and James Glass},
  title={{An Unsupervised Autoregressive Model for Speech Representation Learning}},
  year=2019,
  booktitle={Proc. Interspeech 2019},
  pages={146--150},
  doi={10.21437/Interspeech.2019-1473}
}

@inproceedings{liu21l_interspeech,
  author={Alexander H. Liu and Yu-An Chung and James Glass},
  title={{Non-Autoregressive Predictive Coding for Learning Speech Representations from Local Dependencies}},
  year=2021,
  booktitle={Proc. Interspeech 2021},
  pages={3730--3734},
  doi={10.21437/Interspeech.2021-349}
}

@inproceedings{chi2021audio,
  title={Audio albert: A lite bert for self-supervised learning of audio representation},
  author={Chi, Po-Han and Chung, Pei-Hung and Wu, Tsung-Han and Hsieh, Chun-Cheng and Chen, Yen-Hao and Li, Shang-Wen and Lee, Hung-yi},
  booktitle={2021 IEEE Spoken Language Technology Workshop (SLT)},
  pages={344--350},
  year={2021},
  organization={IEEE}
}


@inproceedings{Prajit2017Searching,
  author       = {Prajit Ramachandran and
                  Barret Zoph and
                  Quoc V. Le},
  title        = {Searching for Activation Functions},
  booktitle    = {6th International Conference on Learning Representations, {ICLR} 2018,
                  Vancouver, BC, Canada, April 30 - May 3, 2018, Workshop Track Proceedings},
  publisher    = {OpenReview.net},
  year         = {2018},
  url          = {https://openreview.net/forum?id=Hkuq2EkPf},
  timestamp    = {Thu, 04 Apr 2019 13:20:09 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/RamachandranZL18.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{
hu2022lora,
title={Lo{RA}: Low-Rank Adaptation of Large Language Models},
author={Edward J Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=nZeVKeeFYf9}
}

@inproceedings{li-liang-2021-prefix,
    title = "Prefix-Tuning: Optimizing Continuous Prompts for Generation",
    author = "Li, Xiang Lisa  and
      Liang, Percy",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.353",
    doi = "10.18653/v1/2021.acl-long.353",
    pages = "4582--4597",
    abstract = "Fine-tuning is the de facto way of leveraging large pretrained language models for downstream tasks. However, fine-tuning modifies all the language model parameters and therefore necessitates storing a full copy for each task. In this paper, we propose prefix-tuning, a lightweight alternative to fine-tuning for natural language generation tasks, which keeps language model parameters frozen and instead optimizes a sequence of continuous task-specific vectors, which we call the prefix. Prefix-tuning draws inspiration from prompting for language models, allowing subsequent tokens to attend to this prefix as if it were {``}virtual tokens{''}. We apply prefix-tuning to GPT-2 for table-to-text generation and to BART for summarization. We show that by learning only 0.1{\%} of the parameters, prefix-tuning obtains comparable performance in the full data setting, outperforms fine-tuning in low-data settings, and extrapolates better to examples with topics that are unseen during training.",
}

@inproceedings{lester-etal-2021-power,
    title = "The Power of Scale for Parameter-Efficient Prompt Tuning",
    author = "Lester, Brian  and
      Al-Rfou, Rami  and
      Constant, Noah",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.243",
    doi = "10.18653/v1/2021.emnlp-main.243",
    pages = "3045--3059",
    abstract = "In this work, we explore {``}prompt tuning,{''} a simple yet effective mechanism for learning {``}soft prompts{''} to condition frozen language models to perform specific downstream tasks. Unlike the discrete text prompts used by GPT-3, soft prompts are learned through backpropagation and can be tuned to incorporate signals from any number of labeled examples. Our end-to-end learned approach outperforms GPT-3{'}s few-shot learning by a large margin. More remarkably, through ablations on model size using T5, we show that prompt tuning becomes more competitive with scale: as models exceed billions of parameters, our method {``}closes the gap{''} and matches the strong performance of model tuning (where all model weights are tuned). This finding is especially relevant because large models are costly to share and serve and the ability to reuse one frozen model for multiple downstream tasks can ease this burden. Our method can be seen as a simplification of the recently proposed {``}prefix tuning{''} of Li and Liang (2021) and we provide a comparison to this and other similar approaches. Finally, we show that conditioning a frozen model with soft prompts confers benefits in robustness to domain transfer and enables efficient {``}prompt ensembling.{''} We release code and model checkpoints to reproduce our experiments.",
}

@inproceedings{vqwav2vec,
  author       = {Alexei Baevski and
                  Steffen Schneider and
                  Michael Auli},
  title        = {vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations},
  booktitle    = {8th International Conference on Learning Representations, {ICLR} 2020,
                  Addis Ababa, Ethiopia, April 26-30, 2020},
  publisher    = {OpenReview.net},
  year         = {2020},
  url          = {https://openreview.net/forum?id=rylwJxrYDS},
  timestamp    = {Thu, 24 Mar 2022 16:25:27 +0100},
  biburl       = {https://dblp.org/rec/conf/iclr/BaevskiSA20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{desplanques20_interspeech,
  author={Brecht Desplanques and Jenthe Thienpondt and Kris Demuynck},
  title={{ECAPA-TDNN: Emphasized Channel Attention, Propagation and Aggregation in TDNN Based Speaker Verification}},
  year=2020,
  booktitle={Proc. Interspeech 2020},
  pages={3830--3834},
  doi={10.21437/Interspeech.2020-2650}
}

@INPROCEEDINGS{9879745,
  author={Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
  booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={A ConvNet for the 2020s}, 
  year={2022},
  volume={},
  number={},
  pages={11966-11976},
  keywords={Computer vision;Image segmentation;Visualization;Computational modeling;Scalability;Semantics;Transformers;Deep learning architectures and techniques; Recognition: detection;categorization;retrieval; Representation learning},
  doi={10.1109/CVPR52688.2022.01167}}


@inproceedings{mirheidari2018detecting,
  title={Detecting Signs of Dementia Using Word Vector Representations.},
  author={Mirheidari, Bahman and Blackburn, Daniel and Walker, Traci and Venneri, Annalena and Reuber, Markus and Christensen, Heidi},
  booktitle={Interspeech},
  pages={1893--1897},
  year={2018}
}

@article{virkkunen2023finnish,
  title={Finnish parliament ASR corpus: Analysis, benchmarks and statistics},
  author={Virkkunen, Anja and Rouhe, Aku and Phan, Nhan and Kurimo, Mikko},
  journal={Language Resources and Evaluation},
  pages={1--26},
  year={2023},
  publisher={Springer}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{chen2023exploring,
  title={Exploring efficient-tuning methods in self-supervised speech models},
  author={Chen, Zih-Ching and Fu, Chin-Lun and Liu, Chih-Ying and Li, Shang-Wen Daniel and Lee, Hung-yi},
  booktitle={2022 IEEE Spoken Language Technology Workshop (SLT)},
  pages={1120--1127},
  year={2023},
  organization={IEEE}
}

@inproceedings{ng23c_interspeech2,
  author={Dianwen Ng and Chong Zhang and Ruixi Zhang and Yukun Ma and Trung Hieu Nguyen and Chongjia Ni and Shengkui Zhao and Qian Chen and Wen Wang and Eng Siong Chng and Bin Ma},
  title={{Adapter-tuning with Effective Token-dependent Representation Shift for Automatic Speech Recognition}},
  year=2023,
  booktitle={Proc. INTERSPEECH 2023},
  pages={1319--1323},
  doi={10.21437/Interspeech.2023-1221}
}

@inproceedings{hsieh23_interspeech,
  author={Cheng-Ping Hsieh and Subhankar Ghosh and Boris Ginsburg},
  title={{Adapter-Based Extension of Multi-Speaker Text-To-Speech Model for New Speakers}},
  year=2023,
  booktitle={Proc. INTERSPEECH 2023},
  pages={3028--3032},
  doi={10.21437/Interspeech.2023-2313}
}

@article{gong2022layer,
  title={Layer-wise fast adaptation for end-to-end multi-accent speech recognition},
  author={Qian, Yanmin and Gong, Xun and Huang, Houjun},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={30},
  pages={2842--2853},
  year={2022},
  publisher={IEEE}
}
@inproceedings{lee97b_eurospeech,
  author={Sungbok Lee and Alexandros Potamianos and Shrikanth Narayanan},
  title={{Analysis of children's speech: duration, pitch and formants}},
  year=1997,
  booktitle={Proc. 5th European Conference on Speech Communication and Technology (Eurospeech 1997)},
  pages={473--476},
  doi={10.21437/Eurospeech.1997-161}
}

@misc{SCTK_nist,
  author = {{National Institute of Standards and technology}},
  year = {2021},
  title = {{SCTK, the NIST Scoring Toolkit}},
  note = {Accessed Febuary 11th, 2024.  \url{https://www.yale.edu/about-yale/yale-facts}}
}