@inproceedings{reviewASRchildren,
author = {Gerosa, Matteo and Giuliani, Diego and Narayanan, Shrikanth and Potamianos, Alexandros},
title = {A Review of ASR Technologies for Children's Speech},
year = {2009},
isbn = {9781605586908},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1640377.1640384},
doi = {10.1145/1640377.1640384},
abstract = {In this paper, we review: (1) the acoustic and linguistic properties of children's
speech for both read and spontaneous speech, and (2) the developments in automatic
speech recognition for children with application to spoken dialogue and multimodal
dialogue system design. First, the effect of developmental changes on the absolute
values and variability of acoustic correlates is presented for read speech for children
ages 6 and up. Then, verbal child-machine spontaneous interaction is reviewed and
results from recent studies are presented. Age trends of acoustic, linguistic and
interaction parameters are discussed, such as sentence duration, filled pauses, politeness
and frustration markers, and modality usage. Some differences between child-machine
and human-human interaction are pointed out. The implications for acoustic modeling,
linguistic modeling and spoken dialogue system design for children are presented.
We conclude with a review of relevant applications of spoken dialogue technologies
for children.},
booktitle = {Proceedings of the 2nd Workshop on Child, Computer and Interaction},
articleno = {7},
numpages = {8},
keywords = {children's speech analysis, spoken dialogue, children's speech recognition},
location = {Cambridge, Massachusetts},
series = {WOCCI '09}
}

@article{Acoustic_change_children,
author = {Lee,Sungbok  and Potamianos,Alexandros  and Narayanan,Shrikanth },
title = {Acoustics of children’s speech: Developmental changes of temporal and spectral parameters},
journal = {The Journal of the Acoustical Society of America},
volume = {105},
number = {3},
pages = {1455-1468},
year = {1999},
doi = {10.1121/1.426686},

URL = { 
        https://doi.org/10.1121/1.426686
    
},
eprint = { 
        https://doi.org/10.1121/1.426686
    
}

}

@ARTICLE{childrenSpeechWorse, 
author={A. Potamianos and S. Narayanan}, 
journal={IEEE Transactions on Speech and Audio Processing}, 
title={Robust recognition of children's speech}, 
year={2003}, 
volume={11}, 
number={6}, 
pages={603-616}, 
keywords={error analysis;speech recognition;piecewise linear techniques;spectral analysis;children speech recognition;age-dependent spectral variability;age-dependent temporal variability;age-related acoustic characteristics;automatic speech recognition;frequency scaling;spectral envelope parameters;acoustic models;word error rate;speaker normalization algorithm;frequency warping;piecewise linear algorithm;phoneme-dependent algorithm;formant scaling;vocal tract normalization;Robustness;Speech recognition;Automatic speech recognition;Frequency;Speech analysis;Acoustic testing;Error analysis;Loudspeakers;Degradation;Piecewise linear techniques}, 
doi={10.1109/TSA.2003.818026}, 
ISSN={1063-6676}, 
}
@article{MyST,
  title={My Science Tutor: A Conversational Multimedia Virtual Tutor.},
  author={W. Ward and R. Cole and Daniel Bola{\~n}os and Cindy Buchenroth-Martin and Edward Svirsky and Timothy B. Weston},
  journal={Journal of Educational Psychology},
  year={2013},
  volume={105},
  pages={1115-1125}
}
@INPROCEEDINGS{librispeech,
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={ICASSP}, 
  title={Librispeech: An ASR corpus based on public domain audio books}, 
  year={2015},
  volume={},
  number={},
  pages={5206-5210},
  doi={10.1109/ICASSP.2015.7178964}}


@inproceedings{singakids,
  title={SingaKids-Mandarin: Speech Corpus of Singaporean Children Speaking Mandarin Chinese.},
  author={Chen, Nancy F and Tong, Rong and Wee, Darren and Lee, Pei Xuan and Ma, Bin and Li, Haizhou},
  booktitle={Interspeech},
  pages={1545--1549},
  year={2016}
}


@inproceedings{cslu,
  title={The OGI kids’ speech corpus and recognizers},
  author={Shobaki, Khaldoun and Hosom, John-Paul and Cole, Ronald},
  booktitle={Proc. of ICSLP},
  pages={564--567},
  year={2000}
}

@MISC{pf-star-british,
    author = {Martin Russell},
    title = {The PF-STAR British English Children’s Speech Corpus},
    year = {2006}
}
@article{cmu,
  title={The CMU kids speech corpus},
  author={Eskenazi, Maxine and Mostow, Jack and Graff, David},
  journal={Corpus of children's read speech digitized and transcribed on two CD-ROMs, with assistance from Multicom Research and David Graff. Published by the Linguistic Data Consortium, University of Pennsylvania},
  year={1997}
}

@article{segmental_duration,
author = {Knutsen,Sten  and Stromswold,Karin  and Kleinschmidt,Dave F. },
title = {Segmental duration as a cue to sentence structure},
journal = {The Journal of the Acoustical Society of America},
volume = {145},
number = {3},
pages = {1910-1910},
year = {2019},
doi = {10.1121/1.5101929},

URL = { 
        https://doi.org/10.1121/1.5101929
    
},
eprint = { 
        https://doi.org/10.1121/1.5101929
    
}

}


@article{first_vowel_study,
author = {Peterson,Gordon E.  and Barney,Harold L. },
title = {Control Methods Used in a Study of the Vowels},
journal = {The Journal of the Acoustical Society of America},
volume = {24},
number = {2},
pages = {175-184},
year = {1952},
doi = {10.1121/1.1906875},

URL = { 
        https://doi.org/10.1121/1.1906875
    
},
eprint = { 
        https://doi.org/10.1121/1.1906875
    
}

}
@inproceedings{asr-google,
title	= {Large Vocabulary Automatic Speech Recognition for Children},
author	= {Hank Liao and Golan Pundak and Olivier Siohan and Melissa Carroll and Noah Coccaro and Qi-Ming Jiang and Tara N. Sainath and Andrew Senior and Françoise Beaufays and Michiel Bacchiani},
year	= {2015},
booktitle	= {Interspeech}
}
@inproceedings{why_children_speech_no_working,
  author={Qun Li and Martin J. Russell},
  title={{Why is automatic recognition of children's speech difficult?}},
  year=2001,
  booktitle={Proc. 7th European Conference on Speech Communication and Technology (Eurospeech 2001)},
  pages={2671--2674}
}
@article{segment_definition,
author = {DAVID CRYSTAL},
year = {2004},
month = {01},
pages = {100 - 101},
title = {A Dictionary of Linguistics and Phonetics (5th edn.). Oxford: Blackwell Publishing, 2003. Pp. 508. ISBN 0 631 22664 8},
volume = {34},
journal = {Journal of the International Phonetic Association},
doi = {10.1017/S0025100304231681}
}

@article{Children_language_model,
  title={Improvements in children's speech recognition performance},
  author={SubrataKumar Das and Don Nix and Michael Picheny},
  journal={Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP '98 (Cat. No.98CH36181)},
  year={1998},
  volume={1},
  pages={433-436 vol.1}
}
@inproceedings{children_language_model2,
  title={Child automatic speech recognition for US English: child interaction with living-room-electronic-devices},
  author={Sharmistha S. Gray and Daniel Willett and Jianhua Lu and Joel Pinto and Paul Maergner and Nathan Bodenstab},
  booktitle={WOCCI},
  year={2014}
}


@inproceedings{language_children,
  title={Acoustic and language modeling for children's read speech assessment},
  author={Tulsiani, Hitesh and Swarup, Prakhar and Rao, Preeti},
  booktitle={2017 Twenty-third National Conference on Communications (NCC)},
  pages={1--6},
  year={2017},
  organization={IEEE}
}


@inproceedings{language_children2,
author = {Potamianos, Alexandros and Narayanan, Shrikanth},
year = {1998},
month = {06},
pages = {197 - 200 vol.1},
title = {Spoken dialog systems for children},
volume = {1},
isbn = {0-7803-4428-6},
booktitle={ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
doi = {10.1109/ICASSP.1998.674401}
}


@inproceedings{darpa1992,
  title={The HTK tied-state continuous speech recogniser.},
  author={Woodland, Philip C and Young, Steve J},
  booktitle={Eurospeech},
  year={1993}
}

@article{htk_book,
  title={The HTK book},
  author={Young, Steve and Evermann, Gunnar and Gales, Mark and Hain, Thomas and Kershaw, Dan and Liu, Xunying and Moore, Gareth and Odell, Julian and Ollason, Dave and Povey, Dan and others},
  journal={Cambridge university engineering department},
  volume={3},
  number={175},
  pages={12},
  year={2002}
}


@ARTICLE{hmm-dnn,
  author={Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George E. and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Sainath, Tara N. and Kingsbury, Brian},
  journal={IEEE Signal Processing Magazine}, 
  title={Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups}, 
  year={2012},
  volume={29},
  number={6},
  pages={82-97},
  doi={10.1109/MSP.2012.2205597}}
  
  
 @article{first_asr,
author = {Davis,K. H.  and Biddulph,R.  and Balashek,S. },
title = {Automatic Recognition of Spoken Digits},
journal = {The Journal of the Acoustical Society of America},
volume = {24},
number = {6},
pages = {637-642},
year = {1952},
doi = {10.1121/1.1906946},

URL = { 
        https://doi.org/10.1121/1.1906946
    
},
eprint = { 
        https://doi.org/10.1121/1.1906946
    
}

}
@ARTICLE{mfcc,
  author={Davis, S. and Mermelstein, P.},
  journal={IEEE Transactions on Acoustics, Speech, and Signal Processing}, 
  title={Comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences}, 
  year={1980},
  volume={28},
  number={4},
  pages={357-366},
  doi={10.1109/TASSP.1980.1163420}}
@ARTICLE{Dragon_system,
  author={Baker, J.},
  journal={IEEE Transactions on Acoustics, Speech, and Signal Processing}, 
  title={The DRAGON system--An overview}, 
  year={1975},
  volume={23},
  number={1},
  pages={24-29},
  doi={10.1109/TASSP.1975.1162650}}
@article{g2p,
  title={Sequence-to-sequence neural net models for grapheme-to-phoneme conversion},
  author={Yao, Kaisheng and Zweig, Geoffrey},
  journal={arXiv preprint arXiv:1506.00196},
  year={2015}
}

@article{n-grams-computational_biology,
author = {Vishnoi, Shubham and Garg, Prabha and Arora, Pooja},
title = {Physicochemical n-Grams Tool: A tool for protein physicochemical descriptor generation via Chou’s 5-step rule},
journal = {Chemical Biology \& Drug Design},
volume = {95},
number = {1},
pages = {79-86},
keywords = {descriptor generation, machine learning, n-Grams, physicochemical parameter, proteomics science},
doi = {https://doi.org/10.1111/cbdd.13617},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cbdd.13617},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cbdd.13617},
abstract = {Abstract Physicochemical n-Grams Tool (PnGT) is an open-source standalone software for calculating physicochemical descriptors of protein. PnGT was developed using the Python scripting language and developed the user interface using Tkinter. The software currently calculates 33 physicochemical descriptors along with the sequence length for the given protein primary sequence. The descriptor generated by this tool can be directly utilized as the feature vector for the development of proteomics statistical or machine learning predictive model.},
year = {2020}
}

@article{n-gram-compression,
	title = {n-{Gram}-{Based} {Text} {Compression}},
	volume = {2016},
	issn = {1687-5265},
	url = {https://doi.org/10.1155/2016/9483646},
	doi = {10.1155/2016/9483646},
	abstract = {We propose an efficient method for compressing Vietnamese text using{\textless}italic{\textgreater} n{\textless}/italic{\textgreater}-gram dictionaries. It has a significant compression ratio in comparison with those of state-of-the-art methods on the same dataset. Given a text, first, the proposed method splits it into{\textless}italic{\textgreater} n{\textless}/italic{\textgreater}-grams and then encodes them based on{\textless}italic{\textgreater} n{\textless}/italic{\textgreater}-gram dictionaries. In the encoding phase, we use a sliding window with a size that ranges from bigram to five grams to obtain the best encoding stream. Each{\textless}italic{\textgreater} n{\textless}/italic{\textgreater}-gram is encoded by two to four bytes accordingly based on its corresponding{\textless}italic{\textgreater} n{\textless}/italic{\textgreater}-gram dictionary. We collected 2.5\&\#x2009;GB text corpus from some Vietnamese news agencies to build{\textless}italic{\textgreater} n{\textless}/italic{\textgreater}-gram dictionaries from unigram to five grams and achieve dictionaries with a size of 12\&\#x2009;GB in total. In order to evaluate our method, we collected a testing set of 10 different text files with different sizes. The experimental results indicate that our method achieves compression ratio around 90\&\#x25; and outperforms state-of-the-art methods.},
	journal = {Computational Intelligence and Neuroscience},
	author = {Nguyen, Vu H. and Nguyen, Hien T. and Duong, Hieu N. and Snasel, Vaclav},
	editor = {Jo, Geun S.},
	month = nov,
	year = {2016},
	note = {Publisher: Hindawi Publishing Corporation},
	pages = {9483646},
}
@article{n-grams-NLP,
  title={Syntactic n-grams as machine learning features for natural language processing},
  author={Sidorov, Grigori and Velasquez, Francisco and Stamatatos, Efstathios and Gelbukh, Alexander and Chanona-Hern{\'a}ndez, Liliana},
  journal={Expert Systems with Applications},
  volume={41},
  number={3},
  pages={853--860},
  year={2014},
  publisher={Elsevier}
}

@misc{transformer,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2017},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{Bert,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{First_End2End,
author = {Graves, Alex and Fern\'{a}ndez, Santiago and Gomez, Faustino and Schmidhuber, J\"{u}rgen},
title = {Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks},
year = {2006},
isbn = {1595933832},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1143844.1143891},
doi = {10.1145/1143844.1143891},
abstract = {Many real-world sequence learning tasks require the prediction of sequences of labels
from noisy, unsegmented input data. In speech recognition, for example, an acoustic
signal is transcribed into words or sub-word units. Recurrent neural networks (RNNs)
are powerful sequence learners that would seem well suited to such tasks. However,
because they require pre-segmented training data, and post-processing to transform
their outputs into label sequences, their applicability has so far been limited. This
paper presents a novel method for training RNNs to label unsegmented sequences directly,
thereby solving both problems. An experiment on the TIMIT speech corpus demonstrates
its advantages over both a baseline HMM and a hybrid HMM-RNN.},
booktitle = {Proceedings of the 23rd International Conference on Machine Learning},
pages = {369–376},
numpages = {8},
location = {Pittsburgh, Pennsylvania, USA},
series = {ICML '06}
}
@ARTICLE{n-grams-smoothing,
  author={Chen, S.F. and Rosenfeld, R.},
  journal={IEEE Transactions on Speech and Audio Processing}, 
  title={A survey of smoothing techniques for ME models}, 
  year={2000},
  volume={8},
  number={1},
  pages={37-50},
  doi={10.1109/89.817452}}
  
  
  @ARTICLE{tfbased,
  author={Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Representation Learning: A Review and New Perspectives}, 
  year={2013},
  volume={35},
  number={8},
  pages={1798-1828},
  doi={10.1109/TPAMI.2013.50}}

@INPROCEEDINGS{tfpathology,
  author={Takashima, Ryoichi and Takiguchi, Tetsuya and Ariki, Yasuo},
  booktitle={ICASSP}, 
  title={Two-Step Acoustic Model Adaptation for Dysarthric Speech Recognition}, 
  year={2020},
  volume={},
  number={},
  pages={6104-6108},
  doi={10.1109/ICASSP40776.2020.9053725}}

@INPROCEEDINGS{tfcharacter,
  author={Cireşan, Dan C. and Meier, Ueli and Schmidhuber, Jürgen},
  booktitle={The 2012 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Transfer learning for Latin and Chinese characters with Deep Neural Networks}, 
  year={2012},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/IJCNN.2012.6252544}}
  
  
@article{TransferLF,
  title={Transfer learning for children's speech recognition},
  author={R. Tong and Lei Wang and B. Ma},
  journal={2017 International Conference on Asian Language Processing (IALP)},
  year={2017},
  pages={36-39}
}


@misc{TFchildren,
      title={Transfer Learning from Adult to Children for Speech Recognition: Evaluation, Analysis and Recommendations}, 
      author={Prashanth Gurunath Shivakumar and Panayiotis Georgiou},
      year={2018},
      eprint={1805.03322},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}

@misc{yosinski2014transferable,
      title={How transferable are features in deep neural networks?}, 
      author={Jason Yosinski and Jeff Clune and Yoshua Bengio and Hod Lipson},
      year={2014},
      eprint={1411.1792},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@ARTICLE{viterbi_decoder,
  author={Viterbi, A.},
  journal={IEEE Transactions on Information Theory}, 
  title={Error bounds for convolutional codes and an asymptotically optimum decoding algorithm}, 
  year={1967},
  volume={13},
  number={2},
  pages={260-269},
  doi={10.1109/TIT.1967.1054010}}
  
  @article{Hermansky1990PerceptualLP,
  title={Perceptual linear predictive (PLP) analysis of speech.},
  author={Hynek Hermansky},
  journal={The Journal of the Acoustical Society of America},
  year={1990},
  volume={87 4},
  pages={
          1738-52
        }
}

@inproceedings{VTLN,
  title={Speaker normalization using efficient frequency warping procedures},
  author={Lee, Li and Rose, Richard C},
  booktitle={1996 IEEE International Conference on Acoustics, Speech, and Signal Processing Conference Proceedings},
  volume={1},
  pages={353--356},
  year={1996},
  organization={IEEE}
}

@INPROCEEDINGS{feat_ext_from_raw,  author={Dubagunta, S. Pavankumar and Hande Kabil, Selen and Magimai.-Doss, Mathew},  booktitle={ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},   title={Improving Children Speech Recognition through Feature Learning from Raw Speech Signal},   year={2019},  volume={},  number={},  pages={5736-5740},  doi={10.1109/ICASSP.2019.8682826}}

@INPROCEEDINGS{sincnet_adapt,  author={Fainberg, Joachim and Klejch, Ondřej and Loweimi, Erfan and Bell, Peter and Renals, Steve},  booktitle={2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},   title={Acoustic Model Adaptation from Raw Waveforms with Sincnet},   year={2019},  volume={},  number={},  pages={897-904},  doi={10.1109/ASRU46091.2019.9003974}}

@misc{Sincnet,
      title={Speaker Recognition from Raw Waveform with SincNet}, 
      author={Mirco Ravanelli and Yoshua Bengio},
      year={2019},
      eprint={1808.00158},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}

@INPROCEEDINGS{ivector,
  author={Senior, Andrew and Lopez-Moreno, Ignacio},
  booktitle={ICASSP}, 
  title={Improving DNN speaker independence with I-vector inputs}, 
  year={2014},
  volume={},
  number={},
  pages={225-229},
  doi={10.1109/ICASSP.2014.6853591}}
  
  
  @INPROCEEDINGS{adversarial-adapt1,
  author={Duan, Richeng and Chen, Nancy F.},
  booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Senone-Aware Adversarial Multi-Task Training for Unsupervised Child to Adult Speech Adaptation}, 
  year={2021},
  volume={},
  number={},
  pages={7758-7762},
  doi={10.1109/ICASSP39728.2021.9413738}}
  
  @article{adversarial-adapt2,
  title={Age-Invariant Training for End-to-End Child Speech Recognition Using Adversarial Multi-Task Learning},
  author={Rumberg, Lars and Ehlert, Hanna and L{\"u}dtke, Ulrike and Ostermann, J{\"o}rn},
  journal={Proc. Interspeech 2021},
  pages={3850--3854},
  year={2021}
}

@article{f0norm,
  title={A Frequency Normalization Technique for Kindergarten Speech Recognition Inspired by the Role of f0 in Vowel Perception},
  author={Yeung, Gary and Alwan, Abeer},
  journal={Interspeech 2019},
  year={2019}
}

@ARTICLE{pitchnorm,
  author={Shahnawazuddin, Syed and Sinha, Rohit and Pradhan, Gayadhar},
  journal={IEEE Signal Processing Letters}, 
  title={Pitch-Normalized Acoustic Features for Robust Children's Speech Recognition}, 
  year={2017},
  volume={24},
  number={8},
  pages={1128-1132},
  doi={10.1109/LSP.2017.2705085}}
  
  @inproceedings{pitch_adapt_norm,
  title={Pitch-Adaptive Front-End Features for Robust Children's ASR},
  author={Syed Shahnawazuddin and Abhishek Dey and Rohit Sinha},
  booktitle={INTERSPEECH},
  year={2016}
}

@INPROCEEDINGS{prosody_feat,
  author={Kathania, Hemant K. and Shahnawazuddin, S. and Adiga, Nagaraj and Ahmad, Waquar},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Role of Prosodic Features on Children's Speech Recognition}, 
  year={2018},
  volume={},
  number={},
  pages={5519-5523},
  doi={10.1109/ICASSP.2018.8461668}}
  
  @inproceedings{speaking_rate,
  title={Improving Children's Speech Recognition Through Time Scale Modification Based Speaking Rate Adaptation},
  author={Kathania, Hemant K and Shahnawazuddin, S and Ahmad, Waquar and Adiga, Nagraj and Jana, Sanjay Kumar and Samaddar, Arun B},
  booktitle={2018 International Conference on Signal Processing and Communications (SPCOM)},
  pages={257--261},
  year={2018},
  organization={IEEE}
}

@article{formant_norm,
author = {Kathania, Hemant and Kadiri, Sudarsana and Alku, Paavo and Kurimo, Mikko},
year = {2022},
month = {01},
pages = {98-106},
title = {A formant modification method for improved ASR of children’s speech},
volume = {136},
journal = {Speech Communication},
doi = {10.1016/j.specom.2021.11.003}
}
@inproceedings{tdnn,
  title={A time delay neural network architecture for efficient modeling of long temporal contexts},
  author={Peddinti, Vijayaditya and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={Sixteenth annual conference of the international speech communication association},
  year={2015}
}
@inproceedings{tdnnf-children,
  title={Advances in Automatic Speech Recognition for Child Speech Using Factored Time Delay Neural Network.},
  author={Wu, Fei and Garc{\'\i}a-Perera, Leibny Paola and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={Interspeech},
  pages={1--5},
  year={2019}
}

@inproceedings{TDNN-F,
  title={Semi-orthogonal low-rank matrix factorization for deep neural networks.},
  author={Povey, Daniel and Cheng, Gaofeng and Wang, Yiming and Li, Ke and Xu, Hainan and Yarmohammadi, Mahsa and Khudanpur, Sanjeev},
  booktitle={Interspeech},
  pages={3743--3747},
  year={2018}
}

@inproceedings{xu21c_interspeech,
  author={Gaopeng Xu and Song Yang and Lu Ma and Chengfei Li and Zhongqin Wu},
  title={{The TAL System for the INTERSPEECH2021 Shared Task on Automatic Speech Recognition for Non-Native Childrens Speech}},
  year=2021,
  booktitle={Proc. Interspeech 2021},
  pages={1294--1298},
  doi={10.21437/Interspeech.2021-1104}
}


@inproceedings{adultAUGMENT1,
  title={Mismatched training data enhancement for automatic recognition of children's speech using DNN-HMM},
  author={Qian, Mengjie and McLoughlin, Ian and Quo, Wu and Dai, Lirong},
  booktitle={2016 10th International Symposium on Chinese Spoken Language Processing (ISCSLP)},
  pages={1--5},
  year={2016},
  organization={IEEE}
}

@inproceedings{adultAUGMENT2,
  title={Improving Children's Speech Recognition Through Out-of-Domain Data Augmentation.},
  author={Fainberg, Joachim and Bell, Peter and Lincoln, Mike and Renals, Steve},
  booktitle={Interspeech},
  pages={1598--1602},
  year={2016}
}
@INPROCEEDINGS{nonnative,
  author={Matassoni, Marco and Gretter, Roberto and Falavigna, Daniele and Giuliani, Diego},
  booktitle={ICASSP}, 
  title={Non-Native Children Speech Recognition Through Transfer Learning}, 
  year={2018},
  volume={},
  number={},
  pages={6229-6233},
  doi={10.1109/ICASSP.2018.8462059}}
  
    @inproceedings{specaugment,
title	= {SpecAugment: A Simple Augmentation Method for Automatic Speech Recognition},
author	= {Daniel S. Park and William Chan and Yu Zhang and Chung-Cheng Chiu and Barret Zoph and Ekin Dogus Cubuk and Quoc V. Le},
year	= {2019},
booktitle	= {INTERSPEECH}
}

@inproceedings{pronunciation,
  title={Improving speech recognition for children using acoustic adaptation and pronunciation modeling.},
  author={Shivakumar, Prashanth Gurunath and Potamianos, Alexandros and Lee, Sungbok and Narayanan, Shrikanth S},
  booktitle={WOCCI},
  pages={15--19},
  year={2014}
}
@inproceedings{pronunciation2,
  title={An analysis of the causes of increased error rates in children's speech recognition},
  author={Li, Qun and Russell, Martin J},
  booktitle={Seventh International Conference on Spoken Language Processing},
  year={2002}
}
@article{subwords,
title = {Highly accurate children’s speech recognition for interactive reading tutors using subword units},
journal = {Speech Communication},
volume = {49},
number = {12},
pages = {861-873},
year = {2007},
issn = {0167-6393},
doi = {https://doi.org/10.1016/j.specom.2007.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S0167639307000878},
author = {Andreas Hagen and Bryan Pellom and Ronald Cole},
keywords = {Literacy tutors, Subword unit based speech recognition, Language modeling, Reading tracking},
}

@article{gelin2021endtoend,
title = {End-to-end acoustic modelling for phone recognition of young readers},
journal = {Speech Communication},
volume = {134},
pages = {71-84},
year = {2021},
issn = {0167-6393},
doi = {https://doi.org/10.1016/j.specom.2021.08.003},
author = {Lucile Gelin and Morgane Daniel and Julien Pinquier and Thomas Pellegrini},
keywords = {Child speech, Phone recognition, Transformer, Connectionist temporal classification, Transfer learning, Low-resource},
}

@article{sri_end2end,
title = {End-to-end neural systems for automatic children speech recognition: An empirical study},
journal = {Computer Speech \& Language},
volume = {72},
pages = {101289},
year = {2022},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2021.101289},
author = {Prashanth {Gurunath Shivakumar} and Shrikanth Narayanan},
keywords = {Children speech recognition, End-to-end speech recognition, Residual network, Time depth separable convolutional network, Transformer},
}

@inproceedings{valtchev1994novel,
  title={A novel decoder design for large vocabulary recognition},
  author={Valtchev, V and Odell, J and Woodland, PC and Young, SJ},
  booktitle={Proceedings of ICSLP},
  year={1994}
}

@inproceedings{aubert1995large,
  title={Large vocabulary continuous speech recognition using word graphs},
  author={Aubert, Xavier and Ney, Hermann},
  booktitle={1995 International Conference on Acoustics, Speech, and Signal Processing},
  volume={1},
  pages={49--52},
  year={1995},
  organization={IEEE}
}

@inproceedings{kaldi,
  title={The Kaldi speech recognition toolkit},
  author={Povey, Daniel and Ghoshal, Arnab and Boulianne, Gilles and Burget, Lukas and Glembek, Ondrej and Goel, Nagendra and Hannemann, Mirko and Motlicek, Petr and Qian, Yanmin and Schwarz, Petr and others},
  booktitle={IEEE 2011 workshop on automatic speech recognition and understanding},
  number={CONF},
  year={2011},
  organization={IEEE Signal Processing Society}
}




@INPROCEEDINGS{linguistic-children,
  author={Wilpon, J.G. and Jacobsen, C.N.},
  booktitle={ICASSP}, 
  title={A study of speech recognition for children and the elderly}, 
  year={1996},
  volume={1},
  number={},
  pages={349-352 vol. 1},
  doi={10.1109/ICASSP.1996.541104}}
 

@inproceedings{asr-improved2,
  title={Adaptation and Normalization Experiments in Speech Recognition for 4 to 8 Year old Children.},
  author={Elenius, Daniel and Blomberg, Mats},
  booktitle={Interspeech},
  pages={2749--2752},
  year={2005}
}


@inproceedings{GANS,
  title={GANs for Children: A Generative Data Augmentation Strategy for Children Speech Recognition},
  author={Sheng, Peiyao and Yang, Zhuolin and Qian, Yanmin},
  booktitle={2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={129--135},
  year={2019},
  organization={IEEE}
}

@misc{etlt,
    title={TLT-school: a Corpus of Non Native Children Speech},
    author={Roberto Gretter and Marco Matassoni and Stefano Bannò and Daniele Falavigna},
    year={2020},
    eprint={2001.08051},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{chorec,
  title={Children’s oral reading corpus (CHOREC): description and assessment of annotator agreement},
  author={Cleuren, Leen and Duchateau, Jacques and Ghesquiere, Pol and others},
  journal={LREC 2008 Proceedings},
  pages={998--1005},
  year={2008},
  publisher={European Language Resources Association (ELRA); Parijs}
}


@inproceedings{sphinx2,
author = {Huang, Xuedong and Alleva, Fileno and Hwang, Mei-Yuh and Rosenfeld, Ronald},
title = {An Overview of the SPHINX-II Speech Recognition System},
year = {1993},
isbn = {1558603247},
publisher = {Association for Computational Linguistics},
address = {USA},
url = {https://doi.org/10.3115/1075671.1075690},
doi = {10.3115/1075671.1075690},
abstract = {In the past year at Carnegie Mellon steady progress has been made in the area of acoustic and language modeling. The result has been a dramatic reduction in speech recognition errors in the SPHINX-II system. In this paper, we review SPHINX-II and summarize our recent efforts on improved speech recognition. Recently SPHINX-II achieved the lowest error rate in the November 1992 DARPA evaluations. For 5000-word, speaker-independent, continuous, speech recognition, the error rate was reduced to 5%.},
booktitle = {Proceedings of the Workshop on Human Language Technology},
pages = {81–86},
numpages = {6},
location = {Princeton, New Jersey},
series = {HLT '93}
}


@inproceedings{letsread,
  title={The LetsRead corpus of Portuguese children reading aloud for performance evaluation},
  author={Proen{\c{c}}a, Jorge and Celorico, Dirce and Candeias, Sara and Lopes, Carla and Perdig{\~a}o, Fernando},
  booktitle={Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC'16)},
  pages={781--785},
  year={2016}
}

@inproceedings{pfstar,
  title={The PF-Star Children's Speech Corpus},
  author={Russell, Martin and D'Arcy, Shona and Wong, M and Batliner, A and Blomberg, M and Gerosa, M},
  booktitle={Interspeech 2005},
  year={2005}
}

@INPROCEEDINGS{ssc,
  author={Paliwal, K.K.},
  booktitle={ICASSP}, 
  title={Spectral subband centroid features for speech recognition}, 
  year={1998},
  volume={2},
  number={},
  pages={617-620 vol.2},
  doi={10.1109/ICASSP.1998.675340}}
  
  
 @inproceedings{2019multi,
  title={Multi-task based mispronunciation detection of children speech using multi-lingual information},
  author={Wei, Linxuan and Dong, Wenwei and Lin, Binghuai and Zhang, Jinsong},
  booktitle={APSIPA ASC},
  pages={1791--1794},
  year={2019},
  organization={IEEE}
}

@article{meyer2019multi,
  title={Multi-task and transfer learning in low-resource speech recognition},
  author={Meyer, Josh},
  year={2019},
  publisher={The University of Arizona.}
}

@inproceedings{multi-nlp,
author = {Collobert, Ronan and Weston, Jason},
title = {A Unified Architecture for Natural Language Processing: Deep Neural Networks with Multitask Learning},
year = {2008},
isbn = {9781605582054},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1390156.1390177},
doi = {10.1145/1390156.1390177},
abstract = {We describe a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense (grammatically and semantically) using a language model. The entire network is trained jointly on all these tasks using weight-sharing, an instance of multitask learning. All the tasks use labeled data except the language model which is learnt from unlabeled text and represents a novel form of semi-supervised learning for the shared tasks. We show how both multitask learning and semi-supervised learning improve the generalization of the shared tasks, resulting in state-of-the-art-performance.},
booktitle = {ICML},
pages = {160–167},
numpages = {8},
location = {Helsinki, Finland},
series = {ICML '08}
}


@INPROCEEDINGS{multi-speech,
  author={Huang, Jui-Ting and Li, Jinyu and Yu, Dong and Deng, Li and Gong, Yifan},
  booktitle={ICASSP}, 
  title={Cross-language knowledge transfer using multilingual deep neural network with shared hidden layers}, 
  year={2013},
  volume={},
  number={},
  pages={7304-7308},
  doi={10.1109/ICASSP.2013.6639081}}
  
    @INPROCEEDINGS{abad2020,
  author={Abad, Alberto and Bell, Peter and Carmantini, Andrea and Renais, Steve},
  booktitle={ICASSP}, 
  title={Cross Lingual Transfer Learning for Zero-Resource Domain Adaptation}, 
  year={2020},
  volume={},
  number={},
  pages={6909-6913},
  doi={10.1109/ICASSP40776.2020.9054468}}

@inproceedings{MTL-LFMMI,
  title={Lattice-Free Maximum Mutual Information Training of Multilingual Speech Recognition Systems.},
  author={Madikeri, Srikanth R and Khonglah, Banriskhem K and Tong, Sibo and Motlicek, Petr and Bourlard, Herv{\'e} and Povey, Daniel},
  booktitle={INTERSPEECH},
  pages={4746--4750},
  year={2020}
}

@INPROCEEDINGS{VTLN2,  author={Serizel, Romain and Giuliani, Diego},  booktitle={SLT Workshop},   title={Vocal tract length normalisation approaches to DNN-based children's and adults' speech recognition},   year={2014},  volume={},  number={},  pages={135-140},  doi={10.1109/SLT.2014.7078563}}

@article{madikeri2021multitask,
  title={Multitask adaptation with Lattice-Free MMI for multi-genre speech recognition of low resource languages},
  author={Madikeri, Srikanth and Motlicek, Petr and Bourlard, Herv{\'e}},
  journal={Proc. Interspeech 2021},
  pages={4329--4333},
  year={2021}
}

@inproceedings{tachbelie2020development,
  title={Development of Multilingual ASR Using GlobalPhone for Less-Resourced Languages: The Case of Ethiopian Languages.},
  author={Tachbelie, Martha Yifiru and Abate, Solomon Teferra and Schultz, Tanja},
  booktitle={Interspeech 2020},
  pages={1032--1036},
  year={2020}
}

@article{semi,
  title={Semi-supervised asr by end-to-end self-training},
  author={Chen, Yang and Wang, Weiran and Wang, Chao},
  journal={arXiv preprint arXiv:2001.09128},
  year={2020}
}

@inproceedings{mtl_computervision,
  title={Fast r-cnn},
  author={Girshick, Ross},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1440--1448},
  year={2015}
}

@article{bioinfo,
  title={Domain-adversarial multi-task framework for novel therapeutic property prediction of compounds},
  author={Xie, Lingwei and He, Song and Zhang, Zhongnan and Lin, Kunhui and Bo, Xiaochen and Yang, Shu and Feng, Boyuan and Wan, Kun and Yang, Kang and Yang, Jie and others},
  journal={Bioinformatics},
  volume={36},
  number={9},
  pages={2848--2855},
  year={2020},
  publisher={Oxford University Press}
}

@article{zhang2018overview,
  title={An overview of multi-task learning},
  author={Zhang, Yu and Yang, Qiang},
  journal={National Science Review},
  volume={5},
  number={1},
  pages={30--43},
  year={2018},
  publisher={Oxford University Press}
}

@article{VTLN_wfun,
author = {Saito, Yuki and Takamichi, Shinnosuke and Saruwatari, Hiroshi},
year = {2019},
month = {06},
pages = {},
title = {Vocoder-free text-to-speech synthesis incorporating generative adversarial networks using low-/multi-frequency STFT amplitude spectra},
volume = {58},
journal = {Computer Speech \& Language},
doi = {10.1016/j.csl.2019.05.008}
}
@inproceedings{SPEECONS,
  title={SPEECON – Speech Databases for Consumer Devices: Database Specification and Validation},
  author={Dorota J. Iskra and Beate Grosskopf and Krzysztof Marasek and Henk van den Heuvel and Frank Diehl and Andreas Kiessling},
  booktitle={LREC},
  year={2002}
}

@article{callslt,
author = {Rayner, Manny and Tsourakis, Nikos and Baur, Claudia and Bouillon, Pierrette and Gerlach, Johanna},
year = {2014},
month = {01},
pages = {},
title = {CALL-SLT: A Spoken CALL System: based on grammar and speech recognition},
volume = {10},
journal = {Linguistic Issues in Language Technology},
doi = {10.33011/lilt.v10i.1353}
}

@misc{childit2,
  title={CHILDIT2--A New Children Read Speech Corpus},
  author={COSI, PIERO and PACI, GIULIO and SOMMAVILLA, GIACOMO and TESSER, FABIO}
}

@inproceedings{JASMIN,
    title = "Recording Speech of Children, Non-Natives and Elderly People for {HLT} Applications: the {JASMIN}-{CGN} Corpus.",
    author = "Cucchiarini, Catia  and
      Driesen, Joris  and
      Van hamme, Hugo  and
      Sanders, Eric",
    booktitle = "Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08)",
    month = may,
    year = "2008",
    address = "Marrakech, Morocco",
    publisher = "European Language Resources Association (ELRA)",
    url = "http://www.lrec-conf.org/proceedings/lrec2008/pdf/366_paper.pdf",
    abstract = "Within the framework of the Dutch-Flemish programme STEVIN, the JASMIN-CGN (Jongeren, Anderstaligen en Senioren in Mens-machine Interactie Corpus Gesproken Nederlands) project was carried out, which was aimed at collecting speech of children, non-natives and elderly people. The JASMIN-CGN project is an extension of the Spoken Dutch Corpus (CGN) along three dimensions. First, by collecting a corpus of contemporary Dutch as spoken by children of different age groups, elderly people and non-natives with different mother tongues, an extension along the age and mother tongue dimensions was achieved. In addition, we collected speech material in a communication setting that was not envisaged in the CGN: human-machine interaction. One third of the data was collected in Flanders and two thirds in the Netherlands. In this paper we report on our experiences in collecting this corpus and we describe some of the important decisions that we made in the attempt to combine efficiency and high quality.",
}

@inproceedings{takemaru,
  title={Public speech-oriented guidance system with adult and child discrimination capability},
  author={Nisimura, Ryuichi and Lee, Akinobu and Saruwatari, Hiroshi and Shikano, Kiyohiro},
  booktitle={2004 IEEE International Conference on Acoustics, Speech, and Signal Processing},
  volume={1},
  pages={I--433},
  year={2004},
  organization={IEEE}
}


@inproceedings{speco,
  title={A Hungarian child database for speech processing applications},
  author={Csat{\'a}ri, Ferenc and Bakcsi, Zs and Vicsi, Kl{\'a}ra},
  booktitle={Sixth European Conference on Speech Communication and Technology},
  year={1999}
}

@inproceedings{tball,
  title={Tball data collection: the making of a young children's speech corpus},
  author={Kazemzadeh, Abe and You, Hong and Iseli, Markus and Jones, Barbara and Cui, Xiaodong and Heritage, Margaret and Price, Patti and Anderson, Elaine and Narayanan, Shrikanth and Alwan, Abeer},
  booktitle={Ninth European Conference on Speech Communication and Technology},
  year={2005}
}
@inproceedings{ad-child_ru,
  title={AD-Child. Ru: Speech corpus for Russian children with atypical development},
  author={Lyakso, Elena and Frolova, Olga and Kaliyev, Arman and Gorodnyi, Viktor and Grigorev, Aleksey and Matveev, Yuri},
  booktitle={International Conference on Speech and Computer},
  pages={299--308},
  year={2019},
  organization={Springer}
}
@article{cuchild,
  title={Cuchild: A large-scale cantonese corpus of child speech for phonology and articulation assessment},
  author={Ng, Si-Ioi and Ng, Cymie Wing-Yee and Wang, Jiarui and Lee, Tan and Lee, Kathy Yuet-Sheung and Tong, Michael Chi-Fai},
  journal={arXiv preprint arXiv:2008.03188},
  year={2020}
}

@INPROCEEDINGS{cass_child,
author={Gao, Jun and Li, Aijun and Xiong, Ziyu},
booktitle={2012 International Conference on Speech Database and Assessments},
title={Mandarin multimedia child speech corpus: Cass\_Child},
year={2012},
volume={},
number={},
pages={7-12}, 
doi={10.1109/ICSDA.2012.6422462}}

@article{russell2006pf,
  title={The pf-star british english childrens speech corpus},
  author={Russell, Martin},
  journal={The Speech Ark Limited},
  year={2006},
  publisher={Citeseer}
}

@article{providence,
  title={Word-minimality, epenthesis and coda licensing in the early acquisition of English},
  author={Demuth, Katherine and Culbertson, Jennifer and Alter, Jennifer},
  journal={Language and speech},
  volume={49},
  number={2},
  pages={137--173},
  year={2006},
  publisher={Sage Publications Sage UK: London, England}
}

@article{LyonSC,
  title={Prosodically-conditioned variability in children's production of French determiners},
  author={Demuth, Katherine and Tremblay, Annie},
  journal={Journal of child language},
  volume={35},
  number={1},
  pages={99--127},
  year={2008},
  publisher={Cambridge University Press}
}


@incollection{demuth1992acquisition,
  title={The acquisition of Sesotho},
  author={Demuth, Katherine},
  booktitle={The crosslinguistic study of language acquisition},
  pages={557--638},
  year={1992},
  publisher={Psychology Press}
}

@article{nitk,
  title={NITK Kids’ speech corpus},
  author={Ramteke, Pravin Bhaskar and Supanekar, Sujata and Hegde, Pradyoth and Nelson, Hanna and Aithal, V and Koolagudi, SG},
  journal={emotion},
  volume={491},
  pages={4--15},
  year={2019}
}

@inproceedings{chiede,
  title={CHIEDE, a spontaneous child language corpus of Spanish},
  author={Garrote, Marta and Moreno Sandoval, A},
  booktitle={Proceedings of the 3rd International LABLITA Workshop in Corpus Linguistics},
  year={2008}
}

@inproceedings{emochildru,
  title={EmoChildRu: emotional child Russian speech corpus},
  author={Lyakso, Elena and Frolova, Olga and Dmitrieva, Evgeniya and Grigorev, Aleksey and Kaya, Heysem and Salah, Albert Ali and Karpov, Alexey},
  booktitle={International Conference on Speech and Computer},
  pages={144--152},
  year={2015},
  organization={Springer}
}

@inproceedings{ahmed2021auskidtalk,
  title={AusKidTalk: an auditory-visual corpus of 3-to 12-year-old Australian children's speech},
  author={Ahmed, Beena and Ballard, Kirrie and Burnham, Denis and Sirojan, Tharmakulasingam and Mehmood, Hadi and Estival, Dominique and Baker, Elise and Cox, Felicity and Arciuli, Joanne and Benders, Titia and others},
  booktitle={Annual Conference of the International Speech Communication Association (22nd: 2021)},
  pages={3680--3684},
  year={2021},
  organization={International Speech Communication Association}
}

@article{eshky2019ultrasuite,
  title={UltraSuite: a repository of ultrasound and acoustic data from child speech therapy sessions},
  author={Eshky, Aciel and Ribeiro, Manuel Sam and Cleland, Joanne and Richmond, Korin and Roxburgh, Zoe and Scobbie, James and Wrench, Alan},
  journal={arXiv preprint arXiv:1907.00835},
  year={2019}
}
@article{lee1999acoustics,
  title={Acoustics of children’s speech: Developmental changes of temporal and spectral parameters},
  author={Lee, Sungbok and Potamianos, Alexandros and Narayanan, Shrikanth},
  journal={The Journal of the Acoustical Society of America},
  volume={105},
  number={3},
  pages={1455--1468},
  year={1999},
  publisher={Acoustical Society of America}
}

@INPROCEEDINGS{CFSC,  author={Pascual, Ronald M. and Guevara, Rowena Cristina L.},  booktitle={TENCON 2012 IEEE Region 10 Conference},   title={Developing a children's Filipino speech corpus for application in automatic detection of reading miscues and disfluencies},   year={2012},  volume={},  number={},  pages={1-6},  doi={10.1109/TENCON.2012.6412235}}

@inproceedings{hagen2003children,
  title={Children's speech recognition with application to interactive books and tutors},
  author={Hagen, Andreas and Pellom, Bryan and Cole, Ronald},
  booktitle={2003 IEEE Workshop on Automatic Speech Recognition and Understanding (IEEE Cat. No. 03EX721)},
  pages={186--191},
  year={2003},
  organization={IEEE}
}

@article{leonard1993tidigits,
  title={Tidigits speech corpus},
  author={Leonard, R Gary and Doddington, George},
  journal={Texas Instruments, Inc},
  year={1993}
}
@phdthesis{gerosa2006acoustic,
  title={Acoustic modeling for automatic recognition of children’s speech},
  author={Gerosa, M},
  year={2006},
  school={Ph. D. thesis, University of Trento}
}

@inproceedings{burkhardt2010database,
  title={A database of age and gender annotated telephone speech},
  author={Burkhardt, Felix and Eckert, Martin and Johannsen, Wiebke and Stegmann, Joachim},
  booktitle={Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC'10)},
  year={2010}
}

@inproceedings{bell2005swedish,
  title={The Swedish NICE Corpus--Spoken dialogues between children and embodied characters in a computer game scenario},
  author={Bell, Linda and Boye, Johan and Gustafson, Joakim and Heldner, Mattias and Lindstr{\"o}m, Anders and Wir{\'e}n, Mats},
  booktitle={Interspeech 2005-Eurospeech, 9th European Conference on Speech Communication and Technology, Lisbon, Portugal, September 4-8, 2005},
  pages={2765--2768},
  year={2005},
  organization={ISCA}
}

@article{grissemann2000zurcher,
  title={Z{\"u}rcher Lesetest},
  author={Grissemann, Hans and Linder, M},
  journal={Bern: Huber Verlag},
  year={2000}
}

@book{steidl2009automatic,
  title={Automatic classification of emotion related user states in spontaneous children's speech},
  author={Steidl, Stefan},
  year={2009},
  publisher={Logos-Verlag Berlin, Germany}
}

@inproceedings{bell2003child,
  title={Child and adult speaker adaptation during error resolution in a publicly available spoken dialogue system},
  author={Bell, Linda and Gustafson, Joakim},
  booktitle={Eighth European Conference on Speech Communication and Technology},
  year={2003},
  organization={Citeseer}
}

@article{PEREZESPINOSA202055,
title = {IESC-Child: An Interactive Emotional Children’s Speech Corpus},
journal = {Computer Speech \& Language},
volume = {59},
pages = {55-74},
year = {2020},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2019.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S0885230817301547},
author = {Humberto Pérez-Espinosa and Juan Martínez-Miranda and Ismael Espinosa-Curiel and Josefina Rodríguez-Jacobo and Luis Villaseñor-Pineda and Himer Avila-George},
keywords = {Interactive systems, Emotional analysis, Paralinguistic information},
abstract = {In this paper, we describe the process that we used to create a new corpus of children’s emotional speech. We used a Wizard of Oz (WoZ) setting to induce different emotional reactions in children during speech-based interactions with two robots. We recorded the speech spoken in Mexican Spanish by 174 children (both sexes) between 6 and 11 years of age. The recordings were manually segmented and transcribed. The segments were then labeled with two types of emotional-related paralinguistic information: emotion and attitude. The corpus contained 2093min of audio recordings (34.88h) divided into 19,793 speech segments. The Interactive Emotional Children’s Speech Corpus (IESC-Child) can be a valuable resource for researchers studying affective reactions in speech communication during child-computer interactions in Spanish and for creating models to recognize acoustic paralinguistic information. IESC-Child is available to the research community upon request.}
}

@inproceedings{hamalainen2013cng,
  title={The CNG corpus of European Portuguese children’s speech},
  author={H{\"a}m{\"a}l{\"a}inen, Annika and Rodrigues, Silvia and J{\'u}dice, Ana and Silva, Sandra Morgado and Calado, Ant{\'o}nio and Pinto, Fernando Miguel and Dias, Miguel Sales},
  booktitle={International Conference on Text, Speech and Dialogue},
  pages={544--551},
  year={2013},
  organization={Springer}
}

@article{big_review_childASR,
author = {Bhardwaj, Vivek and Kukreja, Vinay and Belkhier, Youcef and Bajaj, Mohit and .B, Srikanth Goud and Rehman, Ateeq and Hamam, Habib and Othman, Mohamed},
year = {2022},
month = {04},
pages = {},
title = {Automatic Speech Recognition (ASR) System for Children’s: A Systematic Literature Review},
journal = {Applied Sciences},
doi = {10.3390/app12094419}
}


@inproceedings{bdpublico,
  title={The design of a large vocabulary speech corpus for Portuguese},
  author={Neto, Joao P and Martins, Ciro A and Meinedo, Hugo and Almeida, Luis B},
  booktitle={Fifth European Conference on Speech Communication and Technology},
  year={1997}
}
@article{kunze2017transfer,
  title={Transfer learning for speech recognition on a budget},
  author={Kunze, Julius and Kirsch, Louis and Kurenkov, Ilia and Krug, Andreas and Johannsmeier, Jens and Stober, Sebastian},
  journal={arXiv preprint arXiv:1706.00290},
  year={2017}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{dong2018speech,
  title={Speech-transformer: a no-recurrence sequence-to-sequence model for speech recognition},
  author={Dong, Linhao and Xu, Shuang and Xu, Bo},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5884--5888},
  year={2018},
  organization={IEEE}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{hmm-end2end,
author = {Wang, Dong and Wang, Xiaodong and Lv, Shaohe},
year = {2019},
month = {08},
pages = {1018},
title = {An Overview of End-to-End Automatic Speech Recognition},
volume = {11},
journal = {Symmetry},
doi = {10.3390/sym11081018}
}

@article{VAE,
  title={Auto-Encoding Variational Bayes},
  author={Diederik P. Kingma and Max Welling},
  journal={CoRR},
  year={2014},
  volume={abs/1312.6114}
}


@inproceedings{houlsby,
  title={Parameter-efficient transfer learning for NLP},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={International Conference on Machine Learning},
  pages={2790--2799},
  year={2019},
  organization={PMLR}
}

@inproceedings{pfeiffer,
    title = "{MAD-X}: {A}n {A}dapter-{B}ased {F}ramework for {M}ulti-{T}ask {C}ross-{L}ingual {T}ransfer",
    author = "Pfeiffer, Jonas  and
      Vuli{\'c}, Ivan  and
      Gurevych, Iryna  and
      Ruder, Sebastian",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2020.emnlp-main.617",
    pages = "7654--7673",
}


@misc{speechbrain,
  title={{SpeechBrain}: A General-Purpose Speech Toolkit},
  author={Mirco Ravanelli and Titouan Parcollet and Peter Plantinga and Aku Rouhe and Samuele Cornell and Loren Lugosch and Cem Subakan and Nauman Dawalatabad and Abdelwahab Heba and Jianyuan Zhong and Ju-Chieh Chou and Sung-Lin Yeh and Szu-Wei Fu and Chien-Feng Liao and Elena Rastorgueva and François Grondin and William Aris and Hwidong Na and Yan Gao and Renato De Mori and Yoshua Bengio},
  year={2021},
  eprint={2106.04624},
  archivePrefix={arXiv},
  primaryClass={eess.AS},
  note={arXiv:2106.04624}
}

@article{vae_transformation,
  title={Modeling and transforming speech using variational autoencoders},
  author={Blaauw, Merlijn and Bonada, Jordi},
  journal={Morgan N, editor. Interspeech 2016; 2016 Sep 8-12; San Francisco, CA.[place unknown]: ISCA; 2016. p. 1770-4.},
  year={2016},
  publisher={International Speech Communication Association (ISCA)}
}

@article{vae_gen,
  title={Expressive speech synthesis via modeling expressions with variational autoencoder},
  author={Akuzawa, Kei and Iwasawa, Yusuke and Matsuo, Yutaka},
  journal={arXiv preprint arXiv:1804.02135},
  year={2018}
}

@inproceedings{vae_enh,
  title={A variance modeling framework based on variational autoencoders for speech enhancement},
  author={Leglaive, Simon and Girin, Laurent and Horaud, Radu},
  booktitle={2018 IEEE 28th International Workshop on Machine Learning for Signal Processing (MLSP)},
  pages={1--6},
  year={2018},
  organization={IEEE}
}

@inproceedings{philip2020monolingual,
  title={Monolingual adapters for zero-shot neural machine translation},
  author={Philip, Jerin and Berard, Alexandre and Gall{\'e}, Matthias and Besacier, Laurent},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={4465--4470},
  year={2020}
}

@article{kannan2019large,
  title={Large-scale multilingual speech recognition with a streaming end-to-end model},
  author={Kannan, Anjuli and Datta, Arindrima and Sainath, Tara N and Weinstein, Eugene and Ramabhadran, Bhuvana and Wu, Yonghui and Bapna, Ankur and Chen, Zhifeng and Lee, Seungji},
  journal={arXiv preprint arXiv:1909.05330},
  year={2019}
}
@article{tomanek2021residual,
  title={Residual Adapters for Parameter-Efficient ASR Adaptation to Atypical and Accented Speech},
  author={Tomanek, Katrin and Zayats, Vicky and Padfield, Dirk and Vaillancourt, Kara and Biadsy, Fadi},
  journal={arXiv preprint arXiv:2109.06952},
  year={2021}
}

@article{chen2020data,
  title={Data Augmentation For Children's Speech Recognition--The" Ethiopian" System For The SLT 2021 Children Speech Recognition Challenge},
  author={Chen, Guoguo and Na, Xingyu and Wang, Yongqing and Yan, Zhiyong and Zhang, Junbo and Ma, Sifan and Wang, Yujun},
  journal={arXiv preprint arXiv:2011.04547},
  year={2020}
}

@article{ng2020cuhk,
  title={The cuhk-tudelft system for the slt 2021 children speech recognition challenge},
  author={Ng, Si-Ioi and Liu, Wei and Peng, Zhiyuan and Feng, Siyuan and Huang, Hing-Pang and Scharenborg, Odette and Lee, Tan},
  journal={arXiv preprint arXiv:2011.06239},
  year={2020}
}

@article{luscher2019rwth,
  title={RWTH ASR Systems for LibriSpeech: Hybrid vs Attention--w/o Data Augmentation},
  author={L{\"u}scher, Christoph and Beck, Eugen and Irie, Kazuki and Kitza, Markus and Michel, Wilfried and Zeyer, Albert and Schl{\"u}ter, Ralf and Ney, Hermann},
  journal={arXiv preprint arXiv:1905.03072},
  year={2019}
}

@inproceedings{battenberg2017exploring,
  title={Exploring neural transducers for end-to-end speech recognition},
  author={Battenberg, Eric and Chen, Jitong and Child, Rewon and Coates, Adam and Li, Yashesh Gaur Yi and Liu, Hairong and Satheesh, Sanjeev and Sriram, Anuroop and Zhu, Zhenyao},
  booktitle={2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={206--213},
  year={2017},
  organization={IEEE}
}

@article{soltau2016neural,
  title={Neural speech recognizer: Acoustic-to-word LSTM model for large vocabulary speech recognition},
  author={Soltau, Hagen and Liao, Hank and Sak, Hasim},
  journal={arXiv preprint arXiv:1610.09975},
  year={2016}
}

@article{tribus,
  title={TRIBUS: An end-to-end automatic speech recognition system for European Portuguese},
  author={Carlos F. Carvalho and Alberto Abad},
  journal={IberSPEECH 2021},
  year={2021}
}

@INPROCEEDINGS{hmmvse2e,  author={Karita, Shigeki and Chen, Nanxin and Hayashi, Tomoki and Hori, Takaaki and Inaguma, Hirofumi and Jiang, Ziyan and Someki, Masao and Soplin, Nelson Enrique Yalta and Yamamoto, Ryuichi and Wang, Xiaofei and Watanabe, Shinji and Yoshimura, Takenori and Zhang, Wangyou},  booktitle={2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},   title={A Comparative Study on Transformer vs RNN in Speech Applications},   year={2019},  volume={},  number={},  pages={449-456},  doi={10.1109/ASRU46091.2019.9003750}}

@article{hannun2014deep,
  title={Deep speech: Scaling up end-to-end speech recognition},
  author={Hannun, Awni and Case, Carl and Casper, Jared and Catanzaro, Bryan and Diamos, Greg and Elsen, Erich and Prenger, Ryan and Satheesh, Sanjeev and Sengupta, Shubho and Coates, Adam and others},
  journal={arXiv preprint arXiv:1412.5567},
  year={2014}
}
@article{sutskever2014sequence,
  title={Sequence to sequence learning with neural networks},
  author={Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}
@article{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.0473},
  year={2014}
}

@INPROCEEDINGS{seq2seq_imagecaption,  author={Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},  booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},   title={Show and tell: A neural image caption generator},   year={2015},  volume={},  number={},  pages={3156-3164},  doi={10.1109/CVPR.2015.7298935}}

@article{vinyals2015neural,
  title={A neural conversational model},
  author={Vinyals, Oriol and Le, Quoc},
  journal={arXiv preprint arXiv:1506.05869},
  year={2015}
}

@article{nallapati2016abstractive,
  title={Abstractive text summarization using sequence-to-sequence rnns and beyond},
  author={Nallapati, Ramesh and Zhou, Bowen and Gulcehre, Caglar and Xiang, Bing and others},
  journal={arXiv preprint arXiv:1602.06023},
  year={2016}
}

@inproceedings{shen2018natural,
  title={Natural tts synthesis by conditioning wavenet on mel spectrogram predictions},
  author={Shen, Jonathan and Pang, Ruoming and Weiss, Ron J and Schuster, Mike and Jaitly, Navdeep and Yang, Zongheng and Chen, Zhifeng and Zhang, Yu and Wang, Yuxuan and Skerrv-Ryan, Rj and others},
  booktitle={2018 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={4779--4783},
  year={2018},
  organization={IEEE}
}

@inproceedings{wang2021towards,
  title={Towards data selection on tts data for children’s speech recognition},
  author={Wang, Wei and Zhou, Zhikai and Lu, Yizhou and Wang, Hongji and Du, Chenpeng and Qian, Yanmin},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6888--6892},
  year={2021},
  organization={IEEE}
}

@inproceedings{kim2021conditional,
  title={Conditional variational autoencoder with adversarial learning for end-to-end text-to-speech},
  author={Kim, Jaehyeon and Kong, Jungil and Son, Juhee},
  booktitle={International Conference on Machine Learning},
  pages={5530--5540},
  year={2021},
  organization={PMLR}
}

@inproceedings{laptev2020you,
  title={You do not need more data: Improving end-to-end speech recognition by text-to-speech data augmentation},
  author={Laptev, Aleksandr and Korostik, Roman and Svischev, Aleksey and Andrusenko, Andrei and Medennikov, Ivan and Rybin, Sergey},
  booktitle={2020 13th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)},
  pages={439--444},
  year={2020},
  organization={IEEE}
}

@inproceedings{gelin2021simulating,
  title={Simulating reading mistakes for child speech Transformer-based phone recognition},
  author={Gelin, Lucile and Pellegrini, Thomas and Pinquier, Julien and Daniel, Morgane},
  booktitle={Annual Conference of the International Speech Communication Association (INTERSPEECH)},
  year={2021}
}

@inproceedings{gelin2020babble,
  title={Babble noise augmentation for phone recognition applied to children reading aloud in a classroom environment},
  author={Gelin, Lucile and Daniel, Morgane and Pellegrini, Thomas and Pinquier, Julien},
  booktitle={Speech in Noise Workshop (SPiN)},
  year={2020}
}
@inproceedings{couvreur2000use,
  title={On the use of artificial reverberation for ASR in highly reverberant environments},
  author={Couvreur, Laurent and Couvreur, Christophe},
  booktitle={Proc. 2nd IEEE Benelux Signal Processing Symposium (SPS-2000), Hilvarenbeek, The Netherlands},
  pages={S001--S004},
  year={2000},
  organization={Citeseer}
}
@article{whitenoise,
title = {Assessing local noise level estimation methods: Application to noise robust ASR},
journal = {Speech Communication},
volume = {34},
number = {1},
pages = {141-158},
year = {2001},
note = {Noise Robust ASR},
issn = {0167-6393},
doi = {https://doi.org/10.1016/S0167-6393(00)00051-0},
url = {https://www.sciencedirect.com/science/article/pii/S0167639300000510},
author = {Christophe Ris and Stéphane Dupont},
keywords = {Robust automatic speech recognition, Noise level estimation, Noise reduction, Spectral subtraction, Missing data},
abstract = {In this paper, we assess and compare four methods for the local estimation of noise spectra, namely the energy clustering, the Hirsch histograms, the weighted average method and the low-energy envelope tracking. Moreover we introduce, for these four approaches, the harmonic filtering strategy, a new pre-processing technique, expected to better track fast modulations of the noise energy. The speech periodicity property is used to update the noise level estimate during voiced parts of speech, without explicit detection of voiced portions. Our evaluation is performed with six different kinds of noises (both artificial and real noises) added to clean speech. The best noise level estimation method is then applied to noise robust speech recognition based on techniques requiring a dynamic estimation of the noise spectra, namely spectral subtraction and missing data compensation.
Zusammenfassung
Dans ce papier, nous nous proposons d'évaluer et de comparer différentes méthodes d'estimation locale du spectre de bruit: le clustering des énergies, les histogrammes de Hirsch, la méthode de la moyenne pondérée ainsi que le suivi de l'enveloppe de basse energie. Nous présentons également, en pré-traitement pour chacune de ces méthodes, le filtrage des harmoniques, une technique permettant de suivre plus efficacement des variations rapides de l'énergie du bruit. Le caractère harmonique de certaines portions de parole est exploité afin de réestimer le niveau de bruit pendant les périodes de sons voisés (sans détection explicite du caractère voisé ou non des segments de parole). Ces différentes approches ont été testées sur six types de bruit différents (artificiels et réels) ajoutés à de la parole claire. Les estimateurs de niveaux de bruit ainsi testés ont alors été appliqués à deux méthodes de reconnaissance de la parole robuste aux bruits basées sur la soustraction spectrale et la théorie des données manquantes.}
}

@inproceedings{malek2017robust,
  title={Robust Automatic Recognition of Speech with background music},
  author={Malek, Jiri and Zdansky, Jindrich and Cerva, Petr},
  booktitle={2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5210--5214},
  year={2017},
  organization={IEEE}
}
@inproceedings{VTLP,
  title={Vocal tract length perturbation (VTLP) improves speech recognition},
  author={Jaitly, Navdeep and Hinton, Geoffrey E},
  booktitle={Proc. ICML Workshop on Deep Learning for Audio, Speech and Language},
  volume={117},
  pages={21},
  year={2013}
}

@inproceedings{liu2003noise,
  title={Noise robustness in speech to speech translation},
  author={Liu, Fu-Hua and Gao, Yuqing and Gu, Liang and Picheny, Michael},
  booktitle={Eighth European Conference on Speech Communication and Technology},
  year={2003}
}

@article{pfeiffer2020adapterfusion,
  title={AdapterFusion: Non-destructive task composition for transfer learning},
  author={Pfeiffer, Jonas and Kamath, Aishwarya and R{\"u}ckl{\'e}, Andreas and Cho, Kyunghyun and Gurevych, Iryna},
  journal={arXiv preprint arXiv:2005.00247},
  year={2020}
}

@article{gong2022layer,
  title={Layer-wise fast adaptation for end-to-end multi-accent speech recognition},
  author={Gong, Xun and Lu, Yizhou and Zhou, Zhikai and Qian, Yanmin},
  journal={arXiv preprint arXiv:2204.09883},
  year={2022}
}

@article{van2017neural,
  title={Neural discrete representation learning},
  author={Van Den Oord, Aaron and Vinyals, Oriol and others},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{cooper2020zero,
  title={Zero-shot multi-speaker text-to-speech with state-of-the-art neural speaker embeddings},
  author={Cooper, Erica and Lai, Cheng-I and Yasuda, Yusuke and Fang, Fuming and Wang, Xin and Chen, Nanxin and Yamagishi, Junichi},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6184--6188},
  year={2020},
  organization={IEEE}
}

@inproceedings{hu2022synt++,
  title={SYNT++: Utilizing Imperfect Synthetic Data to Improve Speech Recognition},
  author={Hu, Ting-Yao and Armandpour, Mohammadreza and Shrivastava, Ashish and Chang, Jen-Hao Rick and Koppula, Hema and Tuzel, Oncel},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7682--7686},
  year={2022},
  organization={IEEE}
}

@article{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{hsu2021hubert,
  title={Hubert: Self-supervised speech representation learning by masked prediction of hidden units},
  author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={29},
  pages={3451--3460},
  year={2021},
  publisher={IEEE}
}

@article{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={12449--12460},
  year={2020}
}

@inproceedings{caseiro2002using,
  title={Using dynamic WFST composition for recognizing broadcast news},
  author={Caseiro, Diamantino and Trancoso, Isabel},
  booktitle={Seventh International Conference on Spoken Language Processing},
  year={2002}
}

@article{mohri1997finite,
  title={Finite-state transducers in language and speech processing},
  author={Mohri, Mehryar},
  journal={Computational linguistics},
  volume={23},
  number={2},
  pages={269--311},
  year={1997}
}

@article{botelho2020pathological,
  title={Pathological speech detection using x-vector embeddings},
  author={Botelho, Catarina and Teixeira, Francisco and Rolland, Thomas and Abad, Alberto and Trancoso, Isabel},
  journal={arXiv preprint arXiv:2003.00864},
  year={2020}
}

@inproceedings{snyder2018x,
  title={X-vectors: Robust dnn embeddings for speaker recognition},
  author={Snyder, David and Garcia-Romero, Daniel and Sell, Gregory and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2018 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={5329--5333},
  year={2018},
  organization={IEEE}
}

@inproceedings{hauptman2019identifying,
  title={Identifying Distinctive Acoustic and Spectral Features in Parkinson's Disease.},
  author={Hauptman, Yermiyahu and Aloni-Lavi, Ruth and Lapidot, Itshak and Gurevich, Tanya and Manor, Yael and Naor, Stav and Diamant, Noa and Opher, Irit},
  booktitle={Interspeech},
  pages={2498--2502},
  year={2019}
}

@inproceedings{botelho2019speech,
  title={Speech as a biomarker for obstructive sleep apnea detection},
  author={Botelho, M Catarina and Trancoso, Isabel and Abad, Alberto and Paiva, Teresa},
  booktitle={ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5851--5855},
  year={2019},
  organization={IEEE}
}

@article{pompili2020inesc,
  title={The INESC-ID multi-modal system for the ADReSS 2020 challenge},
  author={Pompili, Anna and Rolland, Thomas and Abad, Alberto},
  journal={arXiv preprint arXiv:2005.14646},
  year={2020}
}

@article{bizzocchi2017many,
  title={How many phonemes does the English language have?},
  author={Bizzocchi, Aldo Luiz},
  journal={International Journal on Studies in English Language and Literature (IJSELL)},
  volume={5},
  number={10},
  pages={36--46},
  year={2017}
}

@article{benzeghiba2007automatic,
  title={Automatic speech recognition and speech variability: A review},
  author={Benzeghiba, Mohamed and De Mori, Renato and Deroo, Olivier and Dupont, Stephane and Erbes, Teodora and Jouvet, Denis and Fissore, Luciano and Laface, Pietro and Mertins, Alfred and Ris, Christophe and others},
  journal={Speech communication},
  volume={49},
  number={10-11},
  pages={763--786},
  year={2007},
  publisher={Elsevier}
}

@article{arora2012automatic,
  title={Automatic speech recognition: a review},
  author={Arora, Shipra J and Singh, Rishi Pal},
  journal={International Journal of Computer Applications},
  volume={60},
  number={9},
  year={2012},
  publisher={Foundation of Computer Science}
}

@article{karpagavalli2016review,
  title={A review on automatic speech recognition architecture and approaches},
  author={Karpagavalli, S and Chandra, Edy},
  journal={International Journal of Signal Processing, Image Processing and Pattern Recognition},
  volume={9},
  number={4},
  pages={393--404},
  year={2016}
}

@book{bourlard2012connectionist,
  title={Connectionist speech recognition: a hybrid approach},
  author={Bourlard, Herve A and Morgan, Nelson},
  volume={247},
  year={2012},
  publisher={Springer Science \& Business Media}
}
@inproceedings{meinedo2003audimus,
  title={AUDIMUS. media: a Broadcast News speech recognition system for the European Portuguese language},
  author={Meinedo, Hugo and Caseiro, Diamantino and Neto, Joao and Trancoso, Isabel},
  booktitle={International Workshop on Computational Processing of the Portuguese Language},
  pages={9--17},
  year={2003},
  organization={Springer}
}


@article{fan2022draft,
  title={DRAFT: A Novel Framework to Reduce Domain Shifting in Self-supervised Learning and Its Application to Children's ASR},
  author={Fan, Ruchao and Alwan, Abeer},
  journal={arXiv preprint arXiv:2206.07931},
  year={2022}
}

@article{shivakumar2020transfer,
  title={Transfer learning from adult to children for speech recognition: Evaluation, analysis and recommendations},
  author={Shivakumar, Prashanth Gurunath and Georgiou, Panayiotis},
  journal={Computer speech \& language},
  volume={63},
  pages={101077},
  year={2020},
  publisher={Elsevier}
}

@article{langbecker2020long,
  title={Long-term effects of childhood speech and language disorders: A scoping review},
  author={Langbecker, Danette and Snoswell, Centaine L and Smith, Anthony C and Verboom, Jedidja and Caffery, Liam J},
  journal={South African Journal of Childhood Education},
  volume={10},
  number={1},
  pages={1--13},
  year={2020},
  publisher={AOSIS Publishing}
}
@article{black2015communication,
  title={Communication Disorders and Use of Intervention Services among Children Aged 3--17 Years: United States, 2012; US Department of Health and Human Services, Centers for Disease Control and Prevention},
  author={Black, LI and Vahratian, A and Hoffman, HJ},
  journal={National Center for Health Statistics: Atlanta, GA, USA},
  year={2015}
}
@book{levelt1993speaking,
  title={Speaking: From intention to articulation},
  author={Levelt, Willem JM},
  year={1993},
  publisher={MIT press}
}

@article{hughes2019increasing,
  title={Increasing access to rural mental health care using hybrid care that includes telepsychiatry.},
  author={Hughes, M Courtney and Gorman, Jack M and Ren, Yingqian and Khalid, Sana and Clayton, Carol},
  journal={Journal of Rural Mental Health},
  volume={43},
  number={1},
  pages={30},
  year={2019},
  publisher={Educational Publishing Foundation}
}

@article{barnett2011utilizing,
  title={Utilizing technological innovations to enhance psychotherapy supervision, training, and outcomes.},
  author={Barnett, Jeffrey E},
  journal={Psychotherapy},
  volume={48},
  number={2},
  pages={103},
  year={2011},
  publisher={Educational Publishing Foundation}
}
@article{hilty2015new,
  title={New frontiers in healthcare and technology: Internet-and web-based mental options emerge to complement in-person and telepsychiatric care options},
  author={Hilty, DM and Chan, S and Torous, J and Mahautmr, J and Mucic, DM},
  journal={J Health Med Informatics},
  volume={6},
  number={4},
  pages={1--14},
  year={2015}
}

@phdthesis{mendoza2022added,
  title={The added value of speech technology in clinical care of patients with dysarthria},
  author={Mendoza Ramos, Viviana},
  year={2022},
  school={University of Antwerp}
}

@inproceedings{brewer2013using,
  title={Using gamification to motivate children to complete empirical studies in lab environments},
  author={Brewer, Robin and Anthony, Lisa and Brown, Quincy and Irwin, Germaine and Nias, Jaye and Tate, Berthel},
  booktitle={Proceedings of the 12th international conference on interaction design and children},
  pages={388--391},
  year={2013}
}

@article{li2023asr,
  title={ASR and Emotional Speech: A Word-Level Investigation of the Mutual Impact of Speech and Emotion Recognition},
  author={Li, Yuanchao and Zhao, Zeyu and Klejch, Ondrej and Bell, Peter and Lai, Catherine},
  journal={arXiv preprint arXiv:2305.16065},
  year={2023}
}

@article{li2014overview,
  title={An overview of noise-robust automatic speech recognition},
  author={Li, Jinyu and Deng, Li and Gong, Yifan and Haeb-Umbach, Reinhold},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={22},
  number={4},
  pages={745--777},
  year={2014},
  publisher={IEEE}
}

@article{king2017robust,
  title={Robust speech recognition via anchor word representations},
  author={King, Brian and Chen, I-Fan and Vaizman, Yonatan and Liu, Yuzong and Maas, Roland and Parthasarathi, Sree Hari Krishnan and Hoffmeister, Bj{\"o}rn},
  year={2017}
}

@book{moats2000speech,
  title={Speech to print: Language essentials for teachers},
  author={Moats, Louisa Cook and Brady, Susan},
  year={2000},
  publisher={Paul H. Brookes Pub.}
}

@article{clark1977psychology,
  title={Psychology and language},
  author={Clark, Herbert H and Clark, Eve V},
  year={1977},
  publisher={Harcourt Brace Jovanovich New York}
}

@inproceedings{radford2023robust,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={28492--28518},
  year={2023},
  organization={PMLR}
}

@article{chen2021gigaspeech,
  title={Gigaspeech: An evolving, multi-domain asr corpus with 10,000 hours of transcribed audio},
  author={Chen, Guoguo and Chai, Shuzhou and Wang, Guanbo and Du, Jiayu and Zhang, Wei-Qiang and Weng, Chao and Su, Dan and Povey, Daniel and Trmal, Jan and Zhang, Junbo and others},
  journal={arXiv preprint arXiv:2106.06909},
  year={2021}
}
@article{khanzadi2022persian,
  title={Persian phoneme and syllable recognition using recurrent neural networks for phonological awareness assessment},
  author={Khanzadi, Maryam and Veisi, Hadi and Alinaghizade, Roghaye and Soleymani, Zahra},
  journal={Journal of AI and Data Mining},
  volume={10},
  number={1},
  pages={117--126},
  year={2022},
  publisher={Shahrood University of Technology}
}
@article{klatt1977review,
  title={Review of the ARPA speech understanding project},
  author={Klatt, Dennis H},
  journal={The Journal of the Acoustical Society of America},
  volume={62},
  number={6},
  pages={1345--1366},
  year={1977},
  publisher={Acoustical Society of America}
}

@inproceedings{kiktova2013comparison,
  title={Comparison of different feature types for acoustic event detection system},
  author={Kiktova, Eva and Lojka, Martin and Pleva, Matus and Juhar, Jozef and Cizmar, Anton},
  booktitle={Multimedia Communications, Services and Security: 6th International Conference, MCSS 2013, Krakow, Poland, June 6-7, 2013. Proceedings 6},
  pages={288--297},
  year={2013},
  organization={Springer}
}
@article{weide1998carnegie,
  title={The carnegie mellon pronouncing dictionary},
  author={Weide, Robert and others},
  journal={release 0.6, www. cs. cmu. edu},
  year={1998}
}

@inproceedings{schwartz1985context,
  title={Context-dependent modeling for acoustic-phonetic recognition of continuous speech},
  author={Schwartz, Richard and Chow, YL and Kimball, Owen and Roucos, S and Krasner, M and Makhoul, John},
  booktitle={ICASSP'85. IEEE International Conference on Acoustics, Speech, and Signal Processing},
  volume={10},
  pages={1205--1208},
  year={1985},
  organization={IEEE}
}

@inproceedings{bahl1991context,
  title={Context dependent modeling of phones in continuous speech using decision trees},
  author={Bahl, Lalit R and deSouza, Peter V and Gopalakrishnan, PS and Nahamoo, David and Picheny, MA},
  booktitle={Speech and Natural Language: Proceedings of a Workshop Held at Pacific Grove, California, February 19-22, 1991},
  year={1991}
}

@article{sak2014long,
  title={Long short-term memory recurrent neural network architectures for large scale acoustic modeling},
  author={Sak, Hasim and Senior, Andrew W and Beaufays, Fran{\c{c}}oise},
  year={2014}
}
@article{lang1990time,
  title={A time-delay neural network architecture for isolated word recognition},
  author={Lang, Kevin J and Waibel, Alex H and Hinton, Geoffrey E},
  journal={Neural networks},
  volume={3},
  number={1},
  pages={23--43},
  year={1990},
  publisher={Elsevier}
}
@incollection{waibel2013phoneme,
  title={Phoneme recognition using time-delay neural networks},
  author={Waibel, Alexander and Hanazawa, Toshiyuki and Hinton, Geoffrey and Shikano, Kiyohiro and Lang, Kevin J},
  booktitle={Backpropagation},
  pages={35--61},
  year={2013},
  publisher={Psychology Press}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@inproceedings{richardson1995lattice,
  title={Lattice-based search strategies for large vocabulary speech recognition},
  author={Richardson, Frederick and Ostendorf, Mari and Rohlicek, Jan Robin},
  booktitle={1995 International Conference on Acoustics, Speech, and Signal Processing},
  volume={1},
  pages={576--579},
  year={1995},
  organization={IEEE}
}

@article{tuske2021limit,
  title={On the limit of English conversational speech recognition},
  author={T{\"u}ske, Zolt{\'a}n and Saon, George and Kingsbury, Brian},
  journal={arXiv preprint arXiv:2105.00982},
  year={2021}
}
@article{bermuth2021scribosermo,
  title={Scribosermo: fast speech-to-text models for German and other languages},
  author={Bermuth, Daniel and Poeppel, Alexander and Reif, Wolfgang},
  journal={arXiv preprint arXiv:2110.07982},
  year={2021}
}

@article{chan2021speechstew,
  title={Speechstew: Simply mix all available speech recognition data to train one large neural network},
  author={Chan, William and Park, Daniel and Lee, Chris and Zhang, Yu and Le, Quoc and Norouzi, Mohammad},
  journal={arXiv preprint arXiv:2104.02133},
  year={2021}
}
@inproceedings{ghai2009exploring,
  title={Exploring the role of spectral smoothing in context of children's speech recognition},
  author={Ghai, Shweta and Sinha, Rohit},
  booktitle={Tenth Annual Conference of the International Speech Communication Association},
  year={2009}
}

@phdthesis{ghai2011addressing,
  title={Addressing pitch mismatch for children's automatic speech recognition},
  author={Ghai, Shweta},
  year={2011}
}

@inproceedings{claus2013survey,
  title={A Survey about ASR for Children},
  author={Claus, Felix and Gamboa Rosales, Hamurabi and Petrick, Rico and Hain, Horst-Udo and Hoffmann, R{\"u}diger},
  booktitle={Speech and Language Technology in Education},
  year={2013}
}

@inproceedings{potamianos1997automatic,
  title={Automatic speech recognition for children},
  author={Potamianos, Alexandros and Narayanan, Shrikanth and Lee, Sungbok},
  booktitle={Fifth European Conference on Speech Communication and Technology},
  year={1997}
}
@inproceedings{potamianos1997combining,
  title={On combining frequency warping and spectral shaping in HMM based speech recognition},
  author={Potamianos, Alexandros and Rose, Richard C},
  booktitle={1997 IEEE International Conference on Acoustics, Speech, and Signal Processing},
  volume={2},
  pages={1275--1278},
  year={1997},
  organization={IEEE}
}

@inproceedings{shahnawazuddin2023gammatone,
  title={Gammatone-Filterbank Based Pitch-Normalized Cepstral Coefficients for Zero-Resource Children’s ASR},
  author={Shahnawazuddin, Syed and Ankita and Kumar, Avinash and Kathania, Hemant Kumar},
  booktitle={International Conference on Speech and Computer},
  pages={494--505},
  year={2023},
  organization={Springer}
}

@inproceedings{kumar2023effect,
  title={Effect of Linear Prediction Order to Modify Formant Locations for Children Speech Recognition},
  author={Kumar, Udara Laxman and Kurimo, Mikko and Kathania, Hemant Kumar},
  booktitle={International Conference on Speech and Computer},
  pages={483--493},
  year={2023},
  organization={Springer}
}

@article{kadyan2023prosody,
  title={Prosody features based low resource Punjabi children ASR and T-NT classifier using data augmentation},
  author={Kadyan, Virender and Hasija, Taniya and Singh, Amitoj},
  journal={Multimedia Tools and Applications},
  volume={82},
  number={3},
  pages={3973--3994},
  year={2023},
  publisher={Springer}
}

@inproceedings{gale2019improving,
  title={Improving asr systems for children with autism and language impairment using domain-focused dnn transfer techniques},
  author={Gale, Robert and Chen, Liu and Dolata, Jill and Van Santen, Jan and Asgari, Meysam},
  booktitle={Interspeech},
  volume={2019},
  pages={11},
  year={2019},
  organization={NIH Public Access}
}

@article{bhardwaj2022automatic,
  title={Automatic speech recognition (asr) systems for children: A systematic literature review},
  author={Bhardwaj, Vivek and Ben Othman, Mohamed Tahar and Kukreja, Vinay and Belkhier, Youcef and Bajaj, Mohit and Goud, B Srikanth and Rehman, Ateeq Ur and Shafiq, Muhammad and Hamam, Habib},
  journal={Applied Sciences},
  volume={12},
  number={9},
  pages={4419},
  year={2022},
  publisher={MDPI}
}

@article{kumar2020leveraging,
  title={Leveraging linguistic context in dyadic interactions to improve automatic speech recognition for children},
  author={Kumar, Manoj and Kim, So Hyun and Lord, Catherine and Lyon, Thomas D and Narayanan, Shrikanth},
  journal={Computer speech \& language},
  volume={63},
  pages={101101},
  year={2020},
  publisher={Elsevier}
}

@article{chan2015listen,
  title={Listen, attend and spell},
  author={Chan, William and Jaitly, Navdeep and Le, Quoc V and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1508.01211},
  year={2015}
}

@article{targ2016resnet,
  title={Resnet in resnet: Generalizing residual architectures},
  author={Targ, Sasha and Almeida, Diogo and Lyman, Kevin},
  journal={arXiv preprint arXiv:1603.08029},
  year={2016}
}

@article{shuyangdata,
  title={Data augmentation for children ASR and child-adult speaker classification using voice conversion methods},
  author={Shuyang, Zhao and Singh, Mittul and Woubie, Abraham and Karhila, Reima}
}

@article{dua2022spectral,
  title={Spectral warping and data augmentation for low resource language ASR system under mismatched conditions},
  author={Dua, Mohit and Kadyan, Virender and Banthia, Neha and Bansal, Akshit and Agarwal, Tanya},
  journal={Applied Acoustics},
  volume={190},
  pages={108643},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{nagano2019data,
  title={Data augmentation based on vowel stretch for improving children's speech recognition},
  author={Nagano, Tohru and Fukuda, Takashi and Suzuki, Masayuki and Kurata, Gakuto},
  booktitle={2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={502--508},
  year={2019},
  organization={IEEE}
}

@inproceedings{yeung2021fundamental,
  title={Fundamental frequency feature normalization and data augmentation for child speech recognition},
  author={Yeung, Gary and Fan, Ruchao and Alwan, Abeer},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6993--6997},
  year={2021},
  organization={IEEE}
}
@article{singh2022spectral,
  title={Spectral Modification Based Data Augmentation For Improving End-to-End ASR For Children's Speech},
  author={Singh, Vishwanath Pratap and Sailor, Hardik and Bhattacharya, Supratik and Pandey, Abhishek},
  journal={arXiv preprint arXiv:2203.06600},
  year={2022}
}

@article{lo2020ntnu,
  title={The NTNU system at the interspeech 2020 non-native Children's speech ASR challenge},
  author={Lo, Tien-Hong and Chao, Fu-An and Weng, Shi-Yan and Chen, Berlin},
  journal={arXiv preprint arXiv:2005.08433},
  year={2020}
}

@inproceedings{ma2006unsupervised,
  title={Unsupervised training on large amounts of broadcast news data},
  author={Ma, Jeff and Matsoukas, Spyros and Kimball, Owen and Schwartz, Richard},
  booktitle={2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings},
  volume={3},
  pages={III--III},
  year={2006},
  organization={IEEE}
}

@inproceedings{zavaliagkos1998utilizing,
  title={Utilizing untranscribed training data to improve perfomance.},
  author={Zavaliagkos, George and Colthurst, Thomas},
  booktitle={LREC},
  pages={317--322},
  year={1998},
  organization={Citeseer}
}

@inproceedings{henaff2020data,
  title={Data-efficient image recognition with contrastive predictive coding},
  author={Henaff, Olivier},
  booktitle={International conference on machine learning},
  pages={4182--4192},
  year={2020},
  organization={PMLR}
}

@article{sarzynska2021detecting,
  title={Detecting formal thought disorder by deep contextualized word representations},
  author={Sarzynska-Wawer, Justyna and Wawer, Aleksander and Pawlak, Aleksandra and Szymanowska, Julia and Stefaniak, Izabela and Jarkiewicz, Michal and Okruszek, Lukasz},
  journal={Psychiatry Research},
  volume={304},
  pages={114135},
  year={2021},
  publisher={Elsevier}
}
@inproceedings{riviere2020unsupervised,
  title={Unsupervised pretraining transfers well across languages},
  author={Riviere, Morgane and Joulin, Armand and Mazar{\'e}, Pierre-Emmanuel and Dupoux, Emmanuel},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7414--7418},
  year={2020},
  organization={IEEE}
}

@inproceedings{wang2022wav2vec,
  title={Wav2vec-switch: Contrastive learning from original-noisy speech pairs for robust speech recognition},
  author={Wang, Yiming and Li, Jinyu and Wang, Heming and Qian, Yao and Wang, Chengyi and Wu, Yu},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7097--7101},
  year={2022},
  organization={IEEE}
}

@article{li2021accent,
  title={Accent-robust automatic speech recognition using supervised and unsupervised wav2vec embeddings},
  author={Li, Jialu and Manohar, Vimal and Chitkara, Pooja and Tjandra, Andros and Picheny, Michael and Zhang, Frank and Zhang, Xiaohui and Saraf, Yatharth},
  journal={arXiv preprint arXiv:2110.03520},
  year={2021}
}

@inproceedings{xu2021tal,
  title={The TAL System for the INTERSPEECH2021 Shared Task on Automatic Speech Recognition for Non-Native Childrens Speech.},
  author={Xu, Gaopeng and Yang, Song and Ma, Lu and Li, Chengfei and Wu, Zhongqin},
  booktitle={Interspeech},
  pages={1294--1298},
  year={2021}
}

@article{jain2023wav2vec2,
  title={A Wav2Vec2-Based Experimental Study On Self-Supervised Learning Methods To Improve Child Speech Recognition.},
  author={Jain, Rishabh and Barcovschi, Andrei and Yiwere, Mariam and Bigioi, Dan and Corcoran, Peter and Cucu, Horia},
  journal={IEEE Access},
  year={2023},
  publisher={IEEE}
}

@article{jain2023adaptation,
  title={Adaptation of Whisper models to child speech recognition},
  author={Jain, Rishabh and Barcovschi, Andrei and Yiwere, Mariam and Corcoran, Peter and Cucu, Horia},
  journal={arXiv preprint arXiv:2307.13008},
  year={2023}
}

@inproceedings{yeung2019robotic,
  title={A robotic interface for the administration of language, literacy, and speech pathology assessments for children.},
  author={Yeung, Gary and Bailey, Alison L and Afshan, Amber and Tinkler, Morgan and P{\'e}rez, Marlen Q and Martin, Alejandra and Pogossian, Anahit A and Spaulding, Samuel and Park, Hae Won and Muco, Manushaqe and others},
  booktitle={SLaTE},
  pages={41--42},
  year={2019}
}

@inproceedings{yu2021slt,
  title={The SLT 2021 children speech recognition challenge: Open datasets, rules and baselines},
  author={Yu, Fan and Yao, Zhuoyuan and Wang, Xiong and An, Keyu and Xie, Lei and Ou, Zhijian and Liu, Bo and Li, Xiulin and Miao, Guanqiong},
  booktitle={2021 IEEE Spoken Language Technology Workshop (SLT)},
  pages={1117--1123},
  year={2021},
  organization={IEEE}
}

@inproceedings{bahrini2023chatgpt,
  title={ChatGPT: Applications, opportunities, and threats},
  author={Bahrini, Aram and Khamoshifar, Mohammadsadra and Abbasimehr, Hossein and Riggs, Robert J and Esmaeili, Maryam and Majdabadkohne, Rastin Mastali and Pasehvar, Morteza},
  booktitle={2023 Systems and Information Engineering Design Symposium (SIEDS)},
  pages={274--279},
  year={2023},
  organization={IEEE}
}

@inproceedings{ramesh2021zero,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={8821--8831},
  year={2021},
  organization={PMLR}
}

@article{wu2020lite,
  title={Lite transformer with long-short range attention},
  author={Wu, Zhanghao and Liu, Zhijian and Lin, Ji and Lin, Yujun and Han, Song},
  journal={arXiv preprint arXiv:2004.11886},
  year={2020}
}

@inproceedings{dauphin2017language,
  title={Language modeling with gated convolutional networks},
  author={Dauphin, Yann N and Fan, Angela and Auli, Michael and Grangier, David},
  booktitle={International conference on machine learning},
  pages={933--941},
  year={2017},
  organization={PMLR}
}

@article{gulati2020conformer,
  title={Conformer: Convolution-augmented transformer for speech recognition},
  author={Gulati, Anmol and Qin, James and Chiu, Chung-Cheng and Parmar, Niki and Zhang, Yu and Yu, Jiahui and Han, Wei and Wang, Shibo and Zhang, Zhengdong and Wu, Yonghui and others},
  journal={arXiv preprint arXiv:2005.08100},
  year={2020}
}
@inproceedings{bello2019attention,
  title={Attention augmented convolutional networks},
  author={Bello, Irwan and Zoph, Barret and Vaswani, Ashish and Shlens, Jonathon and Le, Quoc V},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={3286--3295},
  year={2019}
}
@article{yang2019convolutional,
  title={Convolutional self-attention networks},
  author={Yang, Baosong and Wang, Longyue and Wong, Derek and Chao, Lidia S and Tu, Zhaopeng},
  journal={arXiv preprint arXiv:1904.03107},
  year={2019}
}

@article{lu2019understanding,
  title={Understanding and improving transformer from a multi-particle dynamic system point of view},
  author={Lu, Yiping and Li, Zhuohan and He, Di and Sun, Zhiqing and Dong, Bin and Qin, Tao and Wang, Liwei and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:1906.02762},
  year={2019}
}

@article{frankle2018lottery,
  title={The lottery ticket hypothesis: Finding sparse, trainable neural networks},
  author={Frankle, Jonathan and Carbin, Michael},
  journal={arXiv preprint arXiv:1803.03635},
  year={2018}
}

@INPROCEEDINGS{10095837,
  author={Eeckt, Steven Vander and Van Hamme, Hugo},
  booktitle={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Using Adapters to Overcome Catastrophic Forgetting in End-to-End Automatic Speech Recognition}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  doi={10.1109/ICASSP49357.2023.10095837}}

@inproceedings{rolland2022multilingual,
    title = "Multilingual Transfer Learning for Children Automatic Speech Recognition",
    author = "Rolland, Thomas  and
      Abad, Alberto  and
      Cucchiarini, Catia  and
      Strik, Helmer", 
    booktitle = "LREC 2022",
    month = jun,
    year = "2022",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "",
    pages = "7314--7320",
    abstract = "Despite recent advances in automatic speech recognition (ASR), the recognition of children{'}s speech still remains a significant challenge. This is mainly due to the high acoustic variability and the limited amount of available training data. The latter problem is particularly evident in languages other than English, which are usually less-resourced. In the current paper, we address children ASR in a number of less-resourced languages by combining several small-sized children speech corpora from these languages. In particular, we address the following research question: Does a novel two-step training strategy in which multilingual learning is followed by language-specific transfer learning outperform conventional single language/task training for children speech, as well as multilingual and transfer learning alone? Based on previous experimental results with English, we hypothesize that multilingual learning provides a better generalization of the underlying characteristics of children{'}s speech. Our results provide a positive answer to our research question, by showing that using transfer learning on top of a multilingual model for an unseen language outperforms conventional single language-specific learning.",
}

@INPROCEEDINGS{9847929,
  author={Shraddha, S and G, Jyothish Lal and S, Sachin Kumar},
  booktitle={2022 2nd International Conference on Intelligent Technologies (CONIT)}, 
  title={Child Speech Recognition on End-to-End Neural ASR Models}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/CONIT55038.2022.9847929}}

@inproceedings{hwang2022large,
  title={Large-scale asr domain adaptation using self-and semi-supervised learning},
  author={Hwang, Dongseong and Misra, Ananya and Huo, Zhouyuan and Siddhartha, Nikhil and Garg, Shefali and Qiu, David and Sim, Khe Chai and Strohman, Trevor and Beaufays, Fran{\c{c}}oise and He, Yanzhang},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6627--6631},
  year={2022},
  organization={IEEE}
}

@inproceedings{ruckle2020adapterdrop,
    title = "{AdapterDrop}: {O}n the Efficiency of Adapters in Transformers",
    author = {R{\"u}ckl{\'e}, Andreas  and
      Geigle, Gregor  and
      Glockner, Max  and
      Beck, Tilman  and
      Pfeiffer, Jonas  and
      Reimers, Nils  and
      Gurevych, Iryna},
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.626",
    doi = "10.18653/v1/2021.emnlp-main.626",
    pages = "7930--7946",
    abstract = "Transformer models are expensive to fine-tune, slow for inference, and have large storage requirements. Recent approaches tackle these shortcomings by training smaller models, dynamically reducing the model size, and by training light-weight adapters. In this paper, we propose AdapterDrop, removing adapters from lower transformer layers during training and inference, which incorporates concepts from all three directions. We show that AdapterDrop can dynamically reduce the computational overhead when performing inference over multiple tasks simultaneously, with minimal decrease in task performances. We further prune adapters from AdapterFusion, which improves the inference efficiency while maintaining the task performances entirely.",
}

@article{chen2023efficient,
  title={Efficient Adapters for Giant Speech Models},
  author={Chen, Nanxin and Shafran, Izhak and Zhang, Yu and Chiu, Chung-Cheng and Soltau, Hagen and Qin, James and Wu, Yonghui},
  journal={arXiv preprint arXiv:2306.08131},
  year={2023}
}


@article{kulkarni2023adapting,
  title={Adapting the adapters for code-switching in multilingual ASR},
  author={Kulkarni, Atharva and Kulkarni, Ajinkya and Couceiro, Miguel and Aldarmaki, Hanan},
  journal={arXiv preprint arXiv:2310.07423},
  year={2023}
}

@article{hou2021exploiting,
  title={Exploiting adapters for cross-lingual low-resource speech recognition},
  author={Hou, Wenxin and Zhu, Han and Wang, Yidong and Wang, Jindong and Qin, Tao and Xu, Renjun and Shinozaki, Takahiro},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={30},
  pages={317--329},
  year={2021},
  publisher={IEEE}
}

@inproceedings{thomas2022efficient,
  title={Efficient adapter transfer of self-supervised speech models for automatic speech recognition},
  author={Thomas, Bethan and Kessler, Samuel and Karout, Salah},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7102--7106},
  year={2022},
  organization={IEEE}
}
@article{cappellazzo2023parameter,
  title={Parameter-Efficient Transfer Learning of Audio Spectrogram Transformers},
  author={Cappellazzo, Umberto and Falavigna, Daniele and Brutti, Alessio and Ravanelli, Mirco},
  journal={arXiv preprint arXiv:2312.03694},
  year={2023}
}

@inproceedings{kovaleva-etal-2019-revealing,
    title = "Revealing the Dark Secrets of {BERT}",
    author = "Kovaleva, Olga  and
      Romanov, Alexey  and
      Rogers, Anna  and
      Rumshisky, Anna",
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1445",
    doi = "10.18653/v1/D19-1445",
    pages = "4365--4374",
    abstract = "BERT-based architectures currently give state-of-the-art performance on many NLP tasks, but little is known about the exact mechanisms that contribute to its success. In the current work, we focus on the interpretation of self-attention, which is one of the fundamental underlying components of BERT. Using a subset of GLUE tasks and a set of handcrafted features-of-interest, we propose the methodology and carry out a qualitative and quantitative analysis of the information encoded by the individual BERT{'}s heads. Our findings suggest that there is a limited set of attention patterns that are repeated across different heads, indicating the overall model overparametrization. While different heads consistently use the same attention patterns, they have varying impact on performance across different tasks. We show that manually disabling attention in certain heads leads to a performance improvement over the regular fine-tuned BERT models.",
}

@article{michel2019sixteen,
  title={Are sixteen heads really better than one?},
  author={Michel, Paul and Levy, Omer and Neubig, Graham},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{zheng22d_interspeech,
  author={Weiyi Zheng and Alex Xiao and Gil Keren and Duc Le and Frank Zhang and Christian Fuegen and Ozlem Kalinli and Yatharth Saraf and Abdelrahman Mohamed},
  title={{Scaling ASR Improves Zero and Few Shot Learning}},
  year=2022,
  booktitle={Proc. Interspeech 2022},
  pages={5135--5139},
  doi={10.21437/Interspeech.2022-11023}
}

@article{Kaplan2020ScalingLF,
  title={Scaling Laws for Neural Language Models},
  author={Jared Kaplan and Sam McCandlish and T. J. Henighan and Tom B. Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeff Wu and Dario Amodei},
  journal={ArXiv},
  year={2020},
  volume={abs/2001.08361},
  url={https://api.semanticscholar.org/CorpusID:210861095}
}

@article{wang2021fine,
  title={A fine-tuned wav2vec 2.0/hubert benchmark for speech emotion recognition, speaker verification and spoken language understanding},
  author={Wang, Yingzhi and Boumadane, Abdelmoumene and Heba, Abdelwahab},
  journal={arXiv preprint arXiv:2111.02735},
  year={2021}
}

@misc{ye2023partial,
    title={Partial Fine-Tuning: A Successor to Full Fine-Tuning for Vision Transformers},
    author={Peng Ye and Yongqi Huang and Chongjun Tu and Minglei Li and Tao Chen and Tong He and Wanli Ouyang},
    year={2023},
    eprint={2312.15681},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
@inproceedings{shen2021partial,
  title={Partial is better than all: revisiting fine-tuning strategy for few-shot learning},
  author={Shen, Zhiqiang and Liu, Zechun and Qin, Jie and Savvides, Marios and Cheng, Kwang-Ting},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={11},
  pages={9594--9602},
  year={2021}
}

@article{Sanh2019DistilBERTAD,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Victor Sanh and Lysandre Debut and Julien Chaumond and Thomas Wolf},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.01108},
  url={https://api.semanticscholar.org/CorpusID:203626972}
}

@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}

@article{mccarley2019structured,
  title={Structured pruning of a bert-based question answering model},
  author={McCarley, JS and Chakravarti, Rishav and Sil, Avirup},
  journal={arXiv preprint arXiv:1910.06360},
  year={2019}
}

@misc{gandhi2023distilwhisper,
      title={Distil-Whisper: Robust Knowledge Distillation via Large-Scale Pseudo Labelling}, 
      author={Sanchit Gandhi and Patrick von Platen and Alexander M. Rush},
      year={2023},
      eprint={2311.00430},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{peng23c_interspeech,
  author={Yifan Peng and Yui Sudo and Shakeel Muhammad and Shinji Watanabe},
  title={{DPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models}},
  year=2023,
  booktitle={Proc. INTERSPEECH 2023},
  pages={62--66},
  doi={10.21437/Interspeech.2023-1213}
}

@inproceedings{glorot2010understanding,
  title={Understanding the difficulty of training deep feedforward neural networks},
  author={Glorot, Xavier and Bengio, Yoshua},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={249--256},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{lian2022scaling,
  title={Scaling \& shifting your features: A new baseline for efficient model tuning},
  author={Lian, Dongze and Zhou, Daquan and Feng, Jiashi and Wang, Xinchao},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={109--123},
  year={2022}
}

@inproceedings{wu2018group,
  title={Group normalization},
  author={Wu, Yuxin and He, Kaiming},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={3--19},
  year={2018}
}

@inproceedings{huang2017arbitrary,
  title={Arbitrary style transfer in real-time with adaptive instance normalization},
  author={Huang, Xun and Belongie, Serge},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1501--1510},
  year={2017}
}

@inproceedings{sun2016return,
  title={Return of frustratingly easy domain adaptation},
  author={Sun, Baochen and Feng, Jiashi and Saenko, Kate},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={30},
  number={1},
  year={2016}
}


@inproceedings{ben-zaken-etal-2022-bitfit,
    title = "{B}it{F}it: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models",
    author = "Ben Zaken, Elad  and
      Goldberg, Yoav  and
      Ravfogel, Shauli",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-short.1",
    doi = "10.18653/v1/2022.acl-short.1",
    pages = "1--9",
    abstract = "We introduce BitFit, a sparse-finetuning method where only the bias-terms of the model (or a subset of them) are being modified. We show that with small-to-medium training data, applying BitFit on pre-trained BERT models is competitive with (and sometimes better than) fine-tuning the entire model. For larger data, the method is competitive with other sparse fine-tuning methods. Besides their practical utility, these findings are relevant for the question of understanding the commonly-used process of finetuning: they support the hypothesis that finetuning is mainly about exposing knowledge induced by language-modeling training, rather than learning new task-specific linguistic knowledge.",
}

@inproceedings{fu-etal-2022-adapterbias,
    title = "{A}dapter{B}ias: Parameter-efficient Token-dependent Representation Shift for Adapters in {NLP} Tasks",
    author = "Fu, Chin-Lun  and
      Chen, Zih-Ching  and
      Lee, Yun-Ru  and
      Lee, Hung-yi",
    editor = "Carpuat, Marine  and
      de Marneffe, Marie-Catherine  and
      Meza Ruiz, Ivan Vladimir",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2022",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-naacl.199",
    doi = "10.18653/v1/2022.findings-naacl.199",
    pages = "2608--2621",
    abstract = "Transformer-based pre-trained models with millions of parameters require large storage. Recent approaches tackle this shortcoming by training adapters, but these approaches still require a relatively large number of parameters. In this study, AdapterBias, a surprisingly simple yet effective adapter architecture, is proposed. AdapterBias adds a token-dependent shift to the hidden output of transformer layers to adapt to downstream tasks with only a vector and a linear layer. Extensive experiments are conducted to demonstrate the effectiveness of AdapterBias. The experiments show that our proposed method can dramatically reduce the trainable parameters compared to the previous works with a minimal decrease in task performances compared with fine-tuned pre-trained models. We further find that AdapterBias automatically learns to assign more significant representation shifts to the tokens related to the task in consideration.",
}

@inproceedings{he2022towards,
title={Towards a Unified View of Parameter-Efficient Transfer Learning},
author={Junxian He and Chunting Zhou and Xuezhe Ma and Taylor Berg-Kirkpatrick and Graham Neubig},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=0RDcd5Axok}
}

@inproceedings{mao-etal-2022-unipelt,
    title = "{U}ni{PELT}: A Unified Framework for Parameter-Efficient Language Model Tuning",
    author = "Mao, Yuning  and
      Mathias, Lambert  and
      Hou, Rui  and
      Almahairi, Amjad  and
      Ma, Hao  and
      Han, Jiawei  and
      Yih, Scott  and
      Khabsa, Madian",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.433",
    doi = "10.18653/v1/2022.acl-long.433",
    pages = "6253--6264",
    abstract = "Recent parameter-efficient language model tuning (PELT) methods manage to match the performance of fine-tuning with much fewer trainable parameters and perform especially well when training data is limited. However, different PELT methods may perform rather differently on the same task, making it nontrivial to select the most appropriate method for a specific task, especially considering the fast-growing number of new PELT methods and tasks. In light of model diversity and the difficulty of model selection, we propose a unified framework, UniPELT, which incorporates different PELT methods as submodules and learns to activate the ones that best suit the current data or task setup via gating mechanism. On the GLUE benchmark, UniPELT consistently achieves 1 4{\%} gains compared to the best individual PELT method that it incorporates and even outperforms fine-tuning under different setups. Moreover, UniPELT generally surpasses the upper bound that takes the best performance of all its submodules used individually on each task, indicating that a mixture of multiple PELT methods may be inherently more effective than single methods.",
}

@inproceedings{muthuchamyselvaraj23_interspeech,
  author={Nithish {Muthuchamy Selvaraj} and Xiaobao Guo and Adams Kong and Bingquan Shen and Alex Kot},
  title={{Adapter Incremental Continual Learning of Efficient Audio Spectrogram Transformers}},
  year=2023,
  booktitle={Proc. INTERSPEECH 2023},
  pages={909--913},
  doi={10.21437/Interspeech.2023-1189}
}

@inproceedings{yang23p_interspeech,
  author={Li-Jen Yang and Chao-Han Huck Yang and Jen-Tzung Chien},
  title={{Parameter-Efficient Learning for Text-to-Speech Accent Adaptation}},
  year=2023,
  booktitle={Proc. INTERSPEECH 2023},
  pages={4354--4358},
  doi={10.21437/Interspeech.2023-1212}
}

@inproceedings{li2023evaluating,
  title={Evaluating Parameter-Efficient Transfer Learning Approaches on SURE Benchmark for Speech Understanding},
  author={Li, Yingting and Mehrish, Ambuj and Zhao, Shuai and Bhardwaj, Rishabh and Zadeh, Amir and Majumder, Navonil and Mihalcea, Rada and Poria, Soujanya},
  booktitle={ICASSP},
  year={2023}
}
@article{jie2022convolutional,
  title={Convolutional bypasses are better vision transformer adapters},
  author={Jie, Shibo and Deng, Zhi-Hong},
  journal={arXiv preprint arXiv:2207.07039},
  year={2022}
}

@inproceedings{hu2018squeeze,
  title={Squeeze-and-excitation networks},
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7132--7141},
  year={2018}
}

@article{pires2023one,
  title={One wide feedforward is all you need},
  author={Pires, Telmo Pessoa and Lopes, Ant{\'o}nio V and Assogba, Yannick and Setiawan, Hendra},
  journal={arXiv preprint arXiv:2309.01826},
  year={2023}
}

@inproceedings{geva2020transformer,
    title={Transformer Feed-Forward Layers Are Key-Value Memories},
    author={Geva, Mor and Schuster, Roei and Berant, Jonathan and Levy, Omer},
    booktitle = {Empirical Methods in Natural Language Processing (EMNLP)},
    year={2021},
}
@inproceedings{yang21c_interspeech,
  author={Shu-wen Yang and Po-Han Chi and Yung-Sung Chuang and Cheng-I Jeff Lai and Kushal Lakhotia and Yist Y. Lin and Andy T. Liu and Jiatong Shi and Xuankai Chang and Guan-Ting Lin and Tzu-Hsien Huang and Wei-Cheng Tseng and Ko-tik Lee and Da-Rong Liu and Zili Huang and Shuyan Dong and Shang-Wen Li and Shinji Watanabe and Abdelrahman Mohamed and Hung-yi Lee},
  title={{SUPERB: Speech Processing Universal PERformance Benchmark}},
  year=2021,
  booktitle={Proc. Interspeech 2021},
  pages={1194--1198},
  doi={10.21437/Interspeech.2021-1775}
}
@inproceedings{chang2021exploration,
  title={An exploration of self-supervised pretrained representations for end-to-end speech recognition},
  author={Chang, Xuankai and Maekaku, Takashi and Guo, Pengcheng and Shi, Jing and Lu, Yen-Ju and Subramanian, Aswin Shanmugam and Wang, Tianzi and Yang, Shu-wen and Tsao, Yu and Lee, Hung-yi and others},
  booktitle={2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={228--235},
  year={2021},
  organization={IEEE}
}

@INPROCEEDINGS{librilight,
  author={J. {Kahn} and M. {Rivière} and W. {Zheng} and E. {Kharitonov} and Q. {Xu} and P. E. {Mazaré} and J. {Karadayi} and V. {Liptchinsky} and R. {Collobert} and C. {Fuegen} and T. {Likhomanenko} and G. {Synnaeve} and A. {Joulin} and A. {Mohamed} and E. {Dupoux}},
  booktitle={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Libri-Light: A Benchmark for ASR with Limited or No Supervision}, 
  year={2020},
  pages={7669-7673},
  note = {\url{https://github.com/facebookresearch/libri-light}},
}

@article{babu2021xlsr,
      title={XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale}, 
      author={Arun Babu and Changhan Wang and Andros Tjandra and Kushal Lakhotia and Qiantong Xu and Naman Goyal and Kritika Singh and Patrick von Platen and Yatharth Saraf and Juan Pino and Alexei Baevski and Alexis Conneau and Michael Auli},
      year={2021},
      volume={abs/2111.09296},
      journal={arXiv},
}

@phdthesis{phdthesis,
author = {Gelin, Lucile},
year = {2022},
month = {02},
pages = {},
title = {Reconnaissance automatique de la parole d'enfants apprenant·e·s lecteur·ice·s en salle de classe : modélisation acoustique de phonèmes}
}

@inproceedings{mcauliffe2017montreal,
  title={Montreal forced aligner: Trainable text-speech alignment using kaldi.},
  author={McAuliffe, Michael and Socolof, Michaela and Mihuc, Sarah and Wagner, Michael and Sonderegger, Morgan},
  booktitle={Interspeech},
  volume={2017},
  pages={498--502},
  year={2017}
}

@inproceedings{laaridh17_interspeech,
  author={Imed Laaridh and Waad Ben Kheder and Corinne Fredouille and Christine Meunier},
  title={{Automatic Prediction of Speech Evaluation Metrics for Dysarthric Speech}},
  year=2017,
  booktitle={Proc. Interspeech 2017},
  pages={1834--1838},
  doi={10.21437/Interspeech.2017-1363}
}

@inproceedings{pappagari2020x,
  title={x-vectors meet emotions: A study on dependencies between emotion and speaker recognition},
  author={Pappagari, Raghavendra and Wang, Tianzi and Villalba, Jesus and Chen, Nanxin and Dehak, Najim},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7169--7173},
  year={2020},
  organization={IEEE}
}

@article{perero2019modeling,
  title={Modeling obstructive sleep apnea voices using deep neural network embeddings and domain-adversarial training},
  author={Perero-Codosero, Juan M and Espinoza-Cuadros, Fernando and Ant{\'o}n-Mart{\'\i}n, Javier and Barbero-Alvarez, Miguel A and Hern{\'a}ndez-G{\'o}mez, Luis A},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  volume={14},
  number={2},
  pages={240--250},
  year={2019},
  publisher={IEEE}
}

@article{zargarbashi2019multi,
  title={A multi-modal feature embedding approach to diagnose Alzheimer disease from spoken language},
  author={Zargarbashi, S and Babaali, Bagher},
  journal={arXiv preprint arXiv:1910.00330},
  year={2019}
}

@inproceedings{snyder2017deep,
  title={Deep neural network embeddings for text-independent speaker verification.},
  author={Snyder, David and Garcia-Romero, Daniel and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={Interspeech},
  volume={2017},
  pages={999--1003},
  year={2017}
}

@article{kenny2007joint,
  title={Joint factor analysis versus eigenchannels in speaker recognition},
  author={Kenny, Patrick and Boulianne, Gilles and Ouellet, Pierre and Dumouchel, Pierre},
  journal={IEEE Transactions on Audio, Speech, and Language Processing},
  volume={15},
  number={4},
  pages={1435--1447},
  year={2007},
  publisher={IEEE}
}
@article{reynolds2000speaker,
  title={Speaker verification using adapted Gaussian mixture models},
  author={Reynolds, Douglas A and Quatieri, Thomas F and Dunn, Robert B},
  journal={Digital signal processing},
  volume={10},
  number={1-3},
  pages={19--41},
  year={2000},
  publisher={Elsevier}
}

@article{dehak2010front,
  title={Front-end factor analysis for speaker verification},
  author={Dehak, Najim and Kenny, Patrick J and Dehak, R{\'e}da and Dumouchel, Pierre and Ouellet, Pierre},
  journal={IEEE Transactions on Audio, Speech, and Language Processing},
  volume={19},
  number={4},
  pages={788--798},
  year={2010},
  publisher={IEEE}
}

@article{hamalainen2014easr,
  title={The EASR Corpora of European Portuguese, French, Hungarian and Polish Elderly Speech},
  author={H{\"a}m{\"a}l{\"a}inen, Annika and Avelar, Jairo and Rodrigues, Silvia and Dias, J and Kolesinski, Artur and Fegy{\'o}, Tibor and N{\'e}meth, G{\'e}za and Csob{\'a}nka, Petra and Ting, K and Hewson, David},
  journal={The EASR Corpora of European Portuguese, French, Hungarian and Polish elderly speech},
  pages={1458--1464},
  year={2014},
  publisher={ELRA}
}

@article{pinto2016dysarthria,
  title={Dysarthria in individuals with Parkinson's disease: a protocol for a binational, cross-sectional, case-controlled study in French and European Portuguese (FraLusoPark)},
  author={Pinto, Serge and Cardoso, Rita and Sadat, Jasmin and Guimar{\~a}es, Isabel and Mercier, C{\'e}line and Santos, Helena and Atkinson-Clement, Cyril and Carvalho, Joana and Welby, Pauline and Oliveira, Pedro and others},
  journal={BMJ open},
  volume={6},
  number={11},
  pages={e012885},
  year={2016},
  publisher={British Medical Journal Publishing Group}
}

@inproceedings{orozco2014new,
  title={New Spanish speech corpus database for the analysis of people suffering from Parkinson's disease.},
  author={Orozco-Arroyave, Juan Rafael and Arias-Londo{\~n}o, Juli{\'a}n David and Vargas-Bonilla, Jes{\'u}s Francisco and Gonzalez-R{\'a}tiva, Mar{\'\i}a Claudia and N{\"o}th, Elmar},
  booktitle={LREC},
  pages={342--347},
  year={2014}
}
@inproceedings{pompili2017automatic,
  title={Automatic detection of parkinson’s disease: an experimental analysis of common speech production tasks used for diagnosis},
  author={Pompili, Anna and Abad, Alberto and Romano, Paolo and Martins, Isabel P and Cardoso, Rita and Santos, Helena and Carvalho, Joana and Guimaraes, Isabel and Ferreira, Joaquim J},
  booktitle={International Conference on Text, Speech, and Dialogue},
  pages={411--419},
  year={2017},
  organization={Springer}
}
@article{eyben2015geneva,
  title={The Geneva minimalistic acoustic parameter set (GeMAPS) for voice research and affective computing},
  author={Eyben, Florian and Scherer, Klaus R and Schuller, Bj{\"o}rn W and Sundberg, Johan and Andr{\'e}, Elisabeth and Busso, Carlos and Devillers, Laurence Y and Epps, Julien and Laukka, Petri and Narayanan, Shrikanth S and others},
  journal={IEEE transactions on affective computing},
  volume={7},
  number={2},
  pages={190--202},
  year={2015},
  publisher={IEEE}
}

@inproceedings{eyben2013recent,
  title={Recent developments in opensmile, the munich open-source multimedia feature extractor},
  author={Eyben, Florian and Weninger, Felix and Gross, Florian and Schuller, Bj{\"o}rn},
  booktitle={Proceedings of the 21st ACM international conference on Multimedia},
  pages={835--838},
  year={2013}
}

@article{konig2015automatic,
  title={Automatic speech analysis for the assessment of patients with predementia and Alzheimer's disease},
  author={K{\"o}nig, Alexandra and Satt, Aharon and Sorin, Alexander and Hoory, Ron and Toledo-Ronen, Orith and Derreumaux, Alexandre and Manera, Valeria and Verhey, Frans and Aalten, Pauline and Robert, Phillipe H and others},
  journal={Alzheimer's \& Dementia: Diagnosis, Assessment \& Disease Monitoring},
  volume={1},
  number={1},
  pages={112--124},
  year={2015},
  publisher={Elsevier}
}

@article{fraser2016linguistic,
  title={Linguistic features identify Alzheimer’s disease in narrative speech},
  author={Fraser, Kathleen C and Meltzer, Jed A and Rudzicz, Frank},
  journal={Journal of Alzheimer's Disease},
  volume={49},
  number={2},
  pages={407--422},
  year={2016},
  publisher={IOS Press}
}

@article{gosztolya2019identifying,
  title={Identifying mild cognitive impairment and mild Alzheimer’s disease based on spontaneous speech using ASR and linguistic features},
  author={Gosztolya, G{\'a}bor and Vincze, Veronika and T{\'o}th, L{\'a}szl{\'o} and P{\'a}k{\'a}ski, Magdolna and K{\'a}lm{\'a}n, J{\'a}nos and Hoffmann, Ildik{\'o}},
  journal={Computer Speech \& Language},
  volume={53},
  pages={181--197},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{warnita18_interspeech,
  author={Tifani Warnita and Nakamasa Inoue and Koichi Shinoda},
  title={{Detecting Alzheimer’s Disease Using Gated Convolutional Neural Network from Audio Data}},
  year=2018,
  booktitle={Proc. Interspeech 2018},
  pages={1706--1710},
  doi={10.21437/Interspeech.2018-1713}
}
@inproceedings{karlekar-etal-2018-detecting,
    title = "Detecting Linguistic Characteristics of {A}lzheimer{'}s Dementia by Interpreting Neural Models",
    author = "Karlekar, Sweta  and
      Niu, Tong  and
      Bansal, Mohit",
    editor = "Walker, Marilyn  and
      Ji, Heng  and
      Stent, Amanda",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-2110",
    doi = "10.18653/v1/N18-2110",
    pages = "701--707",
    abstract = "Alzheimer{'}s disease (AD) is an irreversible and progressive brain disease that can be stopped or slowed down with medical treatment. Language changes serve as a sign that a patient{'}s cognitive functions have been impacted, potentially leading to early diagnosis. In this work, we use NLP techniques to classify and analyze the linguistic characteristics of AD patients using the DementiaBank dataset. We apply three neural models based on CNNs, LSTM-RNNs, and their combination, to distinguish between language samples from AD and control patients. We achieve a new independent benchmark accuracy for the AD classification task. More importantly, we next interpret what these neural models have learned about the linguistic characteristics of AD patients, via analysis based on activation clustering and first-derivative saliency techniques. We then perform novel automatic pattern discovery inside activation clusters, and consolidate AD patients{'} distinctive grammar patterns. Additionally, we show that first derivative saliency can not only rediscover previous language patterns of AD patients, but also shed light on the limitations of neural models. Lastly, we also include analysis of gender-separated AD data.",
}
@book{goodglass2001bdae,
  title={BDAE: The Boston diagnostic aphasia examination},
  author={Goodglass, Harold and Kaplan, Edith and Weintraub, Sandra},
  year={2001},
  publisher={Lippincott Williams \& Wilkins Philadelphia, PA}
}

@article{luz2020alzheimer,
  title={Alzheimer's dementia recognition through spontaneous speech: The ADReSS challenge},
  author={Luz, Saturnino and Haider, Fasih and de la Fuente, Sofia and Fromm, Davida and MacWhinney, Brian},
  journal={arXiv preprint arXiv:2004.06833},
  year={2020}
}

@inproceedings{nagrani17_interspeech,
  author={Arsha Nagrani and Joon Son Chung and Andrew Zisserman},
  title={{VoxCeleb: A Large-Scale Speaker Identification Dataset}},
  year=2017,
  booktitle={Proc. Interspeech 2017},
  pages={2616--2620},
  doi={10.21437/Interspeech.2017-950}
}

@article{schuller2020interspeech,
  title={{The INTERSPEECH 2020 Computational Paralinguistics Challenge: Elderly Emotion, Breathing \& Masks}},
  author={Schuller, Bj{\"o}rn W and Batliner, Anton and Bergler, Christian and Messner, Eva-Maria and Hamilton, Antonia and Amiriparian, Shahin and Baird, Alice and Rizos, Georgios and Schmitt, Maximilian and Stappen, Lukas and others},
  journal={Proceedings INTERSPEECH. Shanghai, China: ISCA},
  year={2020}
}

@inproceedings{schuller21_interspeech,
  author={Björn W. Schuller and Anton Batliner and Christian Bergler and Cecilia Mascolo and Jing Han and Iulia Lefter and Heysem Kaya and Shahin Amiriparian and Alice Baird and Lukas Stappen and Sandra Ottl and Maurice Gerczuk and Panagiotis Tzirakis and Chloë Brown and Jagmohan Chauhan and Andreas Grammenos and Apinan Hasthanasombat and Dimitris Spathis and Tong Xia and Pietro Cicuta and Leon J.M. Rothkrantz and Joeri A. Zwerts and Jelle Treep and Casper S. Kaandorp},
  title={{The INTERSPEECH 2021 Computational Paralinguistics Challenge: COVID-19 Cough, COVID-19 Speech, Escalation and Primates}},
  year=2021,
  booktitle={Proc. Interspeech 2021},
  pages={431--435},
  doi={10.21437/Interspeech.2021-19}
}

@article{pramono2016cough,
  title={A cough-based algorithm for automatic diagnosis of pertussis},
  author={Pramono, Renard Xaviero Adhi and Imtiaz, Syed Anas and Rodriguez-Villegas, Esther},
  journal={PloS one},
  volume={11},
  number={9},
  pages={e0162128},
  year={2016},
  publisher={Public Library of Science San Francisco, CA USA}
}
@inproceedings{Hershey2017,
author={S. {Hershey} and S. {Chaudhuri} and D. P. W. {Ellis} and J. F. {Gemmeke} and A. {Jansen} and R. C. {Moore} and M. {Plakal} and D. {Platt} and R. A. {Saurous} and B. {Seybold} and M. {Slaney} and R. J. {Weiss} and K. {Wilson}},
booktitle={{2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}},
title={{CNN architectures for large-scale audio classification}},
year={2017},
volume={},
number={},
pages={131-135},
}
@inproceedings{Chloe2020,
author = {Brown, Chlo\"{e} and Chauhan, Jagmohan and Grammenos, Andreas and Han, Jing and Hasthanasombat, Apinan and Spathis, Dimitris and Xia, Tong and Cicuta, Pietro and Mascolo, Cecilia},
title = {{Exploring Automatic Diagnosis of COVID-19 from Crowdsourced Respiratory Sound Data}},
year = {2020},
isbn = {9781450379984},
doi = {10.1145/3394486.3412865},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
pages = {3474–3484},
numpages = {11},
keywords = {covid-19, coughing, crowdsourcing platform, audio analysis, breathing},
address = {Virtual Event, CA, USA},
}

@article{Bagad2020,
title={{Cough Against COVID: Evidence of COVID-19 Signature in Cough Sounds}},
author={Piyush Bagad and Aman Dalmia and Jigar Doshi and Arsha Nagrani and Parag Bhamare and Amrita Mahale and Saurabh Rane and Neeraj Agarwal and Rahul Panicker},
year={2020},
journal = {preprint arXiv:2009.08790},
eprint={2009.08790},
archivePrefix={arXiv},
primaryClass={cs.SD},
}

@article{Imran2020,
title = {{AI4COVID-19: AI enabled preliminary diagnosis for COVID-19 from cough samples via an app}},
journal = {Informatics in Medicine Unlocked},
volume = {20},
pages = {100378},
year = {2020},
issn = {2352-9148},
author = {Ali Imran and Iryna Posokhova and Haneya N. Qureshi and Usama Masood and Muhammad Sajid Riaz and Kamran Ali and Charles N. John and MD Iftikhar Hussain and Muhammad Nabeel},
}

@article{Chaudhari2021,
title={{Virufy: Global Applicability of Crowdsourced and Clinical Datasets for AI Detection of COVID-19 from Cough}}, 
author={Gunvant Chaudhari and Xinyi Jiang and Ahmed Fakhry and Asriel Han and Jaclyn Xiao and Sabrina Shen and Amil Khanzada},
year={2021},
eprint={2011.13320},
archivePrefix={arXiv},
primaryClass={cs.SD},
journal = {preprint arXiv:2011.13320},
}

@inproceedings{Han2021,
  author={Han, Jing and Brown, Chloë and Chauhan, Jagmohan and Grammenos, Andreas and Hasthanasombat, Apinan and Spathis, Dimitris and Xia, Tong and Cicuta, Pietro and Mascolo, Cecilia},
  booktitle={2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={{Exploring Automatic COVID-19 Diagnosis via Voice and Symptoms from Crowdsourced Data}}, 
  year={2021},
  volume={},
  number={},
  pages={8328-8332},
  doi={10.1109/ICASSP39728.2021.9414576}
}

@article{Orlandic2020,
title={{The COUGHVID crowdsourcing dataset: A corpus for the study of large-scale cough analysis algorithms}}, 
author={Lara Orlandic and Tomas Teijeiro and David Atienza},
year={2020},
eprint={2009.11644},
archivePrefix={arXiv},
primaryClass={cs.SD},
journal = {preprint arXiv:2009.11644},
}

@article{villalbaSRE182020,
author = {Jesús Villalba and Nanxin Chen and David Snyder and Daniel Garcia-Romero and Alan McCree and Gregory Sell and Jonas Borgstrom and Leibny Paola García-Perera and Fred Richardson and Réda Dehak and Pedro A. Torres-Carrasquillo and Najim Dehak},
title = {{State-of-the-art speaker recognition with neural network embeddings in NIST SRE18 and Speakers in the Wild evaluations}},
journal = {{Computer Speech \& Language}},
volume = {60},
pages = {101026},
year = {2020},
issn = {0885-2308},
}

@inproceedings{Simonyan2015,
author = {Karen Simonyan and Andrew Zisserman},
title = {{Very Deep Convolutional Networks for Large-Scale Image Recognition}},
booktitle = {{3rd International Conference on Learning Representations, ICLR 2015}},
address = {San Diego, CA, USA},
year = {2015},
}

@inproceedings{Pascual2019,
  author={Santiago Pascual and Mirco Ravanelli and Joan Serrà and Antonio Bonafonte and Yoshua Bengio},
  title={{Learning Problem-Agnostic Speech Representations from Multiple Self-Supervised Tasks}},
  year=2019,
  booktitle={Proceedings of Interspeech 2019},
  pages={161--165},
  address = {Graz, Austria}
}  %url={http://dx.doi.org/10.21437/Interspeech.2019-2605}

@inproceedings{Ravanelli2020,
  author={Ravanelli, Mirco and Zhong, Jianyuan and Pascual, Santiago and Swietojanski, Pawel and Monteiro, Joao and Trmal, Jan and Bengio, Yoshua},
  booktitle={{2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}}, 
  title={{Multi-Task Self-Supervised Learning for Robust Speech Recognition}}, 
  year={2020},
  volume={},
  number={},
  pages={6989-6993},
  doi={10.1109/ICASSP40776.2020.9053569}
}
@inproceedings{SoleraUrea2021TransferLC,
  title={Transfer Learning-Based Cough Representations for Automatic Detection of COVID-19},
  author={Rub{\'e}n Solera-Ure{\~n}a and Catarina Botelho and Francisco Teixeira and Thomas Rolland and Alberto Abad and Isabel Trancoso},
  booktitle={Interspeech},
  year={2021},
  url={https://api.semanticscholar.org/CorpusID:237489901}
}

@inproceedings{casanova2022asr,
  author={Edresson Casanova and Christopher Shulby and Alexander Korolev and Arnaldo Candido Junior and Anderson da Silva Soares and Sandra Aluísio and Moacir Antonelli Ponti},
  title={{ASR data augmentation in low-resource settings using cross-lingual multi-speaker TTS and cross-lingual voice conversion}},
  year=2023,
  booktitle={Proc. INTERSPEECH 2023},
  pages={1244--1248},
  doi={10.21437/Interspeech.2023-496}
}
@INPROCEEDINGS{9688218,
  author={Ueno, Sei and Mimura, Masato and Sakai, Shinsuke and Kawahara, Tatsuya},
  booktitle={2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)}, 
  title={Data Augmentation for ASR Using TTS Via a Discrete Representation}, 
  year={2021},
  volume={},
  number={},
  pages={68-75},
  doi={10.1109/ASRU51503.2021.9688218}}


@inproceedings{fazel21_interspeech,
  author={Amin Fazel and Wei Yang and Yulan Liu and Roberto Barra-Chicote and Yixiong Meng and Roland Maas and Jasha Droppo},
  title={{SynthASR: Unlocking Synthetic Data for Speech Recognition}},
  year=2021,
  booktitle={Proc. Interspeech 2021},
  pages={896--900},
  doi={10.21437/Interspeech.2021-1882}
}


@InProceedings{casanova2022yourtts,
  title = 	 {{Y}our{TTS}: Towards Zero-Shot Multi-Speaker {TTS} and Zero-Shot Voice Conversion for Everyone},
  author =       {Casanova, Edresson and Weber, Julian and Shulby, Christopher D and Junior, Arnaldo Candido and G{\"o}lge, Eren and Ponti, Moacir A},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {2709--2720},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/casanova22a/casanova22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/casanova22a.html},
  abstract = 	 {YourTTS brings the power of a multilingual approach to the task of zero-shot multi-speaker TTS. Our method builds upon the VITS model and adds several novel modifications for zero-shot multi-speaker and multilingual training. We achieved state-of-the-art (SOTA) results in zero-shot multi-speaker TTS and results comparable to SOTA in zero-shot voice conversion on the VCTK dataset. Additionally, our approach achieves promising results in a target language with a single-speaker dataset, opening possibilities for zero-shot multi-speaker TTS and zero-shot voice conversion systems in low-resource languages. Finally, it is possible to fine-tune the YourTTS model with less than 1 minute of speech and achieve state-of-the-art results in voice similarity and with reasonable quality. This is important to allow synthesis for speakers with a very different voice or recording characteristics from those seen during training.}
}

@inproceedings{45819,title	= {Density estimation using Real NVP},author	= {Laurent Dinh and Jascha Sohl-Dickstein and Samy Bengio},year	= {2017},URL	= {https://arxiv.org/abs/1605.08803}}

@inproceedings{45774,title	= {WaveNet: A Generative Model for Raw Audio},author	= {Aäron van den Oord and Sander Dieleman and Heiga Zen and Karen Simonyan and Oriol Vinyals and Alexander Graves and Nal Kalchbrenner and Andrew Senior and Koray Kavukcuoglu},year	= {2016},URL	= {https://arxiv.org/abs/1609.03499},booktitle	= {Arxiv}}

@misc{heo2020clova,
      title={Clova Baseline System for the VoxCeleb Speaker Recognition Challenge 2020}, 
      author={Hee Soo Heo and Bong-Jin Lee and Jaesung Huh and Joon Son Chung},
      year={2020},
      eprint={2009.14153},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}

@article{kong2020hifi,
  title={Hifi-gan: Generative adversarial networks for efficient and high fidelity speech synthesis},
  author={Kong, Jungil and Kim, Jaehyeon and Bae, Jaekyoung},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={17022--17033},
  year={2020}
}

@article{veaux2016superseded,
  title={Superseded-cstr vctk corpus: English multi-speaker corpus for cstr voice cloning toolkit},
  author={Veaux, Christophe and Yamagishi, Junichi and MacDonald, Kirsten and others},
  year={2016}
}

@article{casanova2022tts,
  title={TTS-Portuguese Corpus: a corpus for speech synthesis in Brazilian Portuguese},
  author={Casanova, Edresson and Junior, Arnaldo Candido and Shulby, Christopher and Oliveira, Frederico Santos de and Teixeira, Jo{\~a}o Paulo and Ponti, Moacir Antonelli and Alu{\'\i}sio, Sandra},
  journal={Language Resources and Evaluation},
  volume={56},
  number={3},
  pages={1043--1055},
  year={2022},
  publisher={Springer}
}

@misc{mailabs,
  author = {{Munich Artificial Intelligence Laboratories GmbH}},
  year = {2017},
  title = {The mailabs speech dataset – caito},
  note = {Accessed January 15, 2024.  \url{https://www.caito.de/2019/01/03/the-m-ailabs-speech-dataset/}}
}

@inproceedings{zeyer2019comparison,
  title={A comparison of transformer and lstm encoder decoder models for asr},
  author={Zeyer, Albert and Bahar, Parnia and Irie, Kazuki and Schl{\"u}ter, Ralf and Ney, Hermann},
  booktitle={2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={8--15},
  year={2019},
  organization={IEEE}
}

@inproceedings{zeineldeen2022conformer,
  title={Conformer-based hybrid ASR system for switchboard dataset},
  author={Zeineldeen, Mohammad and Xu, Jingjing and L{\"u}scher, Christoph and Michel, Wilfried and Gerstenberger, Alexander and Schl{\"u}ter, Ralf and Ney, Hermann},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7437--7441},
  year={2022},
  organization={IEEE}
}

@inproceedings{chang2022distilhubert,
  title={Distilhubert: Speech representation learning by layer-wise distillation of hidden-unit bert},
  author={Chang, Heng-Jui and Yang, Shu-wen and Lee, Hung-yi},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7087--7091},
  year={2022},
  organization={IEEE}
}

@article{liu2021tera,
  title={Tera: Self-supervised learning of transformer encoder representation for speech},
  author={Liu, Andy T and Li, Shang-Wen and Lee, Hung-yi},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={29},
  pages={2351--2366},
  year={2021},
  publisher={IEEE}
}

@article{mockingjay,
   title={Mockingjay: Unsupervised Speech Representation Learning with Deep Bidirectional Transformer Encoders},
   ISBN={9781509066315},
   url={http://dx.doi.org/10.1109/ICASSP40776.2020.9054458},
   DOI={10.1109/icassp40776.2020.9054458},
   journal={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
   publisher={IEEE},
   author={Liu, Andy T. and Yang, Shu-wen and Chi, Po-Han and Hsu, Po-chun and Lee, Hung-yi},
   year={2020},
   month={May}
}

@inproceedings{chung19_interspeech,
  author={Yu-An Chung and Wei-Ning Hsu and Hao Tang and James Glass},
  title={{An Unsupervised Autoregressive Model for Speech Representation Learning}},
  year=2019,
  booktitle={Proc. Interspeech 2019},
  pages={146--150},
  doi={10.21437/Interspeech.2019-1473}
}

@inproceedings{liu21l_interspeech,
  author={Alexander H. Liu and Yu-An Chung and James Glass},
  title={{Non-Autoregressive Predictive Coding for Learning Speech Representations from Local Dependencies}},
  year=2021,
  booktitle={Proc. Interspeech 2021},
  pages={3730--3734},
  doi={10.21437/Interspeech.2021-349}
}

@inproceedings{chi2021audio,
  title={Audio albert: A lite bert for self-supervised learning of audio representation},
  author={Chi, Po-Han and Chung, Pei-Hung and Wu, Tsung-Han and Hsieh, Chun-Cheng and Chen, Yen-Hao and Li, Shang-Wen and Lee, Hung-yi},
  booktitle={2021 IEEE Spoken Language Technology Workshop (SLT)},
  pages={344--350},
  year={2021},
  organization={IEEE}
}

@article{Prajit2017Searching,
  author       = {Prajit Ramachandran and
                  Barret Zoph and
                  Quoc V. Le},
  title        = {Searching for Activation Functions},
  journal      = {CoRR},
  volume       = {abs/1710.05941},
  year         = {2017},
  url          = {http://arxiv.org/abs/1710.05941},
  eprinttype    = {arXiv},
  eprint       = {1710.05941},
  timestamp    = {Mon, 13 Aug 2018 16:48:44 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1710-05941.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}