@inproceedings{reviewASRchildren,
author = {Gerosa, Matteo and Giuliani, Diego and Narayanan, Shrikanth and Potamianos, Alexandros},
title = {A Review of ASR Technologies for Children's Speech},
year = {2009},
isbn = {9781605586908},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1640377.1640384},
doi = {10.1145/1640377.1640384},
abstract = {In this paper, we review: (1) the acoustic and linguistic properties of children's
speech for both read and spontaneous speech, and (2) the developments in automatic
speech recognition for children with application to spoken dialogue and multimodal
dialogue system design. First, the effect of developmental changes on the absolute
values and variability of acoustic correlates is presented for read speech for children
ages 6 and up. Then, verbal child-machine spontaneous interaction is reviewed and
results from recent studies are presented. Age trends of acoustic, linguistic and
interaction parameters are discussed, such as sentence duration, filled pauses, politeness
and frustration markers, and modality usage. Some differences between child-machine
and human-human interaction are pointed out. The implications for acoustic modeling,
linguistic modeling and spoken dialogue system design for children are presented.
We conclude with a review of relevant applications of spoken dialogue technologies
for children.},
booktitle = {Proceedings of the 2nd Workshop on Child, Computer and Interaction},
articleno = {7},
numpages = {8},
keywords = {children's speech analysis, spoken dialogue, children's speech recognition},
location = {Cambridge, Massachusetts},
series = {WOCCI '09}
}

@article{Acoustic_change_children,
author = {Lee,Sungbok  and Potamianos,Alexandros  and Narayanan,Shrikanth },
title = {Acoustics of children’s speech: Developmental changes of temporal and spectral parameters},
journal = {The Journal of the Acoustical Society of America},
volume = {105},
number = {3},
pages = {1455-1468},
year = {1999},
doi = {10.1121/1.426686},

URL = { 
        https://doi.org/10.1121/1.426686
    
},
eprint = { 
        https://doi.org/10.1121/1.426686
    
}

}

@ARTICLE{childrenSpeechWorse, 
author={A. Potamianos and S. Narayanan}, 
journal={IEEE Transactions on Speech and Audio Processing}, 
title={Robust recognition of children's speech}, 
year={2003}, 
volume={11}, 
number={6}, 
pages={603-616}, 
keywords={error analysis;speech recognition;piecewise linear techniques;spectral analysis;children speech recognition;age-dependent spectral variability;age-dependent temporal variability;age-related acoustic characteristics;automatic speech recognition;frequency scaling;spectral envelope parameters;acoustic models;word error rate;speaker normalization algorithm;frequency warping;piecewise linear algorithm;phoneme-dependent algorithm;formant scaling;vocal tract normalization;Robustness;Speech recognition;Automatic speech recognition;Frequency;Speech analysis;Acoustic testing;Error analysis;Loudspeakers;Degradation;Piecewise linear techniques}, 
doi={10.1109/TSA.2003.818026}, 
ISSN={1063-6676}, 
}
@article{MyST,
  title={My Science Tutor: A Conversational Multimedia Virtual Tutor.},
  author={W. Ward and R. Cole and Daniel Bola{\~n}os and Cindy Buchenroth-Martin and Edward Svirsky and Timothy B. Weston},
  journal={Journal of Educational Psychology},
  year={2013},
  volume={105},
  pages={1115-1125}
}
@INPROCEEDINGS{librispeech,
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={ICASSP}, 
  title={Librispeech: An ASR corpus based on public domain audio books}, 
  year={2015},
  volume={},
  number={},
  pages={5206-5210},
  doi={10.1109/ICASSP.2015.7178964}}


@inproceedings{singakids,
  title={SingaKids-Mandarin: Speech Corpus of Singaporean Children Speaking Mandarin Chinese.},
  author={Chen, Nancy F and Tong, Rong and Wee, Darren and Lee, Pei Xuan and Ma, Bin and Li, Haizhou},
  booktitle={Interspeech},
  pages={1545--1549},
  year={2016}
}


@inproceedings{cslu,
  title={The OGI kids’ speech corpus and recognizers},
  author={Shobaki, Khaldoun and Hosom, John-Paul and Cole, Ronald},
  booktitle={Proc. of ICSLP},
  pages={564--567},
  year={2000}
}

@MISC{pf-star-british,
    author = {Martin Russell},
    title = {The PF-STAR British English Children’s Speech Corpus},
    year = {2006}
}
@article{cmu,
  title={The CMU kids speech corpus},
  author={Eskenazi, Maxine and Mostow, Jack and Graff, David},
  journal={Corpus of children's read speech digitized and transcribed on two CD-ROMs, with assistance from Multicom Research and David Graff. Published by the Linguistic Data Consortium, University of Pennsylvania},
  year={1997}
}

@article{segmental_duration,
author = {Knutsen,Sten  and Stromswold,Karin  and Kleinschmidt,Dave F. },
title = {Segmental duration as a cue to sentence structure},
journal = {The Journal of the Acoustical Society of America},
volume = {145},
number = {3},
pages = {1910-1910},
year = {2019},
doi = {10.1121/1.5101929},

URL = { 
        https://doi.org/10.1121/1.5101929
    
},
eprint = { 
        https://doi.org/10.1121/1.5101929
    
}

}


@article{first_vowel_study,
author = {Peterson,Gordon E.  and Barney,Harold L. },
title = {Control Methods Used in a Study of the Vowels},
journal = {The Journal of the Acoustical Society of America},
volume = {24},
number = {2},
pages = {175-184},
year = {1952},
doi = {10.1121/1.1906875},

URL = { 
        https://doi.org/10.1121/1.1906875
    
},
eprint = { 
        https://doi.org/10.1121/1.1906875
    
}

}
@inproceedings{asr-google,
title	= {Large Vocabulary Automatic Speech Recognition for Children},
author	= {Hank Liao and Golan Pundak and Olivier Siohan and Melissa Carroll and Noah Coccaro and Qi-Ming Jiang and Tara N. Sainath and Andrew Senior and Françoise Beaufays and Michiel Bacchiani},
year	= {2015},
booktitle	= {Interspeech}
}
@inproceedings{why_children_speech_no_working,
  author={Qun Li and Martin J. Russell},
  title={{Why is automatic recognition of children's speech difficult?}},
  year=2001,
  booktitle={Proc. 7th European Conference on Speech Communication and Technology (Eurospeech 2001)},
  pages={2671--2674}
}
@article{segment_definition,
author = {DAVID CRYSTAL},
year = {2004},
month = {01},
pages = {100 - 101},
title = {A Dictionary of Linguistics and Phonetics (5th edn.). Oxford: Blackwell Publishing, 2003. Pp. 508. ISBN 0 631 22664 8},
volume = {34},
journal = {Journal of the International Phonetic Association},
doi = {10.1017/S0025100304231681}
}

@article{Children_language_model,
  title={Improvements in children's speech recognition performance},
  author={SubrataKumar Das and Don Nix and Michael Picheny},
  journal={Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP '98 (Cat. No.98CH36181)},
  year={1998},
  volume={1},
  pages={433-436 vol.1}
}
@inproceedings{children_language_model2,
  title={Child automatic speech recognition for US English: child interaction with living-room-electronic-devices},
  author={Sharmistha S. Gray and Daniel Willett and Jianhua Lu and Joel Pinto and Paul Maergner and Nathan Bodenstab},
  booktitle={WOCCI},
  year={2014}
}


@inproceedings{language_children,
  title={Acoustic and language modeling for children's read speech assessment},
  author={Tulsiani, Hitesh and Swarup, Prakhar and Rao, Preeti},
  booktitle={2017 Twenty-third National Conference on Communications (NCC)},
  pages={1--6},
  year={2017},
  organization={IEEE}
}


@inproceedings{language_children2,
author = {Potamianos, Alexandros and Narayanan, Shrikanth},
year = {1998},
month = {06},
pages = {197 - 200 vol.1},
title = {Spoken dialog systems for children},
volume = {1},
isbn = {0-7803-4428-6},
booktitle={ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
doi = {10.1109/ICASSP.1998.674401}
}


@inproceedings{darpa1992,
  title={The HTK tied-state continuous speech recogniser.},
  author={Woodland, Philip C and Young, Steve J},
  booktitle={Eurospeech},
  year={1993}
}

@article{htk_book,
  title={The HTK book},
  author={Young, Steve and Evermann, Gunnar and Gales, Mark and Hain, Thomas and Kershaw, Dan and Liu, Xunying and Moore, Gareth and Odell, Julian and Ollason, Dave and Povey, Dan and others},
  journal={Cambridge university engineering department},
  volume={3},
  number={175},
  pages={12},
  year={2002}
}


@ARTICLE{hmm-dnn,
  author={Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George E. and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Sainath, Tara N. and Kingsbury, Brian},
  journal={IEEE Signal Processing Magazine}, 
  title={Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups}, 
  year={2012},
  volume={29},
  number={6},
  pages={82-97},
  doi={10.1109/MSP.2012.2205597}}
  
  
 @article{first_asr,
author = {Davis,K. H.  and Biddulph,R.  and Balashek,S. },
title = {Automatic Recognition of Spoken Digits},
journal = {The Journal of the Acoustical Society of America},
volume = {24},
number = {6},
pages = {637-642},
year = {1952},
doi = {10.1121/1.1906946},

URL = { 
        https://doi.org/10.1121/1.1906946
    
},
eprint = { 
        https://doi.org/10.1121/1.1906946
    
}

}
@ARTICLE{mfcc,
  author={Davis, S. and Mermelstein, P.},
  journal={IEEE Transactions on Acoustics, Speech, and Signal Processing}, 
  title={Comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences}, 
  year={1980},
  volume={28},
  number={4},
  pages={357-366},
  doi={10.1109/TASSP.1980.1163420}}
@ARTICLE{Dragon_system,
  author={Baker, J.},
  journal={IEEE Transactions on Acoustics, Speech, and Signal Processing}, 
  title={The DRAGON system--An overview}, 
  year={1975},
  volume={23},
  number={1},
  pages={24-29},
  doi={10.1109/TASSP.1975.1162650}}
@article{g2p,
  title={Sequence-to-sequence neural net models for grapheme-to-phoneme conversion},
  author={Yao, Kaisheng and Zweig, Geoffrey},
  journal={arXiv preprint arXiv:1506.00196},
  year={2015}
}

@article{n-grams-computational_biology,
author = {Vishnoi, Shubham and Garg, Prabha and Arora, Pooja},
title = {Physicochemical n-Grams Tool: A tool for protein physicochemical descriptor generation via Chou’s 5-step rule},
journal = {Chemical Biology \& Drug Design},
volume = {95},
number = {1},
pages = {79-86},
keywords = {descriptor generation, machine learning, n-Grams, physicochemical parameter, proteomics science},
doi = {https://doi.org/10.1111/cbdd.13617},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cbdd.13617},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cbdd.13617},
abstract = {Abstract Physicochemical n-Grams Tool (PnGT) is an open-source standalone software for calculating physicochemical descriptors of protein. PnGT was developed using the Python scripting language and developed the user interface using Tkinter. The software currently calculates 33 physicochemical descriptors along with the sequence length for the given protein primary sequence. The descriptor generated by this tool can be directly utilized as the feature vector for the development of proteomics statistical or machine learning predictive model.},
year = {2020}
}

@article{n-gram-compression,
	title = {n-{Gram}-{Based} {Text} {Compression}},
	volume = {2016},
	issn = {1687-5265},
	url = {https://doi.org/10.1155/2016/9483646},
	doi = {10.1155/2016/9483646},
	abstract = {We propose an efficient method for compressing Vietnamese text using{\textless}italic{\textgreater} n{\textless}/italic{\textgreater}-gram dictionaries. It has a significant compression ratio in comparison with those of state-of-the-art methods on the same dataset. Given a text, first, the proposed method splits it into{\textless}italic{\textgreater} n{\textless}/italic{\textgreater}-grams and then encodes them based on{\textless}italic{\textgreater} n{\textless}/italic{\textgreater}-gram dictionaries. In the encoding phase, we use a sliding window with a size that ranges from bigram to five grams to obtain the best encoding stream. Each{\textless}italic{\textgreater} n{\textless}/italic{\textgreater}-gram is encoded by two to four bytes accordingly based on its corresponding{\textless}italic{\textgreater} n{\textless}/italic{\textgreater}-gram dictionary. We collected 2.5\&\#x2009;GB text corpus from some Vietnamese news agencies to build{\textless}italic{\textgreater} n{\textless}/italic{\textgreater}-gram dictionaries from unigram to five grams and achieve dictionaries with a size of 12\&\#x2009;GB in total. In order to evaluate our method, we collected a testing set of 10 different text files with different sizes. The experimental results indicate that our method achieves compression ratio around 90\&\#x25; and outperforms state-of-the-art methods.},
	journal = {Computational Intelligence and Neuroscience},
	author = {Nguyen, Vu H. and Nguyen, Hien T. and Duong, Hieu N. and Snasel, Vaclav},
	editor = {Jo, Geun S.},
	month = nov,
	year = {2016},
	note = {Publisher: Hindawi Publishing Corporation},
	pages = {9483646},
}
@article{n-grams-NLP,
  title={Syntactic n-grams as machine learning features for natural language processing},
  author={Sidorov, Grigori and Velasquez, Francisco and Stamatatos, Efstathios and Gelbukh, Alexander and Chanona-Hern{\'a}ndez, Liliana},
  journal={Expert Systems with Applications},
  volume={41},
  number={3},
  pages={853--860},
  year={2014},
  publisher={Elsevier}
}

@misc{transformer,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2017},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{Bert,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{First_End2End,
author = {Graves, Alex and Fern\'{a}ndez, Santiago and Gomez, Faustino and Schmidhuber, J\"{u}rgen},
title = {Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks},
year = {2006},
isbn = {1595933832},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1143844.1143891},
doi = {10.1145/1143844.1143891},
abstract = {Many real-world sequence learning tasks require the prediction of sequences of labels
from noisy, unsegmented input data. In speech recognition, for example, an acoustic
signal is transcribed into words or sub-word units. Recurrent neural networks (RNNs)
are powerful sequence learners that would seem well suited to such tasks. However,
because they require pre-segmented training data, and post-processing to transform
their outputs into label sequences, their applicability has so far been limited. This
paper presents a novel method for training RNNs to label unsegmented sequences directly,
thereby solving both problems. An experiment on the TIMIT speech corpus demonstrates
its advantages over both a baseline HMM and a hybrid HMM-RNN.},
booktitle = {Proceedings of the 23rd International Conference on Machine Learning},
pages = {369–376},
numpages = {8},
location = {Pittsburgh, Pennsylvania, USA},
series = {ICML '06}
}
@ARTICLE{n-grams-smoothing,
  author={Chen, S.F. and Rosenfeld, R.},
  journal={IEEE Transactions on Speech and Audio Processing}, 
  title={A survey of smoothing techniques for ME models}, 
  year={2000},
  volume={8},
  number={1},
  pages={37-50},
  doi={10.1109/89.817452}}
  
  
  @ARTICLE{tfbased,
  author={Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Representation Learning: A Review and New Perspectives}, 
  year={2013},
  volume={35},
  number={8},
  pages={1798-1828},
  doi={10.1109/TPAMI.2013.50}}

@INPROCEEDINGS{tfpathology,
  author={Takashima, Ryoichi and Takiguchi, Tetsuya and Ariki, Yasuo},
  booktitle={ICASSP}, 
  title={Two-Step Acoustic Model Adaptation for Dysarthric Speech Recognition}, 
  year={2020},
  volume={},
  number={},
  pages={6104-6108},
  doi={10.1109/ICASSP40776.2020.9053725}}

@INPROCEEDINGS{tfcharacter,
  author={Cireşan, Dan C. and Meier, Ueli and Schmidhuber, Jürgen},
  booktitle={The 2012 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Transfer learning for Latin and Chinese characters with Deep Neural Networks}, 
  year={2012},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/IJCNN.2012.6252544}}
  
  
@article{TransferLF,
  title={Transfer learning for children's speech recognition},
  author={R. Tong and Lei Wang and B. Ma},
  journal={2017 International Conference on Asian Language Processing (IALP)},
  year={2017},
  pages={36-39}
}


@misc{TFchildren,
      title={Transfer Learning from Adult to Children for Speech Recognition: Evaluation, Analysis and Recommendations}, 
      author={Prashanth Gurunath Shivakumar and Panayiotis Georgiou},
      year={2018},
      eprint={1805.03322},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}

@misc{yosinski2014transferable,
      title={How transferable are features in deep neural networks?}, 
      author={Jason Yosinski and Jeff Clune and Yoshua Bengio and Hod Lipson},
      year={2014},
      eprint={1411.1792},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@ARTICLE{viterbi_decoder,
  author={Viterbi, A.},
  journal={IEEE Transactions on Information Theory}, 
  title={Error bounds for convolutional codes and an asymptotically optimum decoding algorithm}, 
  year={1967},
  volume={13},
  number={2},
  pages={260-269},
  doi={10.1109/TIT.1967.1054010}}
  
  @article{Hermansky1990PerceptualLP,
  title={Perceptual linear predictive (PLP) analysis of speech.},
  author={Hynek Hermansky},
  journal={The Journal of the Acoustical Society of America},
  year={1990},
  volume={87 4},
  pages={
          1738-52
        }
}

@inproceedings{VTLN,
  title={Speaker normalization using efficient frequency warping procedures},
  author={Lee, Li and Rose, Richard C},
  booktitle={1996 IEEE International Conference on Acoustics, Speech, and Signal Processing Conference Proceedings},
  volume={1},
  pages={353--356},
  year={1996},
  organization={IEEE}
}

@INPROCEEDINGS{feat_ext_from_raw,  author={Dubagunta, S. Pavankumar and Hande Kabil, Selen and Magimai.-Doss, Mathew},  booktitle={ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},   title={Improving Children Speech Recognition through Feature Learning from Raw Speech Signal},   year={2019},  volume={},  number={},  pages={5736-5740},  doi={10.1109/ICASSP.2019.8682826}}

@INPROCEEDINGS{sincnet_adapt,  author={Fainberg, Joachim and Klejch, Ondřej and Loweimi, Erfan and Bell, Peter and Renals, Steve},  booktitle={2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},   title={Acoustic Model Adaptation from Raw Waveforms with Sincnet},   year={2019},  volume={},  number={},  pages={897-904},  doi={10.1109/ASRU46091.2019.9003974}}

@misc{Sincnet,
      title={Speaker Recognition from Raw Waveform with SincNet}, 
      author={Mirco Ravanelli and Yoshua Bengio},
      year={2019},
      eprint={1808.00158},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}

@INPROCEEDINGS{ivector,
  author={Senior, Andrew and Lopez-Moreno, Ignacio},
  booktitle={ICASSP}, 
  title={Improving DNN speaker independence with I-vector inputs}, 
  year={2014},
  volume={},
  number={},
  pages={225-229},
  doi={10.1109/ICASSP.2014.6853591}}
  
  
  @INPROCEEDINGS{adversarial-adapt1,
  author={Duan, Richeng and Chen, Nancy F.},
  booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Senone-Aware Adversarial Multi-Task Training for Unsupervised Child to Adult Speech Adaptation}, 
  year={2021},
  volume={},
  number={},
  pages={7758-7762},
  doi={10.1109/ICASSP39728.2021.9413738}}
  
  @article{adversarial-adapt2,
  title={Age-Invariant Training for End-to-End Child Speech Recognition Using Adversarial Multi-Task Learning},
  author={Rumberg, Lars and Ehlert, Hanna and L{\"u}dtke, Ulrike and Ostermann, J{\"o}rn},
  journal={Proc. Interspeech 2021},
  pages={3850--3854},
  year={2021}
}

@article{f0norm,
  title={A Frequency Normalization Technique for Kindergarten Speech Recognition Inspired by the Role of f0 in Vowel Perception},
  author={Yeung, Gary and Alwan, Abeer},
  journal={Interspeech 2019},
  year={2019}
}

@ARTICLE{pitchnorm,
  author={Shahnawazuddin, Syed and Sinha, Rohit and Pradhan, Gayadhar},
  journal={IEEE Signal Processing Letters}, 
  title={Pitch-Normalized Acoustic Features for Robust Children's Speech Recognition}, 
  year={2017},
  volume={24},
  number={8},
  pages={1128-1132},
  doi={10.1109/LSP.2017.2705085}}
  
  @inproceedings{pitch_adapt_norm,
  title={Pitch-Adaptive Front-End Features for Robust Children's ASR},
  author={Syed Shahnawazuddin and Abhishek Dey and Rohit Sinha},
  booktitle={INTERSPEECH},
  year={2016}
}

@INPROCEEDINGS{prosody_feat,
  author={Kathania, Hemant K. and Shahnawazuddin, S. and Adiga, Nagaraj and Ahmad, Waquar},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Role of Prosodic Features on Children's Speech Recognition}, 
  year={2018},
  volume={},
  number={},
  pages={5519-5523},
  doi={10.1109/ICASSP.2018.8461668}}
  
  @inproceedings{speaking_rate,
  title={Improving Children's Speech Recognition Through Time Scale Modification Based Speaking Rate Adaptation},
  author={Kathania, Hemant K and Shahnawazuddin, S and Ahmad, Waquar and Adiga, Nagraj and Jana, Sanjay Kumar and Samaddar, Arun B},
  booktitle={2018 International Conference on Signal Processing and Communications (SPCOM)},
  pages={257--261},
  year={2018},
  organization={IEEE}
}

@article{formant_norm,
author = {Kathania, Hemant and Kadiri, Sudarsana and Alku, Paavo and Kurimo, Mikko},
year = {2022},
month = {01},
pages = {98-106},
title = {A formant modification method for improved ASR of children’s speech},
volume = {136},
journal = {Speech Communication},
doi = {10.1016/j.specom.2021.11.003}
}
@inproceedings{tdnn,
  title={A time delay neural network architecture for efficient modeling of long temporal contexts},
  author={Peddinti, Vijayaditya and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={Sixteenth annual conference of the international speech communication association},
  year={2015}
}
@inproceedings{tdnnf-children,
  title={Advances in Automatic Speech Recognition for Child Speech Using Factored Time Delay Neural Network.},
  author={Wu, Fei and Garc{\'\i}a-Perera, Leibny Paola and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={Interspeech},
  pages={1--5},
  year={2019}
}

@inproceedings{TDNN-F,
  title={Semi-orthogonal low-rank matrix factorization for deep neural networks.},
  author={Povey, Daniel and Cheng, Gaofeng and Wang, Yiming and Li, Ke and Xu, Hainan and Yarmohammadi, Mahsa and Khudanpur, Sanjeev},
  booktitle={Interspeech},
  pages={3743--3747},
  year={2018}
}

@inproceedings{xu21c_interspeech,
  author={Gaopeng Xu and Song Yang and Lu Ma and Chengfei Li and Zhongqin Wu},
  title={{The TAL System for the INTERSPEECH2021 Shared Task on Automatic Speech Recognition for Non-Native Childrens Speech}},
  year=2021,
  booktitle={Proc. Interspeech 2021},
  pages={1294--1298},
  doi={10.21437/Interspeech.2021-1104}
}


@inproceedings{adultAUGMENT1,
  title={Mismatched training data enhancement for automatic recognition of children's speech using DNN-HMM},
  author={Qian, Mengjie and McLoughlin, Ian and Quo, Wu and Dai, Lirong},
  booktitle={2016 10th International Symposium on Chinese Spoken Language Processing (ISCSLP)},
  pages={1--5},
  year={2016},
  organization={IEEE}
}

@inproceedings{adultAUGMENT2,
  title={Improving Children's Speech Recognition Through Out-of-Domain Data Augmentation.},
  author={Fainberg, Joachim and Bell, Peter and Lincoln, Mike and Renals, Steve},
  booktitle={Interspeech},
  pages={1598--1602},
  year={2016}
}
@INPROCEEDINGS{nonnative,
  author={Matassoni, Marco and Gretter, Roberto and Falavigna, Daniele and Giuliani, Diego},
  booktitle={ICASSP}, 
  title={Non-Native Children Speech Recognition Through Transfer Learning}, 
  year={2018},
  volume={},
  number={},
  pages={6229-6233},
  doi={10.1109/ICASSP.2018.8462059}}
  
    @inproceedings{specaugment,
title	= {SpecAugment: A Simple Augmentation Method for Automatic Speech Recognition},
author	= {Daniel S. Park and William Chan and Yu Zhang and Chung-Cheng Chiu and Barret Zoph and Ekin Dogus Cubuk and Quoc V. Le},
year	= {2019},
booktitle	= {INTERSPEECH}
}

@inproceedings{pronunciation,
  title={Improving speech recognition for children using acoustic adaptation and pronunciation modeling.},
  author={Shivakumar, Prashanth Gurunath and Potamianos, Alexandros and Lee, Sungbok and Narayanan, Shrikanth S},
  booktitle={WOCCI},
  pages={15--19},
  year={2014}
}
@inproceedings{pronunciation2,
  title={An analysis of the causes of increased error rates in children's speech recognition},
  author={Li, Qun and Russell, Martin J},
  booktitle={Seventh International Conference on Spoken Language Processing},
  year={2002}
}
@article{subwords,
title = {Highly accurate children’s speech recognition for interactive reading tutors using subword units},
journal = {Speech Communication},
volume = {49},
number = {12},
pages = {861-873},
year = {2007},
issn = {0167-6393},
doi = {https://doi.org/10.1016/j.specom.2007.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S0167639307000878},
author = {Andreas Hagen and Bryan Pellom and Ronald Cole},
keywords = {Literacy tutors, Subword unit based speech recognition, Language modeling, Reading tracking},
}

@article{gelin2021endtoend,
title = {End-to-end acoustic modelling for phone recognition of young readers},
journal = {Speech Communication},
volume = {134},
pages = {71-84},
year = {2021},
issn = {0167-6393},
doi = {https://doi.org/10.1016/j.specom.2021.08.003},
author = {Lucile Gelin and Morgane Daniel and Julien Pinquier and Thomas Pellegrini},
keywords = {Child speech, Phone recognition, Transformer, Connectionist temporal classification, Transfer learning, Low-resource},
}

@article{sri_end2end,
title = {End-to-end neural systems for automatic children speech recognition: An empirical study},
journal = {Computer Speech \& Language},
volume = {72},
pages = {101289},
year = {2022},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2021.101289},
author = {Prashanth {Gurunath Shivakumar} and Shrikanth Narayanan},
keywords = {Children speech recognition, End-to-end speech recognition, Residual network, Time depth separable convolutional network, Transformer},
}

@inproceedings{valtchev1994novel,
  title={A novel decoder design for large vocabulary recognition},
  author={Valtchev, V and Odell, J and Woodland, PC and Young, SJ},
  booktitle={Proceedings of ICSLP},
  year={1994}
}

@inproceedings{aubert1995large,
  title={Large vocabulary continuous speech recognition using word graphs},
  author={Aubert, Xavier and Ney, Hermann},
  booktitle={1995 International Conference on Acoustics, Speech, and Signal Processing},
  volume={1},
  pages={49--52},
  year={1995},
  organization={IEEE}
}

@inproceedings{kaldi,
  title={The Kaldi speech recognition toolkit},
  author={Povey, Daniel and Ghoshal, Arnab and Boulianne, Gilles and Burget, Lukas and Glembek, Ondrej and Goel, Nagendra and Hannemann, Mirko and Motlicek, Petr and Qian, Yanmin and Schwarz, Petr and others},
  booktitle={IEEE 2011 workshop on automatic speech recognition and understanding},
  number={CONF},
  year={2011},
  organization={IEEE Signal Processing Society}
}




@INPROCEEDINGS{linguistic-children,
  author={Wilpon, J.G. and Jacobsen, C.N.},
  booktitle={ICASSP}, 
  title={A study of speech recognition for children and the elderly}, 
  year={1996},
  volume={1},
  number={},
  pages={349-352 vol. 1},
  doi={10.1109/ICASSP.1996.541104}}
 

@inproceedings{asr-improved2,
  title={Adaptation and Normalization Experiments in Speech Recognition for 4 to 8 Year old Children.},
  author={Elenius, Daniel and Blomberg, Mats},
  booktitle={Interspeech},
  pages={2749--2752},
  year={2005}
}


@inproceedings{GANS,
  title={GANs for Children: A Generative Data Augmentation Strategy for Children Speech Recognition},
  author={Sheng, Peiyao and Yang, Zhuolin and Qian, Yanmin},
  booktitle={2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={129--135},
  year={2019},
  organization={IEEE}
}

@misc{etlt,
    title={TLT-school: a Corpus of Non Native Children Speech},
    author={Roberto Gretter and Marco Matassoni and Stefano Bannò and Daniele Falavigna},
    year={2020},
    eprint={2001.08051},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{chorec,
  title={Children’s oral reading corpus (CHOREC): description and assessment of annotator agreement},
  author={Cleuren, Leen and Duchateau, Jacques and Ghesquiere, Pol and others},
  journal={LREC 2008 Proceedings},
  pages={998--1005},
  year={2008},
  publisher={European Language Resources Association (ELRA); Parijs}
}


@inproceedings{sphinx2,
author = {Huang, Xuedong and Alleva, Fileno and Hwang, Mei-Yuh and Rosenfeld, Ronald},
title = {An Overview of the SPHINX-II Speech Recognition System},
year = {1993},
isbn = {1558603247},
publisher = {Association for Computational Linguistics},
address = {USA},
url = {https://doi.org/10.3115/1075671.1075690},
doi = {10.3115/1075671.1075690},
abstract = {In the past year at Carnegie Mellon steady progress has been made in the area of acoustic and language modeling. The result has been a dramatic reduction in speech recognition errors in the SPHINX-II system. In this paper, we review SPHINX-II and summarize our recent efforts on improved speech recognition. Recently SPHINX-II achieved the lowest error rate in the November 1992 DARPA evaluations. For 5000-word, speaker-independent, continuous, speech recognition, the error rate was reduced to 5%.},
booktitle = {Proceedings of the Workshop on Human Language Technology},
pages = {81–86},
numpages = {6},
location = {Princeton, New Jersey},
series = {HLT '93}
}


@inproceedings{letsread,
  title={The LetsRead corpus of Portuguese children reading aloud for performance evaluation},
  author={Proen{\c{c}}a, Jorge and Celorico, Dirce and Candeias, Sara and Lopes, Carla and Perdig{\~a}o, Fernando},
  booktitle={Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC'16)},
  pages={781--785},
  year={2016}
}

@inproceedings{pfstar,
  title={The PF-Star Children's Speech Corpus},
  author={Russell, Martin and D'Arcy, Shona and Wong, M and Batliner, A and Blomberg, M and Gerosa, M},
  booktitle={Interspeech 2005},
  year={2005}
}

@INPROCEEDINGS{ssc,
  author={Paliwal, K.K.},
  booktitle={ICASSP}, 
  title={Spectral subband centroid features for speech recognition}, 
  year={1998},
  volume={2},
  number={},
  pages={617-620 vol.2},
  doi={10.1109/ICASSP.1998.675340}}
  
  
 @inproceedings{2019multi,
  title={Multi-task based mispronunciation detection of children speech using multi-lingual information},
  author={Wei, Linxuan and Dong, Wenwei and Lin, Binghuai and Zhang, Jinsong},
  booktitle={APSIPA ASC},
  pages={1791--1794},
  year={2019},
  organization={IEEE}
}

@article{meyer2019multi,
  title={Multi-task and transfer learning in low-resource speech recognition},
  author={Meyer, Josh},
  year={2019},
  publisher={The University of Arizona.}
}

@inproceedings{multi-nlp,
author = {Collobert, Ronan and Weston, Jason},
title = {A Unified Architecture for Natural Language Processing: Deep Neural Networks with Multitask Learning},
year = {2008},
isbn = {9781605582054},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1390156.1390177},
doi = {10.1145/1390156.1390177},
abstract = {We describe a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense (grammatically and semantically) using a language model. The entire network is trained jointly on all these tasks using weight-sharing, an instance of multitask learning. All the tasks use labeled data except the language model which is learnt from unlabeled text and represents a novel form of semi-supervised learning for the shared tasks. We show how both multitask learning and semi-supervised learning improve the generalization of the shared tasks, resulting in state-of-the-art-performance.},
booktitle = {ICML},
pages = {160–167},
numpages = {8},
location = {Helsinki, Finland},
series = {ICML '08}
}


@INPROCEEDINGS{multi-speech,
  author={Huang, Jui-Ting and Li, Jinyu and Yu, Dong and Deng, Li and Gong, Yifan},
  booktitle={ICASSP}, 
  title={Cross-language knowledge transfer using multilingual deep neural network with shared hidden layers}, 
  year={2013},
  volume={},
  number={},
  pages={7304-7308},
  doi={10.1109/ICASSP.2013.6639081}}
  
    @INPROCEEDINGS{abad2020,
  author={Abad, Alberto and Bell, Peter and Carmantini, Andrea and Renais, Steve},
  booktitle={ICASSP}, 
  title={Cross Lingual Transfer Learning for Zero-Resource Domain Adaptation}, 
  year={2020},
  volume={},
  number={},
  pages={6909-6913},
  doi={10.1109/ICASSP40776.2020.9054468}}

@inproceedings{MTL-LFMMI,
  title={Lattice-Free Maximum Mutual Information Training of Multilingual Speech Recognition Systems.},
  author={Madikeri, Srikanth R and Khonglah, Banriskhem K and Tong, Sibo and Motlicek, Petr and Bourlard, Herv{\'e} and Povey, Daniel},
  booktitle={INTERSPEECH},
  pages={4746--4750},
  year={2020}
}

@INPROCEEDINGS{VTLN2,  author={Serizel, Romain and Giuliani, Diego},  booktitle={SLT Workshop},   title={Vocal tract length normalisation approaches to DNN-based children's and adults' speech recognition},   year={2014},  volume={},  number={},  pages={135-140},  doi={10.1109/SLT.2014.7078563}}

@article{madikeri2021multitask,
  title={Multitask adaptation with Lattice-Free MMI for multi-genre speech recognition of low resource languages},
  author={Madikeri, Srikanth and Motlicek, Petr and Bourlard, Herv{\'e}},
  journal={Proc. Interspeech 2021},
  pages={4329--4333},
  year={2021}
}

@inproceedings{tachbelie2020development,
  title={Development of Multilingual ASR Using GlobalPhone for Less-Resourced Languages: The Case of Ethiopian Languages.},
  author={Tachbelie, Martha Yifiru and Abate, Solomon Teferra and Schultz, Tanja},
  booktitle={Interspeech 2020},
  pages={1032--1036},
  year={2020}
}

@article{semi,
  title={Semi-supervised asr by end-to-end self-training},
  author={Chen, Yang and Wang, Weiran and Wang, Chao},
  journal={arXiv preprint arXiv:2001.09128},
  year={2020}
}

@inproceedings{mtl_computervision,
  title={Fast r-cnn},
  author={Girshick, Ross},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1440--1448},
  year={2015}
}

@article{bioinfo,
  title={Domain-adversarial multi-task framework for novel therapeutic property prediction of compounds},
  author={Xie, Lingwei and He, Song and Zhang, Zhongnan and Lin, Kunhui and Bo, Xiaochen and Yang, Shu and Feng, Boyuan and Wan, Kun and Yang, Kang and Yang, Jie and others},
  journal={Bioinformatics},
  volume={36},
  number={9},
  pages={2848--2855},
  year={2020},
  publisher={Oxford University Press}
}

@article{zhang2018overview,
  title={An overview of multi-task learning},
  author={Zhang, Yu and Yang, Qiang},
  journal={National Science Review},
  volume={5},
  number={1},
  pages={30--43},
  year={2018},
  publisher={Oxford University Press}
}

@article{VTLN_wfun,
author = {Saito, Yuki and Takamichi, Shinnosuke and Saruwatari, Hiroshi},
year = {2019},
month = {06},
pages = {},
title = {Vocoder-free text-to-speech synthesis incorporating generative adversarial networks using low-/multi-frequency STFT amplitude spectra},
volume = {58},
journal = {Computer Speech \& Language},
doi = {10.1016/j.csl.2019.05.008}
}
@inproceedings{SPEECONS,
  title={SPEECON – Speech Databases for Consumer Devices: Database Specification and Validation},
  author={Dorota J. Iskra and Beate Grosskopf and Krzysztof Marasek and Henk van den Heuvel and Frank Diehl and Andreas Kiessling},
  booktitle={LREC},
  year={2002}
}

@article{callslt,
author = {Rayner, Manny and Tsourakis, Nikos and Baur, Claudia and Bouillon, Pierrette and Gerlach, Johanna},
year = {2014},
month = {01},
pages = {},
title = {CALL-SLT: A Spoken CALL System: based on grammar and speech recognition},
volume = {10},
journal = {Linguistic Issues in Language Technology},
doi = {10.33011/lilt.v10i.1353}
}

@misc{childit2,
  title={CHILDIT2--A New Children Read Speech Corpus},
  author={COSI, PIERO and PACI, GIULIO and SOMMAVILLA, GIACOMO and TESSER, FABIO}
}

@inproceedings{JASMIN,
    title = "Recording Speech of Children, Non-Natives and Elderly People for {HLT} Applications: the {JASMIN}-{CGN} Corpus.",
    author = "Cucchiarini, Catia  and
      Driesen, Joris  and
      Van hamme, Hugo  and
      Sanders, Eric",
    booktitle = "Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08)",
    month = may,
    year = "2008",
    address = "Marrakech, Morocco",
    publisher = "European Language Resources Association (ELRA)",
    url = "http://www.lrec-conf.org/proceedings/lrec2008/pdf/366_paper.pdf",
    abstract = "Within the framework of the Dutch-Flemish programme STEVIN, the JASMIN-CGN (Jongeren, Anderstaligen en Senioren in Mens-machine Interactie Corpus Gesproken Nederlands) project was carried out, which was aimed at collecting speech of children, non-natives and elderly people. The JASMIN-CGN project is an extension of the Spoken Dutch Corpus (CGN) along three dimensions. First, by collecting a corpus of contemporary Dutch as spoken by children of different age groups, elderly people and non-natives with different mother tongues, an extension along the age and mother tongue dimensions was achieved. In addition, we collected speech material in a communication setting that was not envisaged in the CGN: human-machine interaction. One third of the data was collected in Flanders and two thirds in the Netherlands. In this paper we report on our experiences in collecting this corpus and we describe some of the important decisions that we made in the attempt to combine efficiency and high quality.",
}

@inproceedings{takemaru,
  title={Public speech-oriented guidance system with adult and child discrimination capability},
  author={Nisimura, Ryuichi and Lee, Akinobu and Saruwatari, Hiroshi and Shikano, Kiyohiro},
  booktitle={2004 IEEE International Conference on Acoustics, Speech, and Signal Processing},
  volume={1},
  pages={I--433},
  year={2004},
  organization={IEEE}
}


@inproceedings{speco,
  title={A Hungarian child database for speech processing applications},
  author={Csat{\'a}ri, Ferenc and Bakcsi, Zs and Vicsi, Kl{\'a}ra},
  booktitle={Sixth European Conference on Speech Communication and Technology},
  year={1999}
}

@inproceedings{tball,
  title={Tball data collection: the making of a young children's speech corpus},
  author={Kazemzadeh, Abe and You, Hong and Iseli, Markus and Jones, Barbara and Cui, Xiaodong and Heritage, Margaret and Price, Patti and Anderson, Elaine and Narayanan, Shrikanth and Alwan, Abeer},
  booktitle={Ninth European Conference on Speech Communication and Technology},
  year={2005}
}
@inproceedings{ad-child_ru,
  title={AD-Child. Ru: Speech corpus for Russian children with atypical development},
  author={Lyakso, Elena and Frolova, Olga and Kaliyev, Arman and Gorodnyi, Viktor and Grigorev, Aleksey and Matveev, Yuri},
  booktitle={International Conference on Speech and Computer},
  pages={299--308},
  year={2019},
  organization={Springer}
}
@article{cuchild,
  title={Cuchild: A large-scale cantonese corpus of child speech for phonology and articulation assessment},
  author={Ng, Si-Ioi and Ng, Cymie Wing-Yee and Wang, Jiarui and Lee, Tan and Lee, Kathy Yuet-Sheung and Tong, Michael Chi-Fai},
  journal={arXiv preprint arXiv:2008.03188},
  year={2020}
}

@INPROCEEDINGS{cass_child,
author={Gao, Jun and Li, Aijun and Xiong, Ziyu},
booktitle={2012 International Conference on Speech Database and Assessments},
title={Mandarin multimedia child speech corpus: Cass\_Child},
year={2012},
volume={},
number={},
pages={7-12}, 
doi={10.1109/ICSDA.2012.6422462}}

@article{russell2006pf,
  title={The pf-star british english childrens speech corpus},
  author={Russell, Martin},
  journal={The Speech Ark Limited},
  year={2006},
  publisher={Citeseer}
}

@article{providence,
  title={Word-minimality, epenthesis and coda licensing in the early acquisition of English},
  author={Demuth, Katherine and Culbertson, Jennifer and Alter, Jennifer},
  journal={Language and speech},
  volume={49},
  number={2},
  pages={137--173},
  year={2006},
  publisher={Sage Publications Sage UK: London, England}
}

@article{LyonSC,
  title={Prosodically-conditioned variability in children's production of French determiners},
  author={Demuth, Katherine and Tremblay, Annie},
  journal={Journal of child language},
  volume={35},
  number={1},
  pages={99--127},
  year={2008},
  publisher={Cambridge University Press}
}


@incollection{demuth1992acquisition,
  title={The acquisition of Sesotho},
  author={Demuth, Katherine},
  booktitle={The crosslinguistic study of language acquisition},
  pages={557--638},
  year={1992},
  publisher={Psychology Press}
}

@article{nitk,
  title={NITK Kids’ speech corpus},
  author={Ramteke, Pravin Bhaskar and Supanekar, Sujata and Hegde, Pradyoth and Nelson, Hanna and Aithal, V and Koolagudi, SG},
  journal={emotion},
  volume={491},
  pages={4--15},
  year={2019}
}

@inproceedings{chiede,
  title={CHIEDE, a spontaneous child language corpus of Spanish},
  author={Garrote, Marta and Moreno Sandoval, A},
  booktitle={Proceedings of the 3rd International LABLITA Workshop in Corpus Linguistics},
  year={2008}
}

@inproceedings{emochildru,
  title={EmoChildRu: emotional child Russian speech corpus},
  author={Lyakso, Elena and Frolova, Olga and Dmitrieva, Evgeniya and Grigorev, Aleksey and Kaya, Heysem and Salah, Albert Ali and Karpov, Alexey},
  booktitle={International Conference on Speech and Computer},
  pages={144--152},
  year={2015},
  organization={Springer}
}

@inproceedings{ahmed2021auskidtalk,
  title={AusKidTalk: an auditory-visual corpus of 3-to 12-year-old Australian children's speech},
  author={Ahmed, Beena and Ballard, Kirrie and Burnham, Denis and Sirojan, Tharmakulasingam and Mehmood, Hadi and Estival, Dominique and Baker, Elise and Cox, Felicity and Arciuli, Joanne and Benders, Titia and others},
  booktitle={Annual Conference of the International Speech Communication Association (22nd: 2021)},
  pages={3680--3684},
  year={2021},
  organization={International Speech Communication Association}
}

@article{eshky2019ultrasuite,
  title={UltraSuite: a repository of ultrasound and acoustic data from child speech therapy sessions},
  author={Eshky, Aciel and Ribeiro, Manuel Sam and Cleland, Joanne and Richmond, Korin and Roxburgh, Zoe and Scobbie, James and Wrench, Alan},
  journal={arXiv preprint arXiv:1907.00835},
  year={2019}
}
@article{lee1999acoustics,
  title={Acoustics of children’s speech: Developmental changes of temporal and spectral parameters},
  author={Lee, Sungbok and Potamianos, Alexandros and Narayanan, Shrikanth},
  journal={The Journal of the Acoustical Society of America},
  volume={105},
  number={3},
  pages={1455--1468},
  year={1999},
  publisher={Acoustical Society of America}
}

@INPROCEEDINGS{CFSC,  author={Pascual, Ronald M. and Guevara, Rowena Cristina L.},  booktitle={TENCON 2012 IEEE Region 10 Conference},   title={Developing a children's Filipino speech corpus for application in automatic detection of reading miscues and disfluencies},   year={2012},  volume={},  number={},  pages={1-6},  doi={10.1109/TENCON.2012.6412235}}

@inproceedings{hagen2003children,
  title={Children's speech recognition with application to interactive books and tutors},
  author={Hagen, Andreas and Pellom, Bryan and Cole, Ronald},
  booktitle={2003 IEEE Workshop on Automatic Speech Recognition and Understanding (IEEE Cat. No. 03EX721)},
  pages={186--191},
  year={2003},
  organization={IEEE}
}

@article{leonard1993tidigits,
  title={Tidigits speech corpus},
  author={Leonard, R Gary and Doddington, George},
  journal={Texas Instruments, Inc},
  year={1993}
}
@phdthesis{gerosa2006acoustic,
  title={Acoustic modeling for automatic recognition of children’s speech},
  author={Gerosa, M},
  year={2006},
  school={Ph. D. thesis, University of Trento}
}

@inproceedings{burkhardt2010database,
  title={A database of age and gender annotated telephone speech},
  author={Burkhardt, Felix and Eckert, Martin and Johannsen, Wiebke and Stegmann, Joachim},
  booktitle={Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC'10)},
  year={2010}
}

@inproceedings{bell2005swedish,
  title={The Swedish NICE Corpus--Spoken dialogues between children and embodied characters in a computer game scenario},
  author={Bell, Linda and Boye, Johan and Gustafson, Joakim and Heldner, Mattias and Lindstr{\"o}m, Anders and Wir{\'e}n, Mats},
  booktitle={Interspeech 2005-Eurospeech, 9th European Conference on Speech Communication and Technology, Lisbon, Portugal, September 4-8, 2005},
  pages={2765--2768},
  year={2005},
  organization={ISCA}
}

@article{grissemann2000zurcher,
  title={Z{\"u}rcher Lesetest},
  author={Grissemann, Hans and Linder, M},
  journal={Bern: Huber Verlag},
  year={2000}
}

@book{steidl2009automatic,
  title={Automatic classification of emotion related user states in spontaneous children's speech},
  author={Steidl, Stefan},
  year={2009},
  publisher={Logos-Verlag Berlin, Germany}
}

@inproceedings{bell2003child,
  title={Child and adult speaker adaptation during error resolution in a publicly available spoken dialogue system},
  author={Bell, Linda and Gustafson, Joakim},
  booktitle={Eighth European Conference on Speech Communication and Technology},
  year={2003},
  organization={Citeseer}
}

@article{PEREZESPINOSA202055,
title = {IESC-Child: An Interactive Emotional Children’s Speech Corpus},
journal = {Computer Speech \& Language},
volume = {59},
pages = {55-74},
year = {2020},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2019.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S0885230817301547},
author = {Humberto Pérez-Espinosa and Juan Martínez-Miranda and Ismael Espinosa-Curiel and Josefina Rodríguez-Jacobo and Luis Villaseñor-Pineda and Himer Avila-George},
keywords = {Interactive systems, Emotional analysis, Paralinguistic information},
abstract = {In this paper, we describe the process that we used to create a new corpus of children’s emotional speech. We used a Wizard of Oz (WoZ) setting to induce different emotional reactions in children during speech-based interactions with two robots. We recorded the speech spoken in Mexican Spanish by 174 children (both sexes) between 6 and 11 years of age. The recordings were manually segmented and transcribed. The segments were then labeled with two types of emotional-related paralinguistic information: emotion and attitude. The corpus contained 2093min of audio recordings (34.88h) divided into 19,793 speech segments. The Interactive Emotional Children’s Speech Corpus (IESC-Child) can be a valuable resource for researchers studying affective reactions in speech communication during child-computer interactions in Spanish and for creating models to recognize acoustic paralinguistic information. IESC-Child is available to the research community upon request.}
}

@inproceedings{hamalainen2013cng,
  title={The CNG corpus of European Portuguese children’s speech},
  author={H{\"a}m{\"a}l{\"a}inen, Annika and Rodrigues, Silvia and J{\'u}dice, Ana and Silva, Sandra Morgado and Calado, Ant{\'o}nio and Pinto, Fernando Miguel and Dias, Miguel Sales},
  booktitle={International Conference on Text, Speech and Dialogue},
  pages={544--551},
  year={2013},
  organization={Springer}
}

@article{big_review_childASR,
author = {Bhardwaj, Vivek and Kukreja, Vinay and Belkhier, Youcef and Bajaj, Mohit and .B, Srikanth Goud and Rehman, Ateeq and Hamam, Habib and Othman, Mohamed},
year = {2022},
month = {04},
pages = {},
title = {Automatic Speech Recognition (ASR) System for Children’s: A Systematic Literature Review},
journal = {Applied Sciences},
doi = {10.3390/app12094419}
}


@inproceedings{bdpublico,
  title={The design of a large vocabulary speech corpus for Portuguese},
  author={Neto, Joao P and Martins, Ciro A and Meinedo, Hugo and Almeida, Luis B},
  booktitle={Fifth European Conference on Speech Communication and Technology},
  year={1997}
}
@article{kunze2017transfer,
  title={Transfer learning for speech recognition on a budget},
  author={Kunze, Julius and Kirsch, Louis and Kurenkov, Ilia and Krug, Andreas and Johannsmeier, Jens and Stober, Sebastian},
  journal={arXiv preprint arXiv:1706.00290},
  year={2017}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{dong2018speech,
  title={Speech-transformer: a no-recurrence sequence-to-sequence model for speech recognition},
  author={Dong, Linhao and Xu, Shuang and Xu, Bo},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5884--5888},
  year={2018},
  organization={IEEE}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{hmm-end2end,
author = {Wang, Dong and Wang, Xiaodong and Lv, Shaohe},
year = {2019},
month = {08},
pages = {1018},
title = {An Overview of End-to-End Automatic Speech Recognition},
volume = {11},
journal = {Symmetry},
doi = {10.3390/sym11081018}
}

@article{VAE,
  title={Auto-Encoding Variational Bayes},
  author={Diederik P. Kingma and Max Welling},
  journal={CoRR},
  year={2014},
  volume={abs/1312.6114}
}


@inproceedings{houlsby,
  title={Parameter-efficient transfer learning for NLP},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={International Conference on Machine Learning},
  pages={2790--2799},
  year={2019},
  organization={PMLR}
}

@inproceedings{pfeiffer,
    title = "{MAD-X}: {A}n {A}dapter-{B}ased {F}ramework for {M}ulti-{T}ask {C}ross-{L}ingual {T}ransfer",
    author = "Pfeiffer, Jonas  and
      Vuli{\'c}, Ivan  and
      Gurevych, Iryna  and
      Ruder, Sebastian",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2020.emnlp-main.617",
    pages = "7654--7673",
}


@misc{speechbrain,
  title={{SpeechBrain}: A General-Purpose Speech Toolkit},
  author={Mirco Ravanelli and Titouan Parcollet and Peter Plantinga and Aku Rouhe and Samuele Cornell and Loren Lugosch and Cem Subakan and Nauman Dawalatabad and Abdelwahab Heba and Jianyuan Zhong and Ju-Chieh Chou and Sung-Lin Yeh and Szu-Wei Fu and Chien-Feng Liao and Elena Rastorgueva and François Grondin and William Aris and Hwidong Na and Yan Gao and Renato De Mori and Yoshua Bengio},
  year={2021},
  eprint={2106.04624},
  archivePrefix={arXiv},
  primaryClass={eess.AS},
  note={arXiv:2106.04624}
}

@article{vae_transformation,
  title={Modeling and transforming speech using variational autoencoders},
  author={Blaauw, Merlijn and Bonada, Jordi},
  journal={Morgan N, editor. Interspeech 2016; 2016 Sep 8-12; San Francisco, CA.[place unknown]: ISCA; 2016. p. 1770-4.},
  year={2016},
  publisher={International Speech Communication Association (ISCA)}
}

@article{vae_gen,
  title={Expressive speech synthesis via modeling expressions with variational autoencoder},
  author={Akuzawa, Kei and Iwasawa, Yusuke and Matsuo, Yutaka},
  journal={arXiv preprint arXiv:1804.02135},
  year={2018}
}

@inproceedings{vae_enh,
  title={A variance modeling framework based on variational autoencoders for speech enhancement},
  author={Leglaive, Simon and Girin, Laurent and Horaud, Radu},
  booktitle={2018 IEEE 28th International Workshop on Machine Learning for Signal Processing (MLSP)},
  pages={1--6},
  year={2018},
  organization={IEEE}
}

@inproceedings{philip2020monolingual,
  title={Monolingual adapters for zero-shot neural machine translation},
  author={Philip, Jerin and Berard, Alexandre and Gall{\'e}, Matthias and Besacier, Laurent},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={4465--4470},
  year={2020}
}

@article{kannan2019large,
  title={Large-scale multilingual speech recognition with a streaming end-to-end model},
  author={Kannan, Anjuli and Datta, Arindrima and Sainath, Tara N and Weinstein, Eugene and Ramabhadran, Bhuvana and Wu, Yonghui and Bapna, Ankur and Chen, Zhifeng and Lee, Seungji},
  journal={arXiv preprint arXiv:1909.05330},
  year={2019}
}
@article{tomanek2021residual,
  title={Residual Adapters for Parameter-Efficient ASR Adaptation to Atypical and Accented Speech},
  author={Tomanek, Katrin and Zayats, Vicky and Padfield, Dirk and Vaillancourt, Kara and Biadsy, Fadi},
  journal={arXiv preprint arXiv:2109.06952},
  year={2021}
}
@article{geva2020transformer,
  title={Transformer feed-forward layers are key-value memories},
  author={Geva, Mor and Schuster, Roei and Berant, Jonathan and Levy, Omer},
  journal={arXiv preprint arXiv:2012.14913},
  year={2020}
}

@article{chen2020data,
  title={Data Augmentation For Children's Speech Recognition--The" Ethiopian" System For The SLT 2021 Children Speech Recognition Challenge},
  author={Chen, Guoguo and Na, Xingyu and Wang, Yongqing and Yan, Zhiyong and Zhang, Junbo and Ma, Sifan and Wang, Yujun},
  journal={arXiv preprint arXiv:2011.04547},
  year={2020}
}

@article{ng2020cuhk,
  title={The cuhk-tudelft system for the slt 2021 children speech recognition challenge},
  author={Ng, Si-Ioi and Liu, Wei and Peng, Zhiyuan and Feng, Siyuan and Huang, Hing-Pang and Scharenborg, Odette and Lee, Tan},
  journal={arXiv preprint arXiv:2011.06239},
  year={2020}
}

@article{luscher2019rwth,
  title={RWTH ASR Systems for LibriSpeech: Hybrid vs Attention--w/o Data Augmentation},
  author={L{\"u}scher, Christoph and Beck, Eugen and Irie, Kazuki and Kitza, Markus and Michel, Wilfried and Zeyer, Albert and Schl{\"u}ter, Ralf and Ney, Hermann},
  journal={arXiv preprint arXiv:1905.03072},
  year={2019}
}

@inproceedings{battenberg2017exploring,
  title={Exploring neural transducers for end-to-end speech recognition},
  author={Battenberg, Eric and Chen, Jitong and Child, Rewon and Coates, Adam and Li, Yashesh Gaur Yi and Liu, Hairong and Satheesh, Sanjeev and Sriram, Anuroop and Zhu, Zhenyao},
  booktitle={2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={206--213},
  year={2017},
  organization={IEEE}
}

@article{soltau2016neural,
  title={Neural speech recognizer: Acoustic-to-word LSTM model for large vocabulary speech recognition},
  author={Soltau, Hagen and Liao, Hank and Sak, Hasim},
  journal={arXiv preprint arXiv:1610.09975},
  year={2016}
}

@article{tribus,
  title={TRIBUS: An end-to-end automatic speech recognition system for European Portuguese},
  author={Carlos F. Carvalho and Alberto Abad},
  journal={IberSPEECH 2021},
  year={2021}
}

@INPROCEEDINGS{hmmvse2e,  author={Karita, Shigeki and Chen, Nanxin and Hayashi, Tomoki and Hori, Takaaki and Inaguma, Hirofumi and Jiang, Ziyan and Someki, Masao and Soplin, Nelson Enrique Yalta and Yamamoto, Ryuichi and Wang, Xiaofei and Watanabe, Shinji and Yoshimura, Takenori and Zhang, Wangyou},  booktitle={2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},   title={A Comparative Study on Transformer vs RNN in Speech Applications},   year={2019},  volume={},  number={},  pages={449-456},  doi={10.1109/ASRU46091.2019.9003750}}

@article{hannun2014deep,
  title={Deep speech: Scaling up end-to-end speech recognition},
  author={Hannun, Awni and Case, Carl and Casper, Jared and Catanzaro, Bryan and Diamos, Greg and Elsen, Erich and Prenger, Ryan and Satheesh, Sanjeev and Sengupta, Shubho and Coates, Adam and others},
  journal={arXiv preprint arXiv:1412.5567},
  year={2014}
}
@article{sutskever2014sequence,
  title={Sequence to sequence learning with neural networks},
  author={Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}
@article{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.0473},
  year={2014}
}

@INPROCEEDINGS{seq2seq_imagecaption,  author={Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},  booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},   title={Show and tell: A neural image caption generator},   year={2015},  volume={},  number={},  pages={3156-3164},  doi={10.1109/CVPR.2015.7298935}}

@article{vinyals2015neural,
  title={A neural conversational model},
  author={Vinyals, Oriol and Le, Quoc},
  journal={arXiv preprint arXiv:1506.05869},
  year={2015}
}

@article{nallapati2016abstractive,
  title={Abstractive text summarization using sequence-to-sequence rnns and beyond},
  author={Nallapati, Ramesh and Zhou, Bowen and Gulcehre, Caglar and Xiang, Bing and others},
  journal={arXiv preprint arXiv:1602.06023},
  year={2016}
}

@inproceedings{shen2018natural,
  title={Natural tts synthesis by conditioning wavenet on mel spectrogram predictions},
  author={Shen, Jonathan and Pang, Ruoming and Weiss, Ron J and Schuster, Mike and Jaitly, Navdeep and Yang, Zongheng and Chen, Zhifeng and Zhang, Yu and Wang, Yuxuan and Skerrv-Ryan, Rj and others},
  booktitle={2018 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={4779--4783},
  year={2018},
  organization={IEEE}
}

@inproceedings{wang2021towards,
  title={Towards data selection on tts data for children’s speech recognition},
  author={Wang, Wei and Zhou, Zhikai and Lu, Yizhou and Wang, Hongji and Du, Chenpeng and Qian, Yanmin},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6888--6892},
  year={2021},
  organization={IEEE}
}

@inproceedings{kim2021conditional,
  title={Conditional variational autoencoder with adversarial learning for end-to-end text-to-speech},
  author={Kim, Jaehyeon and Kong, Jungil and Son, Juhee},
  booktitle={International Conference on Machine Learning},
  pages={5530--5540},
  year={2021},
  organization={PMLR}
}

@inproceedings{laptev2020you,
  title={You do not need more data: Improving end-to-end speech recognition by text-to-speech data augmentation},
  author={Laptev, Aleksandr and Korostik, Roman and Svischev, Aleksey and Andrusenko, Andrei and Medennikov, Ivan and Rybin, Sergey},
  booktitle={2020 13th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)},
  pages={439--444},
  year={2020},
  organization={IEEE}
}

@inproceedings{gelin2021simulating,
  title={Simulating reading mistakes for child speech Transformer-based phone recognition},
  author={Gelin, Lucile and Pellegrini, Thomas and Pinquier, Julien and Daniel, Morgane},
  booktitle={Annual Conference of the International Speech Communication Association (INTERSPEECH)},
  year={2021}
}

@inproceedings{gelin2020babble,
  title={Babble noise augmentation for phone recognition applied to children reading aloud in a classroom environment},
  author={Gelin, Lucile and Daniel, Morgane and Pellegrini, Thomas and Pinquier, Julien},
  booktitle={Speech in Noise Workshop (SPiN)},
  year={2020}
}
@inproceedings{couvreur2000use,
  title={On the use of artificial reverberation for ASR in highly reverberant environments},
  author={Couvreur, Laurent and Couvreur, Christophe},
  booktitle={Proc. 2nd IEEE Benelux Signal Processing Symposium (SPS-2000), Hilvarenbeek, The Netherlands},
  pages={S001--S004},
  year={2000},
  organization={Citeseer}
}
@article{whitenoise,
title = {Assessing local noise level estimation methods: Application to noise robust ASR},
journal = {Speech Communication},
volume = {34},
number = {1},
pages = {141-158},
year = {2001},
note = {Noise Robust ASR},
issn = {0167-6393},
doi = {https://doi.org/10.1016/S0167-6393(00)00051-0},
url = {https://www.sciencedirect.com/science/article/pii/S0167639300000510},
author = {Christophe Ris and Stéphane Dupont},
keywords = {Robust automatic speech recognition, Noise level estimation, Noise reduction, Spectral subtraction, Missing data},
abstract = {In this paper, we assess and compare four methods for the local estimation of noise spectra, namely the energy clustering, the Hirsch histograms, the weighted average method and the low-energy envelope tracking. Moreover we introduce, for these four approaches, the harmonic filtering strategy, a new pre-processing technique, expected to better track fast modulations of the noise energy. The speech periodicity property is used to update the noise level estimate during voiced parts of speech, without explicit detection of voiced portions. Our evaluation is performed with six different kinds of noises (both artificial and real noises) added to clean speech. The best noise level estimation method is then applied to noise robust speech recognition based on techniques requiring a dynamic estimation of the noise spectra, namely spectral subtraction and missing data compensation.
Zusammenfassung
Dans ce papier, nous nous proposons d'évaluer et de comparer différentes méthodes d'estimation locale du spectre de bruit: le clustering des énergies, les histogrammes de Hirsch, la méthode de la moyenne pondérée ainsi que le suivi de l'enveloppe de basse energie. Nous présentons également, en pré-traitement pour chacune de ces méthodes, le filtrage des harmoniques, une technique permettant de suivre plus efficacement des variations rapides de l'énergie du bruit. Le caractère harmonique de certaines portions de parole est exploité afin de réestimer le niveau de bruit pendant les périodes de sons voisés (sans détection explicite du caractère voisé ou non des segments de parole). Ces différentes approches ont été testées sur six types de bruit différents (artificiels et réels) ajoutés à de la parole claire. Les estimateurs de niveaux de bruit ainsi testés ont alors été appliqués à deux méthodes de reconnaissance de la parole robuste aux bruits basées sur la soustraction spectrale et la théorie des données manquantes.}
}

@inproceedings{malek2017robust,
  title={Robust Automatic Recognition of Speech with background music},
  author={Malek, Jiri and Zdansky, Jindrich and Cerva, Petr},
  booktitle={2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5210--5214},
  year={2017},
  organization={IEEE}
}
@inproceedings{VTLP,
  title={Vocal tract length perturbation (VTLP) improves speech recognition},
  author={Jaitly, Navdeep and Hinton, Geoffrey E},
  booktitle={Proc. ICML Workshop on Deep Learning for Audio, Speech and Language},
  volume={117},
  pages={21},
  year={2013}
}

@inproceedings{liu2003noise,
  title={Noise robustness in speech to speech translation},
  author={Liu, Fu-Hua and Gao, Yuqing and Gu, Liang and Picheny, Michael},
  booktitle={Eighth European Conference on Speech Communication and Technology},
  year={2003}
}

@article{pfeiffer2020adapterfusion,
  title={AdapterFusion: Non-destructive task composition for transfer learning},
  author={Pfeiffer, Jonas and Kamath, Aishwarya and R{\"u}ckl{\'e}, Andreas and Cho, Kyunghyun and Gurevych, Iryna},
  journal={arXiv preprint arXiv:2005.00247},
  year={2020}
}

@article{gong2022layer,
  title={Layer-wise fast adaptation for end-to-end multi-accent speech recognition},
  author={Gong, Xun and Lu, Yizhou and Zhou, Zhikai and Qian, Yanmin},
  journal={arXiv preprint arXiv:2204.09883},
  year={2022}
}

@article{van2017neural,
  title={Neural discrete representation learning},
  author={Van Den Oord, Aaron and Vinyals, Oriol and others},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{cooper2020zero,
  title={Zero-shot multi-speaker text-to-speech with state-of-the-art neural speaker embeddings},
  author={Cooper, Erica and Lai, Cheng-I and Yasuda, Yusuke and Fang, Fuming and Wang, Xin and Chen, Nanxin and Yamagishi, Junichi},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6184--6188},
  year={2020},
  organization={IEEE}
}

@inproceedings{hu2022synt++,
  title={SYNT++: Utilizing Imperfect Synthetic Data to Improve Speech Recognition},
  author={Hu, Ting-Yao and Armandpour, Mohammadreza and Shrivastava, Ashish and Chang, Jen-Hao Rick and Koppula, Hema and Tuzel, Oncel},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7682--7686},
  year={2022},
  organization={IEEE}
}

@article{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{hsu2021hubert,
  title={Hubert: Self-supervised speech representation learning by masked prediction of hidden units},
  author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={29},
  pages={3451--3460},
  year={2021},
  publisher={IEEE}
}

@article{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={12449--12460},
  year={2020}
}

@ARTICLE{tera,  author={Liu, Andy T. and Li, Shang-Wen and Lee, Hung-yi},  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},   title={TERA: Self-Supervised Learning of Transformer Encoder Representation for Speech},   year={2021},  volume={29},  number={},  pages={2351-2366},  doi={10.1109/TASLP.2021.3095662}}

@misc{chi2021audio,
  doi = {10.48550/ARXIV.2005.08575},
  
  url = {https://arxiv.org/abs/2005.08575},
  
  author = {Chi, Po-Han and Chung, Pei-Hung and Wu, Tsung-Han and Hsieh, Chun-Cheng and Chen, Yen-Hao and Li, Shang-Wen and Lee, Hung-yi},
  
  keywords = {Audio and Speech Processing (eess.AS), Computation and Language (cs.CL), Sound (cs.SD), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Audio ALBERT: A Lite BERT for Self-supervised Learning of Audio Representation},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@misc{chang2022distilhubert,
      title={DistilHuBERT: Speech Representation Learning by Layer-wise Distillation of Hidden-unit BERT}, 
      author={Heng-Jui Chang and Shu-wen Yang and Hung-yi Lee},
      year={2022},
      eprint={2110.01900},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{caseiro2002using,
  title={Using dynamic WFST composition for recognizing broadcast news},
  author={Caseiro, Diamantino and Trancoso, Isabel},
  booktitle={Seventh International Conference on Spoken Language Processing},
  year={2002}
}

@article{mohri1997finite,
  title={Finite-state transducers in language and speech processing},
  author={Mohri, Mehryar},
  journal={Computational linguistics},
  volume={23},
  number={2},
  pages={269--311},
  year={1997}
}

@article{botelho2020pathological,
  title={Pathological speech detection using x-vector embeddings},
  author={Botelho, Catarina and Teixeira, Francisco and Rolland, Thomas and Abad, Alberto and Trancoso, Isabel},
  journal={arXiv preprint arXiv:2003.00864},
  year={2020}
}

@inproceedings{snyder2018x,
  title={X-vectors: Robust dnn embeddings for speaker recognition},
  author={Snyder, David and Garcia-Romero, Daniel and Sell, Gregory and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2018 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={5329--5333},
  year={2018},
  organization={IEEE}
}

@inproceedings{hauptman2019identifying,
  title={Identifying Distinctive Acoustic and Spectral Features in Parkinson's Disease.},
  author={Hauptman, Yermiyahu and Aloni-Lavi, Ruth and Lapidot, Itshak and Gurevich, Tanya and Manor, Yael and Naor, Stav and Diamant, Noa and Opher, Irit},
  booktitle={Interspeech},
  pages={2498--2502},
  year={2019}
}

@inproceedings{botelho2019speech,
  title={Speech as a biomarker for obstructive sleep apnea detection},
  author={Botelho, M Catarina and Trancoso, Isabel and Abad, Alberto and Paiva, Teresa},
  booktitle={ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5851--5855},
  year={2019},
  organization={IEEE}
}

@article{pompili2020inesc,
  title={The INESC-ID multi-modal system for the ADReSS 2020 challenge},
  author={Pompili, Anna and Rolland, Thomas and Abad, Alberto},
  journal={arXiv preprint arXiv:2005.14646},
  year={2020}
}

@article{bizzocchi2017many,
  title={How many phonemes does the English language have?},
  author={Bizzocchi, Aldo Luiz},
  journal={International Journal on Studies in English Language and Literature (IJSELL)},
  volume={5},
  number={10},
  pages={36--46},
  year={2017}
}

@article{benzeghiba2007automatic,
  title={Automatic speech recognition and speech variability: A review},
  author={Benzeghiba, Mohamed and De Mori, Renato and Deroo, Olivier and Dupont, Stephane and Erbes, Teodora and Jouvet, Denis and Fissore, Luciano and Laface, Pietro and Mertins, Alfred and Ris, Christophe and others},
  journal={Speech communication},
  volume={49},
  number={10-11},
  pages={763--786},
  year={2007},
  publisher={Elsevier}
}

@article{arora2012automatic,
  title={Automatic speech recognition: a review},
  author={Arora, Shipra J and Singh, Rishi Pal},
  journal={International Journal of Computer Applications},
  volume={60},
  number={9},
  year={2012},
  publisher={Foundation of Computer Science}
}

@article{karpagavalli2016review,
  title={A review on automatic speech recognition architecture and approaches},
  author={Karpagavalli, S and Chandra, Edy},
  journal={International Journal of Signal Processing, Image Processing and Pattern Recognition},
  volume={9},
  number={4},
  pages={393--404},
  year={2016}
}

@book{bourlard2012connectionist,
  title={Connectionist speech recognition: a hybrid approach},
  author={Bourlard, Herve A and Morgan, Nelson},
  volume={247},
  year={2012},
  publisher={Springer Science \& Business Media}
}
@inproceedings{meinedo2003audimus,
  title={AUDIMUS. media: a Broadcast News speech recognition system for the European Portuguese language},
  author={Meinedo, Hugo and Caseiro, Diamantino and Neto, Joao and Trancoso, Isabel},
  booktitle={International Workshop on Computational Processing of the Portuguese Language},
  pages={9--17},
  year={2003},
  organization={Springer}
}


@article{fan2022draft,
  title={DRAFT: A Novel Framework to Reduce Domain Shifting in Self-supervised Learning and Its Application to Children's ASR},
  author={Fan, Ruchao and Alwan, Abeer},
  journal={arXiv preprint arXiv:2206.07931},
  year={2022}
}

@article{shivakumar2020transfer,
  title={Transfer learning from adult to children for speech recognition: Evaluation, analysis and recommendations},
  author={Shivakumar, Prashanth Gurunath and Georgiou, Panayiotis},
  journal={Computer speech \& language},
  volume={63},
  pages={101077},
  year={2020},
  publisher={Elsevier}
}

@article{langbecker2020long,
  title={Long-term effects of childhood speech and language disorders: A scoping review},
  author={Langbecker, Danette and Snoswell, Centaine L and Smith, Anthony C and Verboom, Jedidja and Caffery, Liam J},
  journal={South African Journal of Childhood Education},
  volume={10},
  number={1},
  pages={1--13},
  year={2020},
  publisher={AOSIS Publishing}
}
@article{black2015communication,
  title={Communication Disorders and Use of Intervention Services among Children Aged 3--17 Years: United States, 2012; US Department of Health and Human Services, Centers for Disease Control and Prevention},
  author={Black, LI and Vahratian, A and Hoffman, HJ},
  journal={National Center for Health Statistics: Atlanta, GA, USA},
  year={2015}
}
@book{levelt1993speaking,
  title={Speaking: From intention to articulation},
  author={Levelt, Willem JM},
  year={1993},
  publisher={MIT press}
}