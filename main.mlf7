{\reset@font\mlffont\mtc@string\contentsline{figure}{\noexpand \leavevmode \numberline {7.1}{\ignorespaces Th architecture of the ConvPass adapter. $k$ is the kernel size of the 1D convolution. All Convoluation are depth-wise convolution.\relax }}{\reset@font\mlffont 111}{figure.caption.44}}
{\reset@font\mlffont\mtc@string\contentsline{figure}{\noexpand \leavevmode \numberline {7.2}{\ignorespaces AdapterBias, consisting of a linear layer $L_\alpha $ and a vector $\mathcal {V}$, is added after the second feed-forward layer only in each FFN module.\relax }}{\reset@font\mlffont 113}{figure.caption.45}}
{\reset@font\mlffont\mtc@string\contentsline{figure}{\noexpand \leavevmode \numberline {7.3}{\ignorespaces Different paramter efficent procedure for children ASR in conformer model\relax }}{\reset@font\mlffont 114}{figure.caption.46}}
{\reset@font\mlffont\mtc@string\contentsline{figure}{\noexpand \leavevmode \numberline {7.4}{\ignorespaces Shared-Adapter setup in a Conformer model\relax }}{\reset@font\mlffont 116}{figure.caption.48}}
{\reset@font\mlffont\mtc@string\contentsline{figure}{\noexpand \leavevmode \numberline {7.5}{\ignorespaces Different paramter efficent procedure for children ASR in conformer model with shared-Adapters\relax }}{\reset@font\mlffont 118}{figure.caption.49}}
