{\reset@font\mlffont\mtc@string\contentsline{figure}{\noexpand \leavevmode \numberline {7.1}{\ignorespaces Th architecture of the ConvPass adapter. $k$ is the kernel size of the 1D convolution. All Convoluation are depth-wise convolution.\relax }}{\reset@font\mlffont 105}{figure.caption.41}}
{\reset@font\mlffont\mtc@string\contentsline{figure}{\noexpand \leavevmode \numberline {7.2}{\ignorespaces AdapterBias, consisting of a linear layer $L_\alpha $ and a vector $\mathcal {V}$, is added after the second feed-forward layer only in each FFN module.\relax }}{\reset@font\mlffont 107}{figure.caption.42}}
{\reset@font\mlffont\mtc@string\contentsline{figure}{\noexpand \leavevmode \numberline {7.3}{\ignorespaces Different paramter efficent procedure for children ASR in conformer model\relax }}{\reset@font\mlffont 108}{figure.caption.43}}
{\reset@font\mlffont\mtc@string\contentsline{figure}{\noexpand \leavevmode \numberline {7.4}{\ignorespaces Shared-Adapter setup in a Conformer model\relax }}{\reset@font\mlffont 110}{figure.caption.45}}
{\reset@font\mlffont\mtc@string\contentsline{figure}{\noexpand \leavevmode \numberline {7.5}{\ignorespaces Different paramter efficent procedure for children ASR in conformer model with shared-Adapters\relax }}{\reset@font\mlffont 112}{figure.caption.46}}
