{\reset@font\mlffont\mtc@string\contentsline{figure}{\noexpand \leavevmode \numberline {7.1}{\ignorespaces Th architecture of the ConvPass adapter. $k$ is the kernel size of the 1D convolution. All Convoluation are depth-wise convolution.\relax }}{\reset@font\mlffont 119}{figure.caption.46}}
{\reset@font\mlffont\mtc@string\contentsline{figure}{\noexpand \leavevmode \numberline {7.2}{\ignorespaces AdapterBias, consisting of a linear layer $L_\alpha $ and a vector $\mathcal {V}$, is added after the second feed-forward layer only in each FFN module.\relax }}{\reset@font\mlffont 121}{figure.caption.47}}
{\reset@font\mlffont\mtc@string\contentsline{figure}{\noexpand \leavevmode \numberline {7.3}{\ignorespaces Different paramter efficent procedure for children ASR in conformer model\relax }}{\reset@font\mlffont 122}{figure.caption.48}}
{\reset@font\mlffont\mtc@string\contentsline{figure}{\noexpand \leavevmode \numberline {7.4}{\ignorespaces Shared-Adapter setup in a Conformer model\relax }}{\reset@font\mlffont 125}{figure.caption.50}}
{\reset@font\mlffont\mtc@string\contentsline{figure}{\noexpand \leavevmode \numberline {7.5}{\ignorespaces Different paramter efficent procedure for children ASR in conformer model with shared-Adapters\relax }}{\reset@font\mlffont 126}{figure.caption.51}}
