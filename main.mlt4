{\reset@font\mltfont\mtc@string\contentsline{table}{\noexpand \leavevmode \numberline {4.1}{\ignorespaces My Science Tutor Children Speech Corpus statistics\relax }}{\reset@font\mltfont 71}{table.caption.27}}
{\reset@font\mltfont\mtc@string\contentsline{table}{\noexpand \leavevmode \numberline {4.2}{\ignorespaces Encoder-Decoder experiment\relax }}{\reset@font\mltfont 72}{table.caption.28}}
{\reset@font\mltfont\mtc@string\contentsline{table}{\noexpand \leavevmode \numberline {4.3}{\ignorespaces Modules fine-tuning experiment\relax }}{\reset@font\mltfont 73}{table.caption.30}}
{\reset@font\mltfont\mtc@string\contentsline{table}{\noexpand \leavevmode \numberline {4.4}{\ignorespaces Results of the fine-tuning on part of the model only\relax }}{\reset@font\mltfont 79}{table.caption.32}}
{\reset@font\mltfont\mtc@string\contentsline{table}{\noexpand \leavevmode \numberline {4.5}{\ignorespaces Results of the different approaches; In parenthesis are shown the number of parameters needed for inference after dropping the $\sigma $ branch.\relax }}{\reset@font\mltfont 80}{table.caption.33}}
