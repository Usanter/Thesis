\babel@toc {english}{}
\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}
\contentsline {section}{\numberline {1.1}Context}{3}{section.1.1}
\contentsline {section}{\numberline {1.2}Problem statement}{5}{section.1.2}
\contentsline {section}{\numberline {1.3}Contributions}{6}{section.1.3}
\contentsline {section}{\numberline {1.4}Structure for the thesis}{8}{section.1.4}
\contentsline {chapter}{\numberline {2}Background - Children automatic speech recognition}{9}{chapter.2}
\contentsline {section}{\numberline {2.1}Children speech recognition challenges}{12}{section.2.1}
\contentsline {subsection}{\numberline {2.1.1}Speech variability}{12}{subsection.2.1.1}
\contentsline {subsection}{\numberline {2.1.2}Language and phonetic knowledge}{15}{subsection.2.1.2}
\contentsline {subsection}{\numberline {2.1.3}Data scarcity}{17}{subsection.2.1.3}
\contentsline {section}{\numberline {2.2}Introduction to automatic speech recognition}{19}{section.2.2}
\contentsline {subsection}{\numberline {2.2.1}A brief history of Automatic Speech Recognition}{19}{subsection.2.2.1}
\contentsline {subsubsection}{\numberline {2.2.1.A}Early Days}{19}{subsubsection.2.2.1.1}
\contentsline {subsubsection}{\numberline {2.2.1.B}The Speech Understanding Research program}{20}{subsubsection.2.2.1.2}
\contentsline {subsection}{\numberline {2.2.2}Traditional automatic speech recognition systems}{22}{subsection.2.2.2}
\contentsline {subsubsection}{\numberline {2.2.2.A}Feature extraction}{24}{subsubsection.2.2.2.1}
\contentsline {subsubsection}{\numberline {2.2.2.B}Acoustic model}{26}{subsubsection.2.2.2.2}
\contentsline {subsubsection}{\numberline {2.2.2.C}Pronunciation model}{27}{subsubsection.2.2.2.3}
\contentsline {subsubsection}{\numberline {2.2.2.D}Language model}{28}{subsubsection.2.2.2.4}
\contentsline {subsubsection}{\numberline {2.2.2.E}Decoder}{30}{subsubsection.2.2.2.5}
\contentsline {subsection}{\numberline {2.2.3}End-to-end automatic speech recognition}{31}{subsection.2.2.3}
\contentsline {subsubsection}{\numberline {2.2.3.A}Connectionist Temporal Classification}{32}{subsubsection.2.2.3.1}
\contentsline {subsubsection}{\numberline {2.2.3.B}Sequence to sequence}{33}{subsubsection.2.2.3.2}
\contentsline {subsection}{\numberline {2.2.4}Automatic Speech Recognition metrics}{34}{subsection.2.2.4}
\contentsline {section}{\numberline {2.3}Children automatic speech recognition}{35}{section.2.3}
\contentsline {subsection}{\numberline {2.3.1}Feature extraction stage}{35}{subsection.2.3.1}
\contentsline {subsection}{\numberline {2.3.2}Pronunciation and language model}{37}{subsection.2.3.2}
\contentsline {subsection}{\numberline {2.3.3}Design of acoustic models}{37}{subsection.2.3.3}
\contentsline {subsection}{\numberline {2.3.4}End-to-end models}{38}{subsection.2.3.4}
\contentsline {subsection}{\numberline {2.3.5}Data augmentation}{39}{subsection.2.3.5}
\contentsline {subsubsection}{\numberline {2.3.5.A}Using external data}{39}{subsubsection.2.3.5.1}
\contentsline {subsubsection}{\numberline {2.3.5.B}Using available data}{40}{subsubsection.2.3.5.2}
\contentsline {subsection}{\numberline {2.3.6}Training procedure for children speech recognition}{41}{subsection.2.3.6}
\contentsline {subsubsection}{\numberline {2.3.6.A}Transfer learning}{41}{subsubsection.2.3.6.1}
\contentsline {subsubsection}{\numberline {2.3.6.B}Multi-task learning}{44}{subsubsection.2.3.6.2}
\contentsline {subsubsection}{\numberline {2.3.6.C}Self-supervised Learning}{45}{subsubsection.2.3.6.3}
\contentsline {section}{\numberline {2.4}Children Corpora}{46}{section.2.4}
\contentsline {subsection}{\numberline {2.4.1}LETSREAD}{48}{subsection.2.4.1}
\contentsline {subsection}{\numberline {2.4.2}PFSTAR\_SWEDISH}{48}{subsection.2.4.2}
\contentsline {subsection}{\numberline {2.4.3}ETLTDE}{48}{subsection.2.4.3}
\contentsline {subsection}{\numberline {2.4.4}CMU\_KIDS}{48}{subsection.2.4.4}
\contentsline {subsection}{\numberline {2.4.5}CHOREC}{49}{subsection.2.4.5}
\contentsline {subsection}{\numberline {2.4.6}MyST}{49}{subsection.2.4.6}
\contentsline {section}{\numberline {2.5}Summary}{49}{section.2.5}
\contentsline {chapter}{\numberline {3}Hybrid models for children automatic speech recognition}{51}{chapter.3}
\contentsline {section}{\numberline {3.1}Introduction}{53}{section.3.1}
\contentsline {section}{\numberline {3.2}Multi-task and Transfer learning using adult and children data}{53}{section.3.2}
\contentsline {subsection}{\numberline {3.2.1}Methodology}{53}{subsection.3.2.1}
\contentsline {subsection}{\numberline {3.2.2}Corpus}{54}{subsection.3.2.2}
\contentsline {subsection}{\numberline {3.2.3}Experimental setup}{54}{subsection.3.2.3}
\contentsline {subsection}{\numberline {3.2.4}Results}{55}{subsection.3.2.4}
\contentsline {subsection}{\numberline {3.2.5}Summary and discussion}{56}{subsection.3.2.5}
\contentsline {section}{\numberline {3.3}Multi-task and transfer learning using multilingual children data}{57}{section.3.3}
\contentsline {subsection}{\numberline {3.3.1}Motivation}{57}{subsection.3.3.1}
\contentsline {subsection}{\numberline {3.3.2}Proposed approach}{57}{subsection.3.3.2}
\contentsline {subsection}{\numberline {3.3.3}Setup}{58}{subsection.3.3.3}
\contentsline {subsection}{\numberline {3.3.4}Multilingual-transfer learning experiment}{59}{subsection.3.3.4}
\contentsline {subsection}{\numberline {3.3.5}Cross-lingual validation}{60}{subsection.3.3.5}
\contentsline {subsection}{\numberline {3.3.6}Summary and discussion}{61}{subsection.3.3.6}
\contentsline {section}{\numberline {3.4}Conclusion}{61}{section.3.4}
\contentsline {chapter}{\numberline {4}End-to-End children automatic speech recognition}{63}{chapter.4}
\contentsline {section}{\numberline {4.1}Introduction}{65}{section.4.1}
\contentsline {section}{\numberline {4.2}Transformer model}{65}{section.4.2}
\contentsline {section}{\numberline {4.3}Conformer model}{68}{section.4.3}
\contentsline {section}{\numberline {4.4}Understand transfer learning efficacy for transformer based models}{70}{section.4.4}
\contentsline {subsection}{\numberline {4.4.1}Partial Transfer learning}{71}{subsection.4.4.1}
\contentsline {subsection}{\numberline {4.4.2}Experimental setup}{72}{subsection.4.4.2}
\contentsline {subsection}{\numberline {4.4.3}Corpus}{72}{subsection.4.4.3}
\contentsline {subsection}{\numberline {4.4.4}Implementation details}{72}{subsection.4.4.4}
\contentsline {subsection}{\numberline {4.4.5}Encoder-Decoder Transfer learning}{72}{subsection.4.4.5}
\contentsline {subsection}{\numberline {4.4.6}Modules Transfer learning}{74}{subsection.4.4.6}
\contentsline {section}{\numberline {4.5}Summary}{76}{section.4.5}
\contentsline {chapter}{\numberline {5}Exploring Parameter-Efficient Strategies in Transfer Learning for Child-Focused ASR Systems}{77}{chapter.5}
\contentsline {section}{\numberline {5.1}Introduction}{79}{section.5.1}
\contentsline {section}{\numberline {5.2}Adapter tuning}{80}{section.5.2}
\contentsline {section}{\numberline {5.3}Investigating ASR for Child Speech with Adapters}{82}{section.5.3}
\contentsline {section}{\numberline {5.4}Implementation details}{84}{section.5.4}
\contentsline {section}{\numberline {5.5}Results}{85}{section.5.5}
\contentsline {subsection}{\numberline {5.5.1}Configurations}{85}{subsection.5.5.1}
\contentsline {subsection}{\numberline {5.5.2}Unsupervised Clustering of utterances}{87}{subsection.5.5.2}
\contentsline {chapter}{\numberline {6}Integration of synthetic speech for data augmentation}{89}{chapter.6}
\contentsline {section}{\numberline {6.1}Introduction}{91}{section.6.1}
\contentsline {section}{\numberline {6.2}Enhancing ASR Performance through TTS Data Augmentation}{92}{section.6.2}
\contentsline {section}{\numberline {6.3}Closing the synthetic and real mismatch gap with Adapters}{93}{section.6.3}
\contentsline {section}{\numberline {6.4}Experimental settings}{95}{section.6.4}
\contentsline {subsection}{\numberline {6.4.1}Transformer architecture for ASR}{95}{subsection.6.4.1}
\contentsline {subsection}{\numberline {6.4.2}Multi-speaker text-to-speech: YourTTS}{95}{subsection.6.4.2}
\contentsline {section}{\numberline {6.5}Experimental setup}{97}{section.6.5}
\contentsline {subsection}{\numberline {6.5.1}Real speech corpus}{97}{subsection.6.5.1}
\contentsline {subsection}{\numberline {6.5.2}Synthetic data}{97}{subsection.6.5.2}
\contentsline {subsection}{\numberline {6.5.3}Experiments}{98}{subsection.6.5.3}
\contentsline {section}{\numberline {6.6}Results and discussion}{99}{section.6.6}
\contentsline {subsection}{\numberline {6.6.1}Comparison with existing approaches}{99}{subsection.6.6.1}
\contentsline {subsection}{\numberline {6.6.2}Influence of synthetic number of hours}{100}{subsection.6.6.2}
\contentsline {subsection}{\numberline {6.6.3}Impact of DWAT different hyper-parameters}{101}{subsection.6.6.3}
\contentsline {subsection}{\numberline {6.6.4}Extension DWAT to the Conformer architecture}{101}{subsection.6.6.4}
\contentsline {section}{\numberline {6.7}Conclusions and future work}{103}{section.6.7}
\contentsline {section}{\numberline {6.8}Ongoing and future work}{104}{section.6.8}
\contentsline {chapter}{\numberline {7}Alternative approaches to parameter-efficient transfer learning}{105}{chapter.7}
\contentsline {section}{\numberline {7.1}Introduction}{107}{section.7.1}
\contentsline {section}{\numberline {7.2}Exploring literature alternatives}{107}{section.7.2}
\contentsline {subsection}{\numberline {7.2.1}Scaled Adapters}{107}{subsection.7.2.1}
\contentsline {subsection}{\numberline {7.2.2}Convolution based Adapters}{108}{subsection.7.2.2}
\contentsline {subsection}{\numberline {7.2.3}BitFit}{109}{subsection.7.2.3}
\contentsline {subsection}{\numberline {7.2.4}Scale and Shift features}{110}{subsection.7.2.4}
\contentsline {subsection}{\numberline {7.2.5}AdapterBias}{111}{subsection.7.2.5}
\contentsline {subsection}{\numberline {7.2.6}Results of the different PETL methods}{112}{subsection.7.2.6}
\contentsline {section}{\numberline {7.3}New type of Adapter: The Shared Adapter}{113}{section.7.3}
\contentsline {subsection}{\numberline {7.3.1}Motivation}{113}{subsection.7.3.1}
\contentsline {subsection}{\numberline {7.3.2}Experimental setup}{115}{subsection.7.3.2}
\contentsline {subsection}{\numberline {7.3.3}Results}{115}{subsection.7.3.3}
\contentsline {chapter}{\numberline {8}Conclusions}{117}{chapter.8}
\contentsline {chapter}{Bibliography}{119}{chapter.8}
\contentsline {chapter}{\numberline {A}Pathological speech detection through pre-trained models}{149}{appendix.A}
\contentsline {section}{\numberline {A.1}Introduction}{149}{section.A.1}
\contentsline {section}{\numberline {A.2}Pathological speech detection using x-vector embeddings}{150}{section.A.2}
\contentsline {subsection}{\numberline {A.2.1}Introduction}{150}{subsection.A.2.1}
\contentsline {subsection}{\numberline {A.2.2}Speaker embeddings: i-vector and x-vector}{150}{subsection.A.2.2}
\contentsline {subsection}{\numberline {A.2.3}Experimental setup}{151}{subsection.A.2.3}
\contentsline {subsubsection}{\numberline {A.2.3.A}Corpora}{151}{subsubsection.A.2.3.1}
\contentsline {subsubsection}{\numberline {A.2.3.B}Knowledge based features}{152}{subsubsection.A.2.3.2}
\contentsline {subsubsection}{\numberline {A.2.3.C}Speaker embeddings}{152}{subsubsection.A.2.3.3}
\contentsline {subsection}{\numberline {A.2.4}Results}{153}{subsection.A.2.4}
\contentsline {section}{\numberline {A.3}The INESC-ID Multi-Modal System for the ADReSS 2020 Challenge}{154}{section.A.3}
\contentsline {subsection}{\numberline {A.3.1}Introduction}{154}{subsection.A.3.1}
\contentsline {subsection}{\numberline {A.3.2}Corpus}{155}{subsection.A.3.2}
\contentsline {subsection}{\numberline {A.3.3}Proposed system}{155}{subsection.A.3.3}
\contentsline {subsubsection}{\numberline {A.3.3.A}Acoustics modality}{155}{subsubsection.A.3.3.1}
\contentsline {subsubsection}{\numberline {A.3.3.B}Linguistic modality}{156}{subsubsection.A.3.3.2}
\contentsline {subsection}{\numberline {A.3.4}Results}{157}{subsection.A.3.4}
\contentsline {section}{\numberline {A.4}Transfer Learning-Based Cough Representations for Automatic Detection of COVID-19}{159}{section.A.4}
\contentsline {subsection}{\numberline {A.4.1}Introduction}{159}{subsection.A.4.1}
\contentsline {subsection}{\numberline {A.4.2}Corpora}{160}{subsection.A.4.2}
\contentsline {subsection}{\numberline {A.4.3}Proposed system}{160}{subsection.A.4.3}
\contentsline {subsubsection}{\numberline {A.4.3.A}TDNN-F embedddings}{160}{subsubsection.A.4.3.1}
\contentsline {subsubsection}{\numberline {A.4.3.B}CNN embedddings}{161}{subsubsection.A.4.3.2}
\contentsline {subsubsection}{\numberline {A.4.3.C}PASE+ embedddings}{161}{subsubsection.A.4.3.3}
\contentsline {subsubsection}{\numberline {A.4.3.D}COVID-19 condition classification}{162}{subsubsection.A.4.3.4}
\contentsline {subsection}{\numberline {A.4.4}Results}{162}{subsection.A.4.4}
\contentsline {section}{\numberline {A.5}Conclusion and future work}{163}{section.A.5}
\contentsline {chapter}{\numberline {B}Sefl-supervised learning as feature extractor for children's ASR}{165}{appendix.B}
\contentsline {section}{\numberline {B.1}Introduction}{165}{section.B.1}
\contentsline {section}{\numberline {B.2}Self-supervised pre-trained models}{166}{section.B.2}
\contentsline {subsection}{\numberline {B.2.1}Generative modeling}{166}{subsection.B.2.1}
\contentsline {subsection}{\numberline {B.2.2}Discriminative modeling}{167}{subsection.B.2.2}
\contentsline {section}{\numberline {B.3}Experimental setup}{168}{section.B.3}
\contentsline {section}{\numberline {B.4}Results}{169}{section.B.4}
\contentsline {section}{\numberline {B.5}Analysis of the extracted features}{169}{section.B.5}
\contentsline {section}{\numberline {B.6}Conclusions and future work}{171}{section.B.6}
