\BOOKMARK [0][]{Title.0}{Titlepage}{}% 1
\BOOKMARK [0][]{Abstract.0}{Abstract}{}% 2
\BOOKMARK [0][]{Abstract.0}{Abstract}{}% 3
\BOOKMARK [0][]{toc.0}{Contents}{}% 4
\BOOKMARK [1][]{lof.1}{List of Figures}{toc.0}% 5
\BOOKMARK [1][]{lot.1}{List of Tables}{toc.0}% 6
\BOOKMARK [0][]{chapter.1}{1 Introduction}{}% 7
\BOOKMARK [1][]{section.1.1}{1.1 Problem statement}{chapter.1}% 8
\BOOKMARK [1][]{section.1.2}{1.2 Contributions}{chapter.1}% 9
\BOOKMARK [1][]{section.1.3}{1.3 Structure for the thesis}{chapter.1}% 10
\BOOKMARK [0][]{chapter.2}{2 Background - Children automatic speech recognition}{}% 11
\BOOKMARK [1][]{section.2.1}{2.1 Children speech recognition challenges}{chapter.2}% 12
\BOOKMARK [2][]{subsection.2.1.1}{2.1.1 Speech variability}{section.2.1}% 13
\BOOKMARK [2][]{subsection.2.1.2}{2.1.2 Language and phonetic knowledge}{section.2.1}% 14
\BOOKMARK [2][]{subsection.2.1.3}{2.1.3 Data scarcity}{section.2.1}% 15
\BOOKMARK [1][]{section.2.2}{2.2 Introduction to automatic speech recognition}{chapter.2}% 16
\BOOKMARK [2][]{subsection.2.2.1}{2.2.1 A brief history of Automatic Speech Recognition}{section.2.2}% 17
\BOOKMARK [3][]{subsubsection.2.2.1.1}{2.2.1.A Early Days}{subsection.2.2.1}% 18
\BOOKMARK [3][]{subsubsection.2.2.1.2}{2.2.1.B The Speech Understanding Research program}{subsection.2.2.1}% 19
\BOOKMARK [3][]{subsubsection.2.2.1.3}{2.2.1.C From template matching to statistical modeling: HMM based models}{subsection.2.2.1}% 20
\BOOKMARK [2][]{subsection.2.2.2}{2.2.2 Traditional automatic speech recognition systems}{section.2.2}% 21
\BOOKMARK [3][]{subsubsection.2.2.2.1}{2.2.2.A Feature extraction}{subsection.2.2.2}% 22
\BOOKMARK [3][]{subsubsection.2.2.2.2}{2.2.2.B Acoustic model}{subsection.2.2.2}% 23
\BOOKMARK [3][]{subsubsection.2.2.2.3}{2.2.2.C Pronunciation model}{subsection.2.2.2}% 24
\BOOKMARK [3][]{subsubsection.2.2.2.4}{2.2.2.D Language model}{subsection.2.2.2}% 25
\BOOKMARK [3][]{subsubsection.2.2.2.5}{2.2.2.E Decoder}{subsection.2.2.2}% 26
\BOOKMARK [2][]{subsection.2.2.3}{2.2.3 End-to-end automatic speech recognition}{section.2.2}% 27
\BOOKMARK [3][]{subsubsection.2.2.3.1}{2.2.3.A Connectionist Temporal Classification}{subsection.2.2.3}% 28
\BOOKMARK [3][]{subsubsection.2.2.3.2}{2.2.3.B Sequence to sequence}{subsection.2.2.3}% 29
\BOOKMARK [2][]{subsection.2.2.4}{2.2.4 Automatic Speech Recognition metrics}{section.2.2}% 30
\BOOKMARK [1][]{section.2.3}{2.3 Children automatic speech recognition}{chapter.2}% 31
\BOOKMARK [2][]{subsection.2.3.1}{2.3.1 Feature extraction and adaptation}{section.2.3}% 32
\BOOKMARK [3][]{subsubsection.2.3.1.1}{2.3.1.A Feature extraction}{subsection.2.3.1}% 33
\BOOKMARK [3][]{subsubsection.2.3.1.2}{2.3.1.B Feature adaptation}{subsection.2.3.1}% 34
\BOOKMARK [3][]{subsubsection.2.3.1.3}{2.3.1.C Additional features}{subsection.2.3.1}% 35
\BOOKMARK [2][]{subsection.2.3.2}{2.3.2 Detail of the annotation}{section.2.3}% 36
\BOOKMARK [2][]{subsection.2.3.3}{2.3.3 Structure of the acoustic model}{section.2.3}% 37
\BOOKMARK [3][]{subsubsection.2.3.3.1}{2.3.3.A Hybrid models}{subsection.2.3.3}% 38
\BOOKMARK [3][]{subsubsection.2.3.3.2}{2.3.3.B End-to-end models}{subsection.2.3.3}% 39
\BOOKMARK [2][]{subsection.2.3.4}{2.3.4 Data augmentation}{section.2.3}% 40
\BOOKMARK [3][]{subsubsection.2.3.4.1}{2.3.4.A Using external data}{subsection.2.3.4}% 41
\BOOKMARK [3][]{subsubsection.2.3.4.2}{2.3.4.B Using available data}{subsection.2.3.4}% 42
\BOOKMARK [2][]{subsection.2.3.5}{2.3.5 Training procedure for children speech recognition}{section.2.3}% 43
\BOOKMARK [3][]{subsubsection.2.3.5.1}{2.3.5.A Transfer learning}{subsection.2.3.5}% 44
\BOOKMARK [3][]{subsubsection.2.3.5.2}{2.3.5.B Multi-task learning}{subsection.2.3.5}% 45
\BOOKMARK [1][]{section.2.4}{2.4 Children Corpora}{chapter.2}% 46
\BOOKMARK [2][]{subsection.2.4.1}{2.4.1 LETSREAD}{section.2.4}% 47
\BOOKMARK [2][]{subsection.2.4.2}{2.4.2 PFSTAR\137SWEDISH}{section.2.4}% 48
\BOOKMARK [2][]{subsection.2.4.3}{2.4.3 ETLTDE}{section.2.4}% 49
\BOOKMARK [2][]{subsection.2.4.4}{2.4.4 CMU\137KIDS}{section.2.4}% 50
\BOOKMARK [2][]{subsection.2.4.5}{2.4.5 CHOREC}{section.2.4}% 51
\BOOKMARK [2][]{subsection.2.4.6}{2.4.6 MyST}{section.2.4}% 52
\BOOKMARK [1][]{section.2.5}{2.5 Summary}{chapter.2}% 53
\BOOKMARK [0][]{chapter.3}{3 Hybrid models for children automatic speech recognition}{}% 54
\BOOKMARK [1][]{section.3.1}{3.1 Introduction}{chapter.3}% 55
\BOOKMARK [1][]{section.3.2}{3.2 Multi-task and Transfer learning using adult and children data}{chapter.3}% 56
\BOOKMARK [2][]{subsection.3.2.1}{3.2.1 Methodology}{section.3.2}% 57
\BOOKMARK [2][]{subsection.3.2.2}{3.2.2 Corpus}{section.3.2}% 58
\BOOKMARK [2][]{subsection.3.2.3}{3.2.3 Experimental setup}{section.3.2}% 59
\BOOKMARK [2][]{subsection.3.2.4}{3.2.4 Results}{section.3.2}% 60
\BOOKMARK [2][]{subsection.3.2.5}{3.2.5 Summary and discussion}{section.3.2}% 61
\BOOKMARK [1][]{section.3.3}{3.3 Multi-task and transfer learning using multilingual children data}{chapter.3}% 62
\BOOKMARK [2][]{subsection.3.3.1}{3.3.1 Motivation}{section.3.3}% 63
\BOOKMARK [2][]{subsection.3.3.2}{3.3.2 Proposed approach}{section.3.3}% 64
\BOOKMARK [2][]{subsection.3.3.3}{3.3.3 Setup}{section.3.3}% 65
\BOOKMARK [2][]{subsection.3.3.4}{3.3.4 Multilingual-transfer learning experiment}{section.3.3}% 66
\BOOKMARK [2][]{subsection.3.3.5}{3.3.5 Cross-lingual validation}{section.3.3}% 67
\BOOKMARK [2][]{subsection.3.3.6}{3.3.6 Summary and discussion}{section.3.3}% 68
\BOOKMARK [1][]{section.3.4}{3.4 Conclusion}{chapter.3}% 69
\BOOKMARK [0][]{chapter.4}{4 End-to-End children automatic speech recognition}{}% 70
\BOOKMARK [1][]{section.4.1}{4.1 Introduction}{chapter.4}% 71
\BOOKMARK [1][]{section.4.2}{4.2 Transformer models}{chapter.4}% 72
\BOOKMARK [1][]{section.4.3}{4.3 Adapters for Transformer based models}{chapter.4}% 73
\BOOKMARK [2][]{subsection.4.3.1}{4.3.1 Related work}{section.4.3}% 74
\BOOKMARK [3][]{subsubsection.4.3.1.1}{4.3.1.A Transformer model for children ASR}{subsection.4.3.1}% 75
\BOOKMARK [3][]{subsubsection.4.3.1.2}{4.3.1.B Adapters}{subsection.4.3.1}% 76
\BOOKMARK [3][]{subsubsection.4.3.1.3}{4.3.1.C Variational Auto-Encoders}{subsection.4.3.1}% 77
\BOOKMARK [2][]{subsection.4.3.2}{4.3.2 Variational adapters}{section.4.3}% 78
\BOOKMARK [2][]{subsection.4.3.3}{4.3.3 Experiments}{section.4.3}% 79
\BOOKMARK [3][]{subsubsection.4.3.3.1}{4.3.3.A Corpus}{subsection.4.3.3}% 80
\BOOKMARK [3][]{subsubsection.4.3.3.2}{4.3.3.B Implementation details}{subsection.4.3.3}% 81
\BOOKMARK [3][]{subsubsection.4.3.3.3}{4.3.3.C Experiments description}{subsection.4.3.3}% 82
\BOOKMARK [2][]{subsection.4.3.4}{4.3.4 Results}{section.4.3}% 83
\BOOKMARK [3][]{subsubsection.4.3.4.1}{4.3.4.A Transfer learning experiments}{subsection.4.3.4}% 84
\BOOKMARK [2][]{subsection.4.3.5}{4.3.5 Adapters and Vadapters results}{section.4.3}% 85
\BOOKMARK [3][]{subsubsection.4.3.5.1}{4.3.5.A Adapters for children ASR}{subsection.4.3.5}% 86
\BOOKMARK [3][]{subsubsection.4.3.5.2}{4.3.5.B Variational-adapters}{subsection.4.3.5}% 87
\BOOKMARK [2][]{subsection.4.3.6}{4.3.6 Discusion}{section.4.3}% 88
\BOOKMARK [1][]{section.4.4}{4.4 Summary}{chapter.4}% 89
\BOOKMARK [0][]{chapter.5}{5 Work Plan}{}% 90
\BOOKMARK [1][]{section.5.1}{5.1 Proposal summary}{chapter.5}% 91
\BOOKMARK [1][]{section.5.2}{5.2 Ongoing and future work}{chapter.5}% 92
\BOOKMARK [1][]{section.5.3}{5.3 Proposed timeline}{chapter.5}% 93
\BOOKMARK [0][]{chapter.6}{6 Pathology detection from speech}{}% 94
\BOOKMARK [0][]{bib.0}{Bibliography}{}% 95
\BOOKMARK [0][]{chapter.6}{Bibliography}{}% 96
