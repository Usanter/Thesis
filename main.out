\BOOKMARK [0][]{Title.0}{Titlepage}{}% 1
\BOOKMARK [0][]{Abstract.0}{Abstract}{}% 2
\BOOKMARK [0][]{Abstract.0}{Abstract}{}% 3
\BOOKMARK [0][]{toc.0}{Contents}{}% 4
\BOOKMARK [1][]{lof.1}{List of Figures}{toc.0}% 5
\BOOKMARK [1][]{lot.1}{List of Tables}{toc.0}% 6
\BOOKMARK [0][]{chapter.1}{1 Introduction}{}% 7
\BOOKMARK [1][]{section.1.1}{1.1 Context}{chapter.1}% 8
\BOOKMARK [1][]{section.1.2}{1.2 Problem statement}{chapter.1}% 9
\BOOKMARK [1][]{section.1.3}{1.3 Contributions}{chapter.1}% 10
\BOOKMARK [1][]{section.1.4}{1.4 Structure for the thesis}{chapter.1}% 11
\BOOKMARK [0][]{chapter.2}{2 Background - Children automatic speech recognition}{}% 12
\BOOKMARK [1][]{section.2.1}{2.1 Children speech recognition challenges}{chapter.2}% 13
\BOOKMARK [2][]{subsection.2.1.1}{2.1.1 Speech variability}{section.2.1}% 14
\BOOKMARK [2][]{subsection.2.1.2}{2.1.2 Language and phonetic knowledge}{section.2.1}% 15
\BOOKMARK [2][]{subsection.2.1.3}{2.1.3 Data scarcity}{section.2.1}% 16
\BOOKMARK [1][]{section.2.2}{2.2 Introduction to automatic speech recognition}{chapter.2}% 17
\BOOKMARK [2][]{subsection.2.2.1}{2.2.1 A brief history of Automatic Speech Recognition}{section.2.2}% 18
\BOOKMARK [3][]{subsubsection.2.2.1.1}{2.2.1.A Early Days}{subsection.2.2.1}% 19
\BOOKMARK [3][]{subsubsection.2.2.1.2}{2.2.1.B The Speech Understanding Research program}{subsection.2.2.1}% 20
\BOOKMARK [2][]{subsection.2.2.2}{2.2.2 Traditional automatic speech recognition systems}{section.2.2}% 21
\BOOKMARK [3][]{subsubsection.2.2.2.1}{2.2.2.A Feature extraction}{subsection.2.2.2}% 22
\BOOKMARK [3][]{subsubsection.2.2.2.2}{2.2.2.B Acoustic model}{subsection.2.2.2}% 23
\BOOKMARK [3][]{subsubsection.2.2.2.3}{2.2.2.C Pronunciation model}{subsection.2.2.2}% 24
\BOOKMARK [3][]{subsubsection.2.2.2.4}{2.2.2.D Language model}{subsection.2.2.2}% 25
\BOOKMARK [3][]{subsubsection.2.2.2.5}{2.2.2.E Decoder}{subsection.2.2.2}% 26
\BOOKMARK [2][]{subsection.2.2.3}{2.2.3 End-to-end automatic speech recognition}{section.2.2}% 27
\BOOKMARK [3][]{subsubsection.2.2.3.1}{2.2.3.A Connectionist Temporal Classification}{subsection.2.2.3}% 28
\BOOKMARK [3][]{subsubsection.2.2.3.2}{2.2.3.B Sequence to sequence}{subsection.2.2.3}% 29
\BOOKMARK [2][]{subsection.2.2.4}{2.2.4 Automatic Speech Recognition metrics}{section.2.2}% 30
\BOOKMARK [1][]{section.2.3}{2.3 Children automatic speech recognition}{chapter.2}% 31
\BOOKMARK [2][]{subsection.2.3.1}{2.3.1 Feature extraction stage}{section.2.3}% 32
\BOOKMARK [2][]{subsection.2.3.2}{2.3.2 Pronunciation and language model}{section.2.3}% 33
\BOOKMARK [2][]{subsection.2.3.3}{2.3.3 Design of acoustic models}{section.2.3}% 34
\BOOKMARK [2][]{subsection.2.3.4}{2.3.4 End-to-end models}{section.2.3}% 35
\BOOKMARK [2][]{subsection.2.3.5}{2.3.5 Data augmentation}{section.2.3}% 36
\BOOKMARK [3][]{subsubsection.2.3.5.1}{2.3.5.A Using external data}{subsection.2.3.5}% 37
\BOOKMARK [3][]{subsubsection.2.3.5.2}{2.3.5.B Using available data}{subsection.2.3.5}% 38
\BOOKMARK [2][]{subsection.2.3.6}{2.3.6 Training procedure for children speech recognition}{section.2.3}% 39
\BOOKMARK [3][]{subsubsection.2.3.6.1}{2.3.6.A Transfer learning}{subsection.2.3.6}% 40
\BOOKMARK [3][]{subsubsection.2.3.6.2}{2.3.6.B Multi-task learning}{subsection.2.3.6}% 41
\BOOKMARK [3][]{subsubsection.2.3.6.3}{2.3.6.C Self-supervised Learning}{subsection.2.3.6}% 42
\BOOKMARK [1][]{section.2.4}{2.4 Children Corpora}{chapter.2}% 43
\BOOKMARK [2][]{subsection.2.4.1}{2.4.1 LETSREAD}{section.2.4}% 44
\BOOKMARK [2][]{subsection.2.4.2}{2.4.2 PFSTAR\137SWEDISH}{section.2.4}% 45
\BOOKMARK [2][]{subsection.2.4.3}{2.4.3 ETLTDE}{section.2.4}% 46
\BOOKMARK [2][]{subsection.2.4.4}{2.4.4 CMU\137KIDS}{section.2.4}% 47
\BOOKMARK [2][]{subsection.2.4.5}{2.4.5 CHOREC}{section.2.4}% 48
\BOOKMARK [2][]{subsection.2.4.6}{2.4.6 MyST}{section.2.4}% 49
\BOOKMARK [1][]{section.2.5}{2.5 Summary}{chapter.2}% 50
\BOOKMARK [0][]{chapter.3}{3 Hybrid models for children automatic speech recognition}{}% 51
\BOOKMARK [1][]{section.3.1}{3.1 Introduction}{chapter.3}% 52
\BOOKMARK [1][]{section.3.2}{3.2 Factorised Time Delay Neural Network for children ASR}{chapter.3}% 53
\BOOKMARK [1][]{section.3.3}{3.3 Assessing the efficacy of multi-task and transfer learning from adult to children}{chapter.3}% 54
\BOOKMARK [2][]{subsection.3.3.1}{3.3.1 Methodology}{section.3.3}% 55
\BOOKMARK [2][]{subsection.3.3.2}{3.3.2 Corpus}{section.3.3}% 56
\BOOKMARK [2][]{subsection.3.3.3}{3.3.3 Experimental setup}{section.3.3}% 57
\BOOKMARK [2][]{subsection.3.3.4}{3.3.4 Results}{section.3.3}% 58
\BOOKMARK [2][]{subsection.3.3.5}{3.3.5 Summary and discussion}{section.3.3}% 59
\BOOKMARK [1][]{section.3.4}{3.4 Combining multi-task and transfer learning using multilingual children data}{chapter.3}% 60
\BOOKMARK [2][]{subsection.3.4.1}{3.4.1 Motivation}{section.3.4}% 61
\BOOKMARK [2][]{subsection.3.4.2}{3.4.2 The Multilingual-transfer learning approach}{section.3.4}% 62
\BOOKMARK [2][]{subsection.3.4.3}{3.4.3 Experimental Setup}{section.3.4}% 63
\BOOKMARK [2][]{subsection.3.4.4}{3.4.4 Multilingual-transfer learning experiment}{section.3.4}% 64
\BOOKMARK [2][]{subsection.3.4.5}{3.4.5 Cross-lingual validation}{section.3.4}% 65
\BOOKMARK [1][]{section.3.5}{3.5 Summary and discussion}{chapter.3}% 66
\BOOKMARK [0][]{chapter.4}{4 End-to-End children automatic speech recognition}{}% 67
\BOOKMARK [1][]{section.4.1}{4.1 Introduction}{chapter.4}% 68
\BOOKMARK [1][]{section.4.2}{4.2 Transformer model}{chapter.4}% 69
\BOOKMARK [1][]{section.4.3}{4.3 Conformer model}{chapter.4}% 70
\BOOKMARK [1][]{section.4.4}{4.4 Understand transfer learning efficacy for transformer based models}{chapter.4}% 71
\BOOKMARK [2][]{subsection.4.4.1}{4.4.1 Partial Transfer learning}{section.4.4}% 72
\BOOKMARK [2][]{subsection.4.4.2}{4.4.2 Experimental setup}{section.4.4}% 73
\BOOKMARK [2][]{subsection.4.4.3}{4.4.3 Corpus}{section.4.4}% 74
\BOOKMARK [2][]{subsection.4.4.4}{4.4.4 Implementation details}{section.4.4}% 75
\BOOKMARK [2][]{subsection.4.4.5}{4.4.5 Encoder-Decoder Transfer learning}{section.4.4}% 76
\BOOKMARK [2][]{subsection.4.4.6}{4.4.6 Modules Transfer learning}{section.4.4}% 77
\BOOKMARK [1][]{section.4.5}{4.5 Summary and discussion}{chapter.4}% 78
\BOOKMARK [0][]{chapter.5}{5 Exploring Parameter-Efficient Strategies in Transfer Learning for Child-Focused ASR Systems}{}% 79
\BOOKMARK [1][]{section.5.1}{5.1 Introduction}{chapter.5}% 80
\BOOKMARK [1][]{section.5.2}{5.2 Adapter tuning}{chapter.5}% 81
\BOOKMARK [1][]{section.5.3}{5.3 Investigating ASR for Child Speech with Adapters}{chapter.5}% 82
\BOOKMARK [1][]{section.5.4}{5.4 Implementation details}{chapter.5}% 83
\BOOKMARK [1][]{section.5.5}{5.5 Results}{chapter.5}% 84
\BOOKMARK [2][]{subsection.5.5.1}{5.5.1 Configurations}{section.5.5}% 85
\BOOKMARK [2][]{subsection.5.5.2}{5.5.2 Effect of the Adapter hidden dimension}{section.5.5}% 86
\BOOKMARK [2][]{subsection.5.5.3}{5.5.3 Unsupervised clustering for grouped-speaker Adapters}{section.5.5}% 87
\BOOKMARK [1][]{section.5.6}{5.6 Summary and discussion}{chapter.5}% 88
\BOOKMARK [0][]{chapter.6}{6 Integration of synthetic speech for data augmentation}{}% 89
\BOOKMARK [1][]{section.6.1}{6.1 Introduction}{chapter.6}% 90
\BOOKMARK [1][]{section.6.2}{6.2 Enhancing ASR Performance through TTS Data Augmentation}{chapter.6}% 91
\BOOKMARK [1][]{section.6.3}{6.3 Closing the synthetic and real mismatch gap with Adapters}{chapter.6}% 92
\BOOKMARK [1][]{section.6.4}{6.4 Overview of the automatic speech recognition and text-to-speechs systems}{chapter.6}% 93
\BOOKMARK [2][]{subsection.6.4.1}{6.4.1 Transformer architecture for ASR}{section.6.4}% 94
\BOOKMARK [2][]{subsection.6.4.2}{6.4.2 Multi-speaker text-to-speech: YourTTS}{section.6.4}% 95
\BOOKMARK [1][]{section.6.5}{6.5 Experimental setup}{chapter.6}% 96
\BOOKMARK [2][]{subsection.6.5.1}{6.5.1 Real speech corpus}{section.6.5}% 97
\BOOKMARK [2][]{subsection.6.5.2}{6.5.2 Synthetic data}{section.6.5}% 98
\BOOKMARK [2][]{subsection.6.5.3}{6.5.3 Experiments}{section.6.5}% 99
\BOOKMARK [1][]{section.6.6}{6.6 Results and discussion}{chapter.6}% 100
\BOOKMARK [2][]{subsection.6.6.1}{6.6.1 Comparison with existing approaches}{section.6.6}% 101
\BOOKMARK [